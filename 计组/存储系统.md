# above  

## 【考纲内容】  

（一）存储器的分类  

（二）层次化存储器的基本结构  

（三）半导体随机存储器（RAM）SRAM、DRAM、Flash存储器  

（四）主存储器DRAM芯片和内存条、多模块存储器、主存储器和CPU之间的连接  

（五）外部存储器磁盘存储器、固态硬盘（SSD）  

（六）高速缓冲存储器（Cache）Cache的基本原理：Cache和主存之间的映射方式Cache中主存块的替换算法：Cache写策略  

（七）虚拟存储器  

虚拟存储器的基本概念页式虚拟存储器：基本原理、页表、地址转换、TLB（快表）段式虚拟存储器的基本原理：段页式虚拟存储器的基本原理  

## 【复习提示】  

本章是历年命题重点，特别是有关Cache和虚拟存储器的考点容易出综合题。此外，存储器的特点，存储器的扩展（芯片选择、连接方式、地址范围等），交叉存储器，Cache的相关计算与替换算法，虚拟存储器与TLB也容易出选择题。读者应在掌握基本原理的基础上，多结合习题进行反复训练，以加深巩固。另外，读者需掌握存在Cache和TLB的计算机中的地址翻译与Cache映射问题，也建议结合《操作系统考研复习指导》复习。  

在学习本章时，请读者思考以下问题  

1）存储器系统为何要分这些层次？计算机如何管理这些层次？  

2）影响Cache性能的因素有哪些？  

3）虚拟存储系统的页面是设置得大一些好还是设置得小一些好？请读者在学习本章的过程中寻找答案，本章末尾会给出参考答案。  

# 存储器概述  

## 存储器的分类  

存储器种类繁多，可从不同角度对存储器进行分类。  
### 按在计算机中的作用（层次）分类  

1）主存储器。简称主存，也称内存储器（内存），用来存放计算机运行期间所需的程序和数据，CPU可以直接随机地对其进行访问，也可以和高速缓冲存储器（Cache）及辅助存储器交换数据。其特点是容量较小、存取速度较快、每位的价格较高。2）辅助存储器。简称辅存，也称外存储器或外存，用来存放当前暂时不用的程序和数据，以及一些需要永久性保存的信息。辅存的内容需要调入主存后才能被CPU访问。其特点是容量大、存取速度较慢、单位成本低。3）高速缓冲存储器。简称Cache，位于主存和CPU之间，用来存放当前CPU经常使用的指令和数据，以便CPU能高速地访问它们。Cache的存取速度可与CPU的速度相匹配，但存储容量小、价格高。现代计算机通常将它们制作在CPU中。  

### 按存储介质分类  

按存储介质，存储器可分为磁表面存储器（磁盘、磁带）、磁芯存储器、半导体存储器（MOS型存储器、双极型存储器）和光存储器（光盘）。  

### 按存取方式分类  

>#### pro：采用随机存取的存储器（2011）  

1）随机存储器（RAM)。存储器的任何一个存储单元都可以随机存取，而且存取时间与存储单元的物理位置无关。其优点是读/写方便、使用灵活，主要用作主存或高速缓冲存储器。RAM又分为静态RAM和动态RAM（第2节会详细介绍）。2）只读存储器（ROM）。存储器的内容只能随机读出而不能写入。信息一旦写入存储器就固定不变，即使断电，内容也不会丢失。因此，通常用它存放固定不变的程序、常数和汉字字库等。它与随机存储器可共同作为主存的一部分，统一构成主存的地址域。由ROM派生出的存储器也包含可反复重写的类型，ROM和RAM的存取方式均为随机存取。广义上的只读存储器已可通过电擦除等方式进行写入，其“只读”的概念没有保留，但仍保留了断电内容保留、随机读取特性，但其写入速度比读取速度慢得多。3）串行访问存储器。对存储单元进行读/写操作时，需按其物理位置的先后顺序寻址，包括顺序存取存储器（如磁带）和直接存取存储器（如磁盘、光盘）。  

顺序存取存储器的内容只能按某种顺序存取，存取时间的长短与信息在存储体上的物理位置有关，其特点是存取速度慢。直接存取存储器既不像RAM那样随机地访问任何一个存储单元，又不像顺序存取存储器那样完全按顺序存取，而是介于两者之间。存取信息时通常先寻我整个存储器中的某个小区域（如磁盘上的磁道），再在小区域内顺序查找。  

### 按信息的可保存性分类  

断电后，存储信息即消失的存储器，称为易失性存储器，如RAM。断电后信息仍然保持的存储器，称为非易失性存储器，如ROM、磁表面存储器和光存储器。  

若某个存储单元所存储的信息被读出时，原存储信息被破坏，则称为破坏性读出：若读出时，被读单元原存储信息不被破坏，则称为非破坏性读出。具有破坏性读出性能的存储器，每次读出操作后，必须紧接一个再生的操作，以便恢复被破坏的信息。  

## 存储器的性能指标  

存储器有三个主要性能指标，即存储容量、单位成本和存储速度。这三个指标相互制约，设计存储器系统所追求的目标就是大容量、低成本和高速度。  
1）存储容量 $=$ 存储字数 $\times$ 字长（如 $1\mathrm{M}{\times}8$ 位）。单位换算：1B（Byte，字节） $=8\mathrm{b}$ (bit，位)。存储字数表示存储器的地址空间大小，字长表示一次存取操作的数据量。  

2）单位成本：每位价格 $=$ 总成本/总容量。  

3）存储速度：数据传输速率（每秒传送信息的位数） $=$ 数据的宽度/存取周期  

$\textcircled{\scriptsize{1}}$ 存取时间（ $T_{\mathrm{a}})$ ：存取时间是指从启动一次存储器操作到完成该操作所经历的时间，分为读出时间和写入时间。 $\circledcirc$ 存取周期（ $T_{\mathrm{m}}$ )：存取周期是指存储器进行一次完整的读/写操作所需的全部时间，即连续两次独立访问存储器操作（读或写操作）之间所需的最小时间间隔。 $\textcircled{3}$ 主存带宽（ $B_{\mathrm{m}}$ )：也称数据传输速率，表示每秒从主存进出信息的最大数量，单位为字/秒、字节/秒（ $\mathbf{B}/\mathrm{s}.$ ）或位/秒（b/s)。  

存取时间不等于存取周期，通常存取周期大于存取时间。这是因为对任何一种存储器，在读/写操作之后，总要有一段恢复内部状态的复原时间。对于破坏性读出的存储器，存取周期往往比存取时间大得多，甚至可达 $T_{\mathrm{m}}\,{=}\,2T_{\mathrm{a}}$ ，因为存储器中的信息读出后需要马上进行再生。  

存取时间与存取周期的关系如图3.1所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/21f64fafd194c1ba1c6165c7728968a6e8ae536402c6539569c4d4e7c1719c0f.jpg)  
图3.1存取时间与存取周期的关系  

## 多级层次的存储系统  

为了解决存储系统大容量、高速度和低成本这三个相互制约的矛盾，在计算机系统中，通常采用多级存储器结构，如图3.2所示。在图中由上至下，位价越来越低，速度越来越慢，容量越来越大，CPU访问的频度也越来越低。实际上，存储系统层次结构主要体现在Cache-主存层和主存-辅存层。在存储体系中，Cache、主存能与CPU直接交换信息，辅存则要通过主存与CPU交换信息：主存与CPU、Cache、辅存都能交换信息，如图3.3所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/ecbfb7431920fae95ef8cac047bea026b1dcf473fe23120161d91a5948c10f1a.jpg)  
图3.2多级存储器结构  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3695ac60caa0ef8aa0adc0813638b48ef2f1586374984cdd5278a8b6809a560d.jpg)  
图3.3三级存储系统的层次结构及其构成  

存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。当CPU要从存储器中存取数据时，先访问Cache，若不在Cache中，则访问主存，若不在主存中，则访问磁盘，此时，操作数从磁盘读出送到主存，然后从主存送到Cache。从CPU的角度看，Cache-主存层的速度接近于Cache，容量和位价却接近于主存。从主存-辅存层分析，其速度接近于主存，容量和位价却接近于辅存。这就解决了速度、容量、成本这三者之间的矛盾。  
Cache-主存层主要解决CPU和主存速度不匹配的问题，主存和Cache之间的数据调动是由硬件自动完成的，对所有程序员均是透明的。主存一辅存层主要解决存储系统的容量问题，主存和辅存之间的数据调动是由硬件和操作系统共同完成的，对应用程序员是透明的。  

在主存一辅存层的不断发展中，逐渐形成了虚拟存储系统，在这个系统中程序员编程的地址范围与虚拟存储器的地址空间相对应，编程时可用的地址空间远大于主存空间。  

>##### attention：  

在Cache一主存层和主存一辅存层中，上一层中的内容都只是下一层中的内容的副本，也即Cache（或主存）中的内容只是主存（或辅存）中的内容的一部分。  



# 主存储器  

## SRAM DRAM  

半导体存储器分为随机存储器（RAM）和只读存储器（ROM）。RAM又分为静态随机存储器

（SRAM）和动态随机存储器（DRAM），主存储器主要由DRAM实现，靠近处理器的那一层（Cache）则由SRAM实现，它们都是易失性存储器。ROM是非易失性存储器。  

1.SRAM的工作原理  

通常把存放一个二进制位的物理器件称为存储元，它是存储器的最基本的构件。地址码相同的多个存储元构成一个存储单元。若干存储单元的集合构成存储体。  

静态随机存储器（SRAM）的存储元是用双稳态触发器（六晶体管MOS）来记忆信息的，静态是指即使信息被读出后，它仍保持其原状态而不需要再生（非破坏性读出）。  

SRAM的存取速度快，但集成度低，功耗较大，价格昂贵，一般用于高速缓冲存储器  

2.DRAM的工作原理  

与SRAM的存储原理不同，动态随机存储器（DRAM）是利用存储元电路中栅极电容上的电荷来存储信息的，DRAM的基本存储元通常只使用一个晶体管，所以它比SRAM的密度要高很多。相对于SRAM来说，DRAM具有集成度高、位价低和功耗低等优点，但DRAM的存取速度比SRAM慢，且必须定时刷新和读后再生，一般用于大容量的主存系统。  
>#### pro：需要刷新的存储芯片：SDRAM（2015）  

DRAM电容上的电荷一般只能维持 $1\!\sim\!2\mathrm{ms}$ ，因此即使电源不断电，信息也会自动消失。此外，读操作会使其状态发生改变（破坏性读出），需读后再生，这也是称其为动态存储器的原因。刷新可以采用读出的方法进行，根据读出内容对相应单元进行重写，即读后再生。对同一行进行相邻两次刷新的时间间隔称为刷新周期，通常取 $2\mathrm{ms}$ 。常用的刷新方式有以下3种：  

1）集中刷新：在一个刷新周期内，利用一段固定的时间，依次对存储器的所有行进行逐一再生，在此期间停止对存储器的读/写操作，称为死时间，也称访存死区。优点是读/写操  

作时不受刷新工作的影响：缺点是在集中刷新期间（死区）不能访问存储器。后半部分用于刷新。这种刷新方式增加了系统的存取周期，如存储芯片的存取周期为 $0.5\upmu\mathrm{s}$  $1\upmu\mathrm{s}$ 。优点是没有死区；缺点是加长了系统的存取周期。3）异步刷新：结合了前两种方法，使得在一个刷新周期内每一行仅刷新一次。具体做法是将刷新周期除以行数，得到相邻两行之间刷新的时间间隔1，每隔时间1产生一次刷新请求。这样就使“死时间”的分布更加分散，避免让CPU连续等待过长的时间。  

DRAM的刷新需要注意以下问题： $\textcircled{\scriptsize{1}}$ 刷新对CPU是透明的，即刷新不依赖于外部的访问； $\circledcirc$ DRAM的刷新单位是行，由芯片内部自行生成行地址； $\textcircled{3}$ 刷新操作类似于读操作，但又有所不同。另外，刷新时不需要选片，即整个存储器中的所有芯片同时被刷新。  

>##### attention：  

虽然DRAM的刷新和再生都是恢复数据，但刷新与再生的过程并不完全相同。刷新是以行为单位，逐行恢复数据的，而再生仅需恢复被读出的那些单元的数据。  

>#### pro：DRAM芯片行缓冲器容量的计算（2022）  

目前更常用的是SDRAM（同步DRAM)芯片，其工作方式与传统DRAM的不同，传统DRAM与CPU采用异步方式交换数据，CPU发出地址和控制信号后，经过一段延迟时间，数据才读出或写入，在读/写完成之前，CPU不能做其他工作。而SDRAM与CPU采用同步方式交换数据，它将CPU发出的地址和控制信号锁存起来，CPU在其读/写完成之前可进行其他操作。SDRAM的每一步操作都在系统时钟的控制下进行，支持突发传输方式?。第一次存取时给出首地址，同一行的所有数据都被送到行缓冲器，因此，以后每个时钟都可以连续地从SDRAM输出一个数据。行缓冲器用来缓存指定行中整行的数据，其大小为“列数 $\cdot\times$ 位平面数”，通常用SRAM实现。  

### DRAM芯片的读/写周期  

DRAM芯片读/写周期的时序图如图3.4所示。为了使芯片能正确接收行、列地址并实现读写操作，各信号的时间关系应符合一定要求。读（写）周期时间 $t_{\mathrm{{RC}}}$  $t_{\mathrm{{wc}}}$ ）表示DRAM芯片进行两次连续读（写）操作时所必须间隔的时间。  

在读周期中，在RAS有效前将行地址送到芯片的地址引I脚，CAS滞后RAS一段时间，在CAS有效前再将列地址送到芯片的地址引脚，RAS、CAS应分别至少保持 $t_{\mathrm{RAS}}$ 和 $t_{\mathrm{CAS}}$ 的时间。在读周期中WE为高电平，并在CAS有效前建立。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/ac49c5139324c976bef95c5760eecc986130d9c6997bdc4b888ceda236371d26.jpg)  
图3.4DRAM芯片读/写周期时序图  

在写周期中，行列选通信号的时序关系和读周期相同。在写周期中WE为低电平，同样在CAS有效前建立。为了保证数据可靠地写入，写数据必须在CAS有效前在数据总线上保持稳定。  

### SRAM DRAM  

表3.1详细列出了SRAM和DRAM各自的特点。  

表3.1SRAM DRAM
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/247e4075afae5a6921141e41eb4721eb9e64db737333bbae6ebd4d1ecd2c7aab.jpg)  

### 存储器芯片的内部结构  

如图3.5所示，存储器芯片由存储体、1/0读/写电路、地址译码器和控制电路等部分组成。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/2516f94b368ccd12877ec553c7401ec98c5b18224a062f7a42b548d1c7b596b4.jpg)  
图3.5存储器芯片结构图  
1）存储体（存储矩阵）。存储体是存储单元的集合，它由行选择线（X）和列选择线（Y）来选择所访问单元，存储体的相同行、列上的多位（位平面数）同时被读出或写入。  

2）地址译码器。用来将地址转换为译码输出线上的高电乎，以便驱动相应的读/写电路。地址译码有单译码法（一维译码）和双译码法（二维译码）两种方式。  

·单译码法。只有一个行译码器，同一行中所有存储单元的字线连在一起，同一行中的各单元构成一个字，被同时读出或写入。缺点是地址译码器的输出线数过多。·双译码法。如图3.5所示，地址译码器分为 $X$ 和Y方向两个译码器，在选中的行和列交叉点上能确定一个存储单元，这是DRAM芯片目前普遍采用的译码结构。  

3）I/O控制电路。用以控制被选中的单元的读出或写入，具有放大信息的作用。  

4）片选控制信号。单个芯片容量太小，往往满足不了计算机对存储器容量的要求，因此需用一定数量的芯片进行存储器的扩展。在访问某个字时，必须“选中”该存储字所在的芯片，而其他芯片不被“选中”，因此需要有片选控制信号。  

5）读/写控制信号。根据CPU给出的读命令或写命令，控制被选中单元进行读或写，  

## 只读存储器  

### 只读存储器（ROM）的特点  

>#### pro：RAM和ROM的区别（2010）  

ROM和RAM都是支持随机访问的存储器，其中SRAM和DRAM均为易失性半导体存储器。而ROM中一旦有了信息，就不能轻易改变，即使掉电也不会丢失。ROM具有两个显著的优点：

 $\textcircled{\scriptsize{1}}$ 结构简单，所以位密度比可读/写存储器的高。 $\circledcirc$ 具有非易失性，所以可靠性高。  

### ROM的类型  

根据制造工艺的不同，ROM可分为掩模式只读存储器（MROM）、一次可编程只读存储器

（PROM）、可擦除可编程只读存储器（EPROM）、Flash存储器和固态硬盘（SSD）。  

（1）掩模式只读存储器  

MROM的内容由半导体制造厂按用户提出的要求在芯片的生产过程中直接写入，写入以后任何人都无法改变其内容。优点是可靠性高，集成度高，价格便宜；缺点是灵活性差。  

（2）一次可编程只读存储器  

PROM是可以实现一次性编程的只读存储器。允许用户利用专门的设备（编程器）写入自己的程序，一旦写入，内容就无法改变。  

（3）可擦除可编程只读存储器  

EPROM不仅可以由用户利用编程器写入信息，而且可以对其内容进行多次改写。EPROM虽然既可读又可写，但它不能取代RAM，因为EPROM的编程次数有限，且写入时间过长。  

（4）Flash存储器  

>#### pro：Flash存储器的特点（2012）  

Flash存储器是在EPROM的基础上发展起来的，它兼有ROM和RAM的优点，可在不加电的情况下长期保存信息，又能在线进行快速擦除与重写。Flash存储器既有EPROM价格便宜、集成度高的优点，又有EPROM电可擦除重写的特点，且擦除重写的速度快。  

（5）固态硬盘（Solid State Drive，SSD）基于闪存的固态硬盘是用固态电子存储芯片阵列制成的硬盘，由控制单元和存储单元（Flash芯片）组成。保留了Flash存储器长期保存信息、快速擦除与重写的特性。对比传统硬盘也具有读/写速度快、低功耗的特性，缺点是价格较高。  
## 主存储器的基本组成  

图3.6是主存储器（MainMemory，MM）的基本框图，其中由一个个存储0或1的记忆单元（也称存储元件）构成的存储矩阵（也称存储体）是存储器的核心部件。存储元件是具有两种稳态的能表示二进制0和1的物理器件。为了存取存储体中的信息，必须对存储单元编号（也称编址）。编址单位是指具有相同地址的那些存储元件构成的一个单位，可以按字节编址，也可以按字编址。现代计算机通常采用字节编址方式，此时存储体内的一个地址中有1字节。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/32d7adac4f2bd43918e63a15cb75067abfdb78b3072fd13466d39b41b1a285a2.jpg)  
图3.6主存储器的基本组成框图  

指令执行过程中需要访问主存时，CPU首先把被访问单元的地址送到MAR中，然后通过地址线将主存地址送到主存中的地址寄存器，以便地址译码器进行译码，选中相应单元，同时CPU将读/写信号通过控制线送到主存的读/写控制电路。若是写操作，则CPU同时将要写的信息送到MIDR中，在读/写控制电路的控制下，经数据线将信号写入选中的单元；若是读操作，则主存读出选中单元的内容送至数据线，然后被送到MDR中。MDR的位数与数据线的位数相同，MAR的位数与地址线的位数相同。图3.6采用64位数据线，所以在按字节编址方式下，每次最多可以存取8个单元的内容。地址线的位数决定了主存地址空间的最大可寻址范围。例如，36位地址的最大寻址范围为 $0{\sim}2^{36}\!-\!1$ ，即地址从0开始编号。  

>##### attention：  

数据线的位数通常等于存储字长，因此MIDR的位数通常等于存储字长；若数据线的位数不等于存储字长，则MIDR的位数由数据线的位数决定。  

>#### pro：DRAM芯片的地址引脚复用技术（2014）  

DRAM芯片容量较大，地址位数较多，为了减少芯片的地址引脚数，通常采用地址引脚复用技术，行地址和列地址通过相同的引脚分先后两次输入，这样地址引脚数可减少一半。  

>#### pro：DRAM芯片行、列数的优化原则（2018）  

假定有一个 $2^{n}{\times}b$ 位DRAM芯片的存储阵列，其行数为r，列数为 $c$ ，则 $2^{n}\!=r\!\times\!c_{\circ}$ 存储阵列的地址位数为 $n$ ，其中行地址位数为 $\log_{2}r$ ，列地址位数为 $\log_{2}\!c$ ，则 $n\!=\!\log_{2}\!r\!+\!\log_{2}\!c$ 。由于DRAM芯片采用地址引脚复用技术，为减少地址引脚数，应尽量使行、列位数相同，即满足 $|r–c|$ 最小。又由于DRAM按行刷新，为减少刷新开销，应使行数较少，因此还需满足 $r\!\leqslant c$  
## 多模块存储器  

多模块存储器是一种空间并行技术，利用多个结构完全相同的存储模块的并行工作来提高存储器的吞吐率。常用的有单体多字存储器和多体低位交叉存储器。  

>##### attention：  

CPU的速度比存储器快得多，若同时从存储器中取出 $n$ 条指令，就可以充分利用CPU资源，提高运行速度。多体交叉存储器就是基于这种思想提出的。  

### 单体多字存储器  

在单体多字系统中，每个存储单元存储 $m$ 个字，总线宽度也为 $m$ 个字，一次并行读出 $m$ 个字。在一个存取周期内，从同一地址取出 $m$ 条指令，然后将指令逐条送至CPU执行，即每隔 $1/m$ 存取周期，CPU向主存取一条指令。这显然提高了单体存储器的工作速度。  

缺点：只有指令和数据在主存中连续存放时，这种方法才能有效提升存取速度。一旦遇到转移指令，或操作数不能连续存放时，这种方法的提升效果就不明显。  

### 多体并行存储器  

多体并行存储器由多体模块组成。每个模块都有相同的容量和存取速度，各模块都有独立的读/写控制电路、地址寄存器和数据寄存器。它们既能并行工作，又能交叉工作。  

多体并行存储器分为高位交叉编址和低位交叉编址两种。  

（1）高位交叉编址（顺序方式）  

高位地址表示模块号（或体号），低位地址为模块内地址（或体内地址）。如图3.7所示，存储器共有4个模块 $\mathbf{M}_{0}{\sim}\mathbf{M}_{3}$ ，每个模块有 $n$ 个单元，各模块的地址范围如图中所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/75d2ac2a627c5bcdace95fe592ef3010583976cec7fbd37807fc2eed52d25b78.jpg)  
图3.7高位交叉编址的多体存储器  

在高位交叉方式下，总把低位的体内地址送到由高位体号确定的模块内进行译码。访问一个连续主存块时，总是先在一个模块内访问，等到该模块访问完才转到下一个模块访问，CPU总是按顺序访问存储模块，各模块不能被并行访问，因而不能提高存储器的吞吐率。  

>##### attention：  

模块内的地址是连续的，存取方式仍是串行存取，因此这种存储器仍是顺序存储器。  
（2）低位交叉编址（交叉方式）  

>#### pro：交叉存储器中数据的存放方式（2017）  

低位地址为模块号，高位地址为模块内地址。如图3.8所示，每个模块按“模 $m$ ”交叉编址，模块号 $=$ 单元地址 $\%\,m$ ，假定有 $m$ 个模块，每个模块有 $k$ 个单元，则单元 $0,m,\cdots,(k-1)m$ 位于 $\mathbf{M}_{0}$ ：单元 $1,m+1,\cdots,(k-1)m+1$ 位于 $\mathbf{M}_{1}$ ；以此类推。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/b4f48c1df4011710c3242e64f98016fdf9a431c95108f08cf1745946d0aec796.jpg)  
图3.8低位交叉编址的多体存储器  

低位交义方式下，总是把高位的体内地址送到由低位体号所确定的模块内进行译码。程序连续存放在相邻模块中，因此称采用此编址方式的存储器为交叉存储器。  

交叉存储器可以采用轮流启动或同时启动两种方式。  

轮流启动方式  

若每个模块一次读/写的位数正好等于数据总线位数，模块的存取周期为T，总线周期为 $r,$ 为实现轮流启动方式，存储器交叉模块数应大于或等于  

$$
m=T/r
$$  

>#### pro：交叉存储器存取时间和带宽的计算（2012、2013）  

按每隔 $1/m$ 个存取周期轮流启动各模块，则每隔 $1/m$ 个存取周期就可读出或写入一个数据，存取速度提高 $m$ 倍，图3.9展示了4体交叉轮流启动的时间关系。交叉存储器要求其模块数大于或等于 $m$ ，以保证启动某模块后经过 $_{m\times r}$ 的时间后再次启动该模块时，其上次的存取操作已经完成（以保证流水线不间断）。这样，连续存取 $m$ 个字所需的时间为  

$$
t_{1}=T+(m-1)r
$$  

而顺序方式连续读取 $m$ 个字所需的时间为 $t_{2}\!=\!m T$ 。可见交叉存储器的带宽大大提高。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/357a8d6b3c8858f8e0445d4f33ec790e4dc9c97914e01f04c3acc061319ce47a.jpg)  
图3.9低位交叉轮流启动的存取时间示意图  

>#### pro：交叉存储器中访存冲突的分析（2015）  

在理想情况下， $m$ 体交叉存储器每隔1/m存取周期可读/写一个数据，若相邻的 $m$ 次访问的访存地址出现在同一个模块内，则会发生访存冲突，此时需延迟发生冲突的访问请求。  
同时启动方式  

若所有模块一次并行读/写的总位数正好等于数据总线位数，则可以同时启动所有模块进行读/写。设每个模块一次读/写的位数为16位，模块数 $m=4$ ，数据总线位数为64位，4个模块一共提供64位，正好构成一个存储字，因此应该同时启动4个模块进行并行读/写。  
 

# 主存储器与CPU的连接  

## 连接原理  

1）主存储器通过数据总线、地址总线和控制总线与CPU连接。  

2）数据总线的位数与工作频率的乘积正比于数据传输速率。  

3）地址总线的位数决定了可寻址的最大内存空间。  

4）控制总线（读/写）指出总线周期的类型和本次输入/输出操作完成的时刻。  

主存储器与CPU的连接如图3.10所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/1e1d92cf5473f7cdbefec0c268399f79d298a75bd67083e238876b319130a603.jpg)  
图3.10主存储器与CPU的连接  

单个芯片的容量是有限的，因此通过存储器芯片扩展技术，将多个芯片集成在一个内存条上，然后由多个内存条及主板上的ROM芯片组成计算机所需的主存空间，再通过总线与CPU相连。  

## 主存容量的扩展  

由于单个存储芯片的容量是有限的，它在字数或字长方面与实际存储器的要求都有差距，因此需要在字和位两方面进行扩充才能满足实际存储器的容量要求。  

1.位扩展法  

位扩展是指对字长进行扩展（增加存储字长）。当CPU的系统数据线数多于存储芯片的数据位数时，必须对存储芯片扩位，使其数据位数与CPU的数据线数相等。  
位扩展的连接方式：各芯片的地址线、片选线和读/写控制线与系统总线相应并联：各芯片的数据线单独引出，分别连接系统数据线。各芯片同时工作。  

如图3.11所示，用8片 $8K\!\times\!1$ 位的RAM芯片组成 $8K\!\times\!8$ 位的存储器。8片RAM芯片的地址线 $\mathrm{A}_{12}{\sim}\mathrm{A}_{0}$ 、CS、WE都分别连在一起，每片的数据线依次作为CPU数据线的一位。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f2b1e66bdcaafe6c0055bf34f9b6020f9ac3160dbd2ded9961f636deabd2b444.jpg)  
图3.11位扩展连接示意图  

2.字扩展法  

字扩展是指对存储字的数量进行扩展，而存储字的位数满足系统要求。系统数据线位数等于芯片数据线位数，系统地址线位数多于芯片地址线位数。  

字扩展的连接方式：各芯片的地址线与系统地址线的低位对应相连；芯片的数据线和读/写控制线与系统总线相应并联；由系统地址线的高位译码得到各芯片的片选信号。各芯片分时工作。  

>#### pro：字扩展（或字位扩展）后存储芯片的地址范围（2010、2016）  

如图3.12所示，用4片 $16K{\times}8$ 位的RAM芯片组成 $64\mathrm{K}\!\times\!8$ 位的存储器。4片RAM芯片的数据线 $\mathrm{D}_{0}{\sim}\mathrm{D}_{7}$ 和WE都分别连在一起。将 $\mathrm{A_{15}A_{14}}$ 用作片选信号， $\mathrm{A}_{15}\mathrm{A}_{14}=00$ 时，译码器输出端0有效，选中最左边1号芯片； $\mathrm{A}_{15}\mathrm{A}_{14}=01$ 时，译码器输出端1有效，选中2号芯片，以此类推（同一时刻只能有一个芯片被选中）。各芯片的地址分配如下：  

第一片，最低地址：0000000000000000：最高地址：0011111111111111（16位）第二片，最低地址：0100000000000000：最高地址：0111111111111111  

第三片，最低地址：1000000000000000；最高地址：1011111111111111第四片，最低地址：1100000000000000：最高地址：1111111111111111  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/44f1fe99a9391d96d9aeb0fb8712474bf298dbedaaa36321308e7bb49a6874d2.jpg)  
图3.12字扩展连接示意图  
3.字位同时扩展法  

字位同时扩展是前两种扩展的组合，这种方式既增加存储字的数量，又增加存储字长。  

字位同时扩展的连接方式：将进行位扩展的芯片作为一组，各组的连接方式与位扩展的相同；由系统地址线高位译码产生若干片选信号，分别接到各组芯片的片选信号。  

如图3.13所示，用8片 $16K\times4$ 位的RAM芯片组成 $64\mathrm{K}\!\times\!8$ 位的存储器。每两片构成一组 $16K\times8$ 位的存储器（位扩展），4组便构成 $64\mathrm{K}\!\times\!8$ 位的存储器（字扩展）。地址线 $\mathrm{A}_{15}\mathrm{A}_{14}$ 经译码器得到4个片选信号， $\mathrm{A}_{15}\mathrm{A}_{14}=00$ 时，输出端0有效，选中第一组的芯片（ $\textcircled{\scriptsize{1}}$ 和 $\circledcirc$ )； $\mathrm{A}_{15}\mathrm{A}_{14}=01$ 时，输出端1有效，选中第二组的芯片（ $\textcircled{3}$ 和 $\textcircled{4}$ )，以此类推。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/1bd0ffee871eff245d8c4e998e914cbf1ee53c30a0465b58592027c9ed8d0501.jpg)  
图3.13字位同时扩展及CPU的连接图  

## 存储芯片的地址分配和片选  

CPU要实现对存储单元的访问，首先要选择存储芯片，即进行片选；然后在选定的芯片中选择具体的存储单元，以进行数据的读/写，即进行字选。芯片内的字选通常是由CPU送出的 $N$ 条低位地址线完成（ $(N$ 由片内存储容量 $2^{N}$ 决定）。片选信号的产生方法分为线选法和译码片选法。  

### 线选法  

线选法用除片内寻址外的高位地址线直接连接至各个存储芯片的片选端，当某位地址线信息为“0”时，就选中与之对应的存储芯片。这些片选地址线每次寻址时只能有一位有效，不允许同时有多位有效，这样才能保证每次只选中一个芯片（或芯片组）。假设4片  $2\mathrm{K}\!\times\!8$  位存储芯片采用线选法构成  $8K\!\times\!8$  位存储器，各芯片 的片选信号见表3.2，其中低位地址线 $\mathrm{A_{10}}\mathrm{\sim}\mathrm{A_{0}}$ 作为字选线，用于片内寻址。  

优点：不需要地址译码器，线路简单。缺点：地址空间不连续，选片的地址线必须分时为低电平（否则不能工作），不能充分利用系统的存储器空间，造成地址资源的浪费。  

表3.2线选法的地址分配
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/d3e8ef9e2d826e33c5a04dddaf3613401040af874224f56e1f181b5f42aec2d2.jpg)  

### 译码片选法  

译码片选法用除片内寻址外的高位地址线通过地址译码器产生片选信号。如用8片 $8K\!\times\!8$ 位的存储芯片组成 $64\mathrm{K}\!\times\!8$ 位存储器（地线为16位，数据线为8位），需要8个片选信号；若采用线选法，除去片内寻址的13位地址线，仅余高3位，不足以产生8个片选信号。因此，采用译码片选法，即用一片74LS138作为地址译码器，高3位用于片选，则 $\mathrm{A}_{15}\mathrm{A}_{14}\mathrm{A}_{13}=000$ 时选中第一片， $\mathrm{A}_{15}\mathrm{A}_{14}\mathrm{A}_{13}\,{=}\,001$ 时选中第二片，以此类推。  
## 存储器与CPU的连接  

### 合理选择存储芯片  
 

>#### pro：根据要求合理选择存储芯片（2009、2021）  

要组成一个主存系统，选择存储芯片是第一步，主要指存储芯片的类型（RAM或ROM）和数量的选择。通常选用ROM存放系统程序、标准子程序和各类常数，RAM则是为用户编程而设置的。此外，在考虑芯片数量时，要尽量使连线简单、方便。  

### 地址线的连接  

>#### pro：  地址范围与存储容量的对应关系（2016、2023）  

存储芯片的容量不同，其地址线数也不同，而CPU的地址线数往往比存储芯片的地址线数要多。通常将CPU地址线的低位与存储芯片的地址线相连，以选择芯片中的某一单元（字选），这部分的译码是由芯片的片内逻辑完成的。而CPU地址线的高位则在扩充存储芯片时使用，用来选择存储芯片（片选），这部分译码由外接译码器逻辑完成。  

例如，设CPU地址线为16位，即 $\mathrm{A}_{15}{\sim}\mathrm{A}_{0}$  $1K{\times}4$ 位的存储芯片仅有10根地址线，此时可将CPU的低位地址 $\mathrm{A}_{9}{\sim}\mathrm{A}_{0}$ 与存储芯片的地址线 $\mathrm{A}_{9}{\sim}\mathrm{A}_{0}$ 相连。  

### 数据线的连接  

CPU的数据线数与存储芯片的数据线数不一定相等，在相等时可直接相连：在不等时必须对存储芯片扩位，使其数据位数与CPU的数据线数相等。  

### 读/写命令线的连接  

CPU读/写命令线一般可直接与存储芯片的读/写控制端相连，通常高电平为读，低电平为写。有些CPU的读/写命令线是分开的（读为RD，写为WE，均为低电平有效），此时CPU的读命令线应与芯片的充许读控制端相连，而CPU的写命令线则应与芯片的充许写控制端相连。  

### 片选线的连接  

片选线的连接是CPU与存储芯片连接的关键。存储器由许多存储芯片叠加而成，哪一片被选中完全取决于该存储芯片的片选控制端CS是否能接收到来自CPU的片选有效信号。  

片选有效信号与CPU的访存控制信号MREQ（低电平有效）有关，因为只有当CPU要求访存时，才要求选中存储芯片。若CPU访问I/O，则MREQ为高，表示不要求存储器工作。  


# 外部存储器  

## 磁盘存储器  

磁盘存储器是以磁盘为存储介质的存储器，其主要优点： $\textcircled{\scriptsize{1}}$ 存储容量大，位价格低： $\circledcirc$ 记录介质可重复使用： $\textcircled{3}$ 记录信息可长期保存而不丢失，甚至可脱机存档： $\textcircled{4}$ 非破坏性读出，读出时不需要再生。缺点：存取速度慢，机械结构复杂，对工作环境要求较高。  

### 磁盘存储器  

>#### pro：  磁盘存储器的相关概念（2019）  

#### （1）磁盘设备的组成  

$\textcircled{\scriptsize{1}}$ 磁盘存储器的组成。磁盘存储器由磁盘驱动器、磁盘控制器和盘片组成。  

·磁盘驱动器。驱动磁盘转动并在盘面上通过磁头进行读/写操作的装置，如图3.14所示。·磁盘控制器。磁盘驱动器与主机的接口，负责接收并解释CPU发来的命令，向磁盘驱 动器发出各种控制信号，并负责检测磁盘驱动器的状态。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/949e3320f633db83d48f7dfbb5d87ac3e37d71935bede8ce35981b7926da2bb7.jpg)  
图3.14磁盘驱动器示意图  

$\circledcirc$ 存储区域。一个磁盘含有若干记录面，每个记录面划分为若干圆形的磁道，而每条磁道又划分为若干扇区，扇区（也称块）是磁盘读/写的最小单位，即磁盘按块存取。  

·磁头数（Heads）：即记录面数，表示磁盘共有多少个磁头，磁头用于读取/写入盘片上记录面的信息，一个记录面对应一个磁头·柱面数（Cylinders）：表示磁盘每面盘片上有多少条磁道。在一个盘组中，不同记录面的相同编号（位置）的诸磁道构成一个圆柱面。  

·扇区数（Sectors）：表示每条磁道上有多少个扇区。  

相邻磁道及相邻扇区间通过一定的间隙分隔开，以避免精度错误。由于扇区按固定圆心角度划分，因此位密度从最外道向里道增加，磁盘的存储能力受限于最内道的最大记录密度。  
$\textcircled{3}$ 磁盘高速缓存（DiskCache）。在内存中开辟一部分区域，用于缓冲将被送到磁盘上的数据。优点：写磁盘时是按“簇”进行的，可以避免频繁地用小块数据写盘；有些中间结果数据在写回磁盘之前可被快速地再次使用。  

#### （2）磁记录原理  

编码方法：按某种方案（规律），把一连串的二进制信息变换成存储介质磁层中一个磁化翻转状态的序列，并使读/写控制电路容易、可靠地实现转换。  

磁记录方式：通常采用调频制（FM）和改进型调频制（MFM）的记录方式。  

#### （3）磁盘的性能指标  

$\textcircled{\scriptsize{1}}$ 记录密度。记录密度是指盘片单位面积上记录的二进制信息量，通常以道密度、位密度和面密度表示。道密度是沿磁盘半径方向单位长度上的磁道数，位密度是磁道单位长度上能记录的二进制代码位数，面密度是位密度和道密度的乘积。  

$\circledcirc$ 磁盘的容量。磁盘容量有非格式化容量和格式化容量之分。非格式化容量是指磁记录表面可利用的磁化单元总数，非格式化容量 $=$ 记录面数 $\cdot\times$ 柱面数 $\times$ 每条磁道的磁化单元数。格式化容量是指按照某种特定的记录格式所能存储信息的总量。格式化容量  $=$  记录面数  $\times$  柱 面数 $\times$ 每道扇区数x每个扇区的容量。格式化后的容量比非格式化容量要小。  

>#### pro：磁盘存取时间的计算（2013、2015、2022）  

$\circledast$ 存取时间。存取时间由寻道时间（磁头移动到自的磁道的时间）、旋转延迟时间（磁头定位到要读/写扇区的时间）和传输时间（传输数据所花费的时间）三部分构成。因为寻道和我扇区的距离远近不一，所以寻道时间和旋转延迟时间通常取平均值（平均寻道时间取从最外道移动到最内道时间的一半，平均旋转延迟时间取旋转半周的时间）。  

$\textcircled{4}$ 数据传输速率。磁盘存储器在单位时间内向主机传送数据的字节数，称为数据传输速率。假设磁盘转数为r转/秒，每条磁道容量为 $N$ 字节，则数据传输速率为  

$$
D_{\mathrm{r}}\,{=}\,r N
$$  

####  （4）磁盘地址  

>#### pro：磁盘地址结构的计算（2022）  

主机向磁盘控制器发送寻址信息，磁盘的地址一般如下图所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/63c7621ebd786e99322bc2b3b8f2b7a6108c715c1896f3fefe6388625f9c5d47.jpg)  

若磁盘有16个盘面，每个盘面有256个磁道，每个磁道划分为16个扇区，则每个扇区地址要16位二进制代码，其格式如下图所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/a05c8eee3f46040951717583967f67c0aa6f299dd9fed653a49b666bc3e3b2b4.jpg)  

（5）磁盘的工作过程  

磁盘的主要操作是寻址、读盘、写盘。每个操作都对应一个控制字，磁盘工作时，第一步是取控制字，第二步是执行控制字。磁盘属于机械式部件，其读/写操作是事行的，不可能在同一时刻既读又写，也不可能在同一时刻读两组数据或写两组数据。  

### 磁盘阵列  

RAID（独立冗余磁盘阵列）是指将多个独立的物理磁盘组成一个独立的逻辑盘，数据在多个物理盘上分割交义存储、并行访问，具有更好的存储性能、可靠性和安全性。  
>#### pro：提高RAID可靠性的措施（2013）  

RAID的分级如下所示。在RAID1～RAID5几种方案中，无论何时有磁盘损坏，都可随时拔出受损的磁盘再插入好的磁盘，而数据不会损坏，提升了系统的可靠性。  

RAID0：无冗余和无校验的磁盘阵列，RAID1：镜像磁盘阵列。RAID2：采用纠错的海明码的磁盘阵列。RAID3：位交叉奇偶校验的磁盘阵列。RAID4：块交叉奇偶校验的磁盘阵列。RAID5：无独立校验的奇偶校验磁盘阵列。  

RAIDO把连续多个数据块交替地存放在不同物理磁盘的扇区中，几个磁盘交叉并行读/写，即条带化技术，这样不仅扩大了存储容量，还提高了磁盘存取速度，但RAIDO没有容错能力。  

为了提高可靠性，RAID1使两个磁盘同时进行读/写，互为备份，若一个磁盘出现故障，可从另一磁盘中读出数据。两个磁盘当一个磁盘使用，意味着容量减少一半。  

总之，RAID通过同时使用多个磁盘，提高了传输速率；通过在多个磁盘上并行存取来大幅提高存储系统的数据吞吐量：通过镜像功能，提高安全可靠性：通过数据校验，提供容错能力。  

## 固态硬盘  

### 固态硬盘的特性  

固态硬盘（SSD）是一种基于闪存技术的存储器。它与U盘并无本质差别，只是容量更大，存取性能更好。一个SSD由一个或多个闪存芯片和闪存翻译层组成，如图3.15所示。闪存芯片替代传统旋转磁盘中的机械驱动器，而闪存翻译层将来自CPU的逻辑块读/写请求翻译成对底层 物理设备的读/写控制信号，因此，这个闪存翻译层相当于代替了磁盘控制器的角色。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f4c9b82aff9e75d81635a4e6f89fa583ec0838d5124b1cd07047a821d4691ebd.jpg)  
图3.15固态硬盘（SSD）  

在图3.15中，一个闪存由 $B$ 块组成，每块由 $P$ 页组成。通常，页的大小是 $512\mathrm{B}{\sim}4\mathrm{KB}$ ，每块由 $32\!\sim\!128$ 页组成，块的大小为 $16\mathrm{KB}{\sim}512\mathrm{KB}$ 。数据是以页为单位读/写的。只有在一页所属的块整个被擦除后，才能写这一页。不过，一旦一个块被擦除，块中的每个页就都可以直接再写一次。某个块进行了若干次重复写之后，就会磨损坏，不能再使用。  

随机写很慢，有两个原因。首先，擦除块较慢，通常比访问页高一个数量级。其次，若写操作试图修改一个包含已有数据的页 $P_{i},$ 则这个块中所有含有用数据的页都必须被复制到一个新（擦除过的）块中，然后才能进行对页 $P_{i}$ 的写操作。  

比起传统磁盘，SSD有很多优点，它由半导体存储器构成，没有移动的部件，因而随机访问时间比机械磁盘要快很多，也没有任何机械噪声和振动，能耗更低，抗震性好，安全性高等。  
### 磨损均衡（Wear Leveling）  

固态硬盘也有缺点，闪存的擦写寿命是有限的，一般是几百次到几干次。若直接用普通闪存组装SSD，则实际的寿命表现可能非常令人失望一一读/写数据时会集中在SSD的一部分闪存，这部分闪存的寿命会损耗得特别快。一旦这部分闪存损坏，整块SSD也就损坏了。这种磨损不均衡的情况，可能会导致一块256GB的SSD，只因数兆字节空间的闪存损坏而整块损坏。  

为了弥补SSD的寿命缺陷，引入了磨损均衡。SSD磨损均衡技术大致分为两种1）动态磨损均衡。写入数据时，自动选择较新的闪存块。老的闪存块先歇一歇。  

2）静态磨损均衡。这种技术更为先进，就算没有数据写入，SSD也会监测并自动进行数据分配，让老的闪存块承担无须写数据的存储任务，同时让较新的闪存块腾出空间，平常的读/写操作在较新的闪存块中进行。如此一来，各个闪存块的寿命损耗就都差不多。  

有了这种算法加持，SSD的寿命就比较可观了。例如，对于一个256GB的SSD，若闪存的擦写寿命是500次，则需要写入125TB数据，才寿终正寝。就算每天写入10GB数据，也要三十多年才能将闪存磨损坏，更何况很少有人每天往SSD中写入10GB数据。  
 

# 缓冲存储器  

由于程序的转移概率不会很低，数据分布的离散性较大，因此单纯依靠并行主存系统提高主存系统的效率是有限的。高速缓存Cache拥有比主存更快的速度，因此在CPU和主存之间设置Cache可以显著提高存储系统的效率。Cache由SRAM组成，通常直接集成在CPU中。  

## 程序访问的局部性原理  

程序访问的局部性原理包括时间局部性和空间局部性。>#### pro：分析给定代码的时空局部性（2017、2023）  

时间局部性是指最近的未来要用到的信息，很可能是现在正在使用的信息，因为程序中存在盾环和需要多次重复执行的子程序段，以及对数组的存储和访问操作。空间局部性是指最近的末来要用到的信息，很可能与现在正在使用的信息在存储空间上是邻近的，因为指令通常是顺序存放、顺序执行的，数据一般也是以向量、数组等形式簇聚地存储的。  
高速缓冲技术就是利用局部性原理，把程序中正在使用的部分数据存放在一个高速的、容量较小的Cache中，使CPU的访存操作大多数针对Cache进行，从而提高程序的执行速度。  

【例3.2】假设数组元素按行优先方式存储，对于下面的两个程序：  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/b41550f0178bf3620106cb205eed357ec765a9ec70eeda1a5cf5cda98d67dbf0.jpg)  

1）对于数组a的访问，哪个空间局部性更好？哪个时间局部性更好？2）对于指令访问来说，for循环体的空间局部性和时间局部性如何？  

解：假定M、N都为2048，按字节编址，每个数组元素占4字节，则指令和数据在主存中的存放情况如图3.16所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3beffe3fd561e33f22d27b23b7735f6b3805a9b89288a00b6514d0ad34b06ace.jpg)  
图3.16指令和数据在主存的存放  

>#### pro：数组按行或列访问命中率的分析（2010）；数组循环访问的命中率分析（2016、2020）  

1）对于数组a，程序A和程序B的空间局部性相差较大  

程序A对数组a的访问顺序为a[0][0],a[0][1],,a[0][2047];a[1][0],a[1][1],,a[1][2047] 由此可见，访问顺序与存放顺序是一致的，因此空间局部性好。  

程序B对数组a的访问顺序为a[0][0],a[1][0].,a[2047][0];a[0][1],a[1][1],,a[2047][1]；。由此可见，访问顺序与存放顺序不一致，每次访问都要跳过2048个数组元素，即8192字节，若主存与Cache的交换单位小于8KB，则每访问一个数组元素都需要将一个主存块装入Cache，因而没有空间局部性。  

两个程序中，数组a的时间局部性都差，因为每个数组元素都只被访问一次。  
>#### pro：程序中指令Cache的命中率分析（2014）  

2）对于for循环体，程序A和程序B中的访问局部性是一样的。因为循环体内指令按序连续存放，所以空间局部性好；内循环体被连续重复执行 $2048{\times}2048$ 次，因此时间局部性也好。  

由上述分析可知，虽然程序A和程序B的功能相同，但因内、外两重循环的顺序不同而导致两者对数组a访问的空间局部性相差较大，从而带来执行时间的巨大差异。  

## Cache的基本工作原理  

为便于Cache与主存交换信息，Cache和主存都被划分为大小相等的块，Cache块也称Cache行，每块由若干字节组成，块的长度称为块长（也称行长）。因为Cache的容量远小于主存的容量，所以Cache中的块数要远少于主存中的块数，Cache中仅保存主存中最活跃的若干块的副本。因此，可按照某种策略预测CPU在未来一段时间内欲访存的数据，将其装入Cache。图3.17所示为Cache的基本结构。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/e95e7ed2b82fea1f024168bab35ac7aaf81ff99ed3bddc2a543be0029e74d2bd.jpg)  
图3.17高速缓冲存储器的工作原理  

>#### pro：  

Cache命中对CPU执行时间影响的分析（2013、2015）  

当CPU发出读请求时，若访存地址在Cache中命中，就将此地址转换成Cache地址，直接对Cache进行读操作，与主存无关；若Cache不命中，则仍需访问主存，并把此字所在的块一次性地从主存调入Cache。若此时Cache已满，则需根据某种替换算法，用这个块替换Cache中原来的某块信息。整个过程全部由硬件实现。值得注意的是，CPU与Cache之间的数据交换以字为单位，而Cache与主存之间的数据交换则以Cache块为单位。  

当CPU发出写请求时，若Cache命中，有可能会遇到Cache与主存中的内容不一致的问题。例如，由于CPU写Cache，把Cache某单元中的内容从 $X$ 修改成 $X$ ，而主存对应单元中的内容仍然是 $X,$ ，没有改变，因此若Cache命中，需要按照一定的写策略处理，常见的处理方法有全写法和回写法，详见本节的Cache写策略部分。  

>##### attention：  

某些计算机中也采用同时访问Cache和主存的方式，若Cache命中，则终止访存。  

>#### pro：Cache命中率的计算（2009）  

CPU欲访问的信息已在Cache 中的比率称为Cache的命中率。设一个程序执行期间，Cache的总命中次数为 $N_{\mathrm{c}}$ ，访问主存的总次数为 $N_{\mathrm{m}}$ ，则命中率 $H$ 为  
$$
H={N_{\mathrm{c}}}\,/({N_{\mathrm{c}}}+{N_{\mathrm{m}}})
$$  

可见为提高访问效率，命中率 $H$ 越接近1越好。设 $t_{c}$ 为命中时的Cache访问时间， $t_{\mathrm{m}}$ 为未命中时的访问时间， $1-H$ 表示未命中率，则Cache-主存系统的平均访问时间 $T_{\mathrm{a}}$ 为  

$$
T_{\mathrm{a}}=H t_{\mathrm{c}}+\left(1-H\right)t_{\mathrm{m}}
$$  

>#### pro：Cache缺失率对主存带宽的影响（2012）  

【例3.3】假设Cache的速度是主存的5倍，且Cache的命中率为 $95\%$ ，则采用Cache后，存储器性能提高多少（假设采用先访问Cache，Cache不命中时，才采用访问主存的方式）？  

解：设Cache的存取周期为 $t$ ，主存的存取周期为 $5t$ ，得出系统的平均访问时间 $T$ 为  

$T\!=$ Cache命中时的访问时间 $\times$ 命中率 $^+$ Cache缺失时的访问时间 $\times$ 缺失率 $=0.95\times t+0.05\times(t+5t)=1.25t$  

或  

$T\!=$  Cache命中时的访问时间  $^+$  Cache缺失时的访存开销  $\times$  缺失率  $=t+0.05{\times}5t=1.25t$  可知，采用Cache后的存储器性能为原来的 $5t/1.25t/{\approx}\,4$ 倍。  

根据Cache的读、写流程，可知实现Cache时需解决以下关键问题  

1）数据查找。如何快速判断数据是否在Cache中。2）地址映射。主存块如何存放在Cache中，如何将主存地址转换为Cache地址。3）替换策略。Cache满后，使用何种策略对Cache块进行替换或淘汰。4）写入策略。如何既保证主存块和Cache块的数据一致性，又尽量提升效率。  

## Cache和主存的映射方式  

由于Cache行数比主存块数少得多，因此主存中只有一部分块的信息可放在Cache中，因此在Cache中要为每块加一个标记位，指明它是主存中哪一块的副本。该标记的内容相当于主存中块的编号。为了说明Cache行中的信息是否有效，每个Cache行需要一个有效位。  

Cache行中的信息是主存中某个块的副本，地址映射是指把主存地址空间映射到Cache地址空间，即把存放在主存中的信息按照某种规则装入Cachnie。地址映射的方法有以下3种。  

### 直接映射  

主存中的每一块只能装入Cache中的唯一位置。若这个位置已有内容，则产生块冲突，原来的块将无条件地被替换出去（无须使用替换算法）。直接映射实现简单，但不够灵活，即使Cache的其他许多地址空着也不能占用，这使得直接映射的块冲突概率最高，空间利用率最低。  

>#### pro：直接映射的地址结构及映射关系的分析（2010、2011、2015）  

直接映射的关系可定义为  

Cache行号 $=$ mod Cache  

假设Cache共有 $2^{c}$ 行，主存有 $2^{m}$ 块，在直接映射方式中，主存的第0块、第 $2^{c}$ 块、第 $2^{c+1}$ 块·………·只能映射到Cache的第0行；而主存的第1块、第 $2^{c}+1$ 块、第 $2^{c+1}+1$ 块·只能映射到Cache的第1行，以此类推。由映射函数可看出，主存块号的低 $^c$ 位正好是它要装入的Cache行号。给每个Cache行设置一个长为 $\scriptstyle t\,=\,m\,-\,c$ 的标记（tag），当主存某块调入Cache后，就将其块号的高 $t$ 位设置在对应Cache行的标记中，如图3.18（a所示。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/0d4d9150e1b74972905e0f2411e001d19ac079c052b685d6319df172fd1f46af.jpg)  
图3.18Cache和主存之间的直接映射方式  

直接映射的地址结构为  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/1a310ec397e1e430790891edc7b4fe7034517d79896535099a72318e362d5cfc.jpg)  

CPU访存过程如图3.18（b）所示。首先根据访存地址中间的c位，找到对应的Cache行，将对 应Cache行中的标记和主存地址的高t位标记进行比较，若相等且有效位为1，则访问Cache“命中”，此时根据主存地址中低位的块内地址，在对应的Cache行中存取信息；若不相等或有效位为O，则“不命中”，此时CPU从主存中读出该地址所在的一块信息送到对应的Cache行中，将有效位置1，并将标记设置为地址中的高：位，同时将该地址中的内容送CPU。  

### 全相联映射  

主存中的每一块可以装入Cache中的任何位置，如图3.19所示，每行的标记用于指出该行来自主存的哪一块，因此CPU访存时需要与所有Cache行的标记进行比较。优点： $\textcircled{\scriptsize{1}}$ Cache块的冲突概率低，只要有空闲Cache行，就不会发生冲突： $\circledcirc$ 空间利用率高： $\textcircled{3}$ 命中率高：缺点： $\textcircled{\scriptsize{1}}$ 标记的比较速度较慢： $\circledcirc$ 实现成本较高，通常需采用按内容寻址的相联存储器。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/a8989ceb071e5ad8c8d6dca134a27f62a4c6286c510cc52ef891f745bf53aba0.jpg)  
图3.19Cache和主存之间的全相联映射方式  

全相联映射的地址结构为  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/d778483358bb5cfaa81acdb4053dea9aacce5ec9ea238257e705ba9e2fca92cd.jpg)  
CPU访存过程如下：首先将主存地址的高位标记（位数 $=\log_{2}$ 主存块数）与Cache各行的标记进行比较，若有一个相等且对应有效位为1，则命中，此时根据块内地址从该Cache行中取出信息；若都不相等，则不命中，此时CPU从主存中读出该地址所在的一块信息送到Cache的任意一个空闲行中，将有效位置1，并设置标记，同时将该地址中的内容送CPU。  

>#### pro：根据地址结构和比较器数量判断映射方式（2018）  

通常为每个Cache行都设置一个比较器，比较器位数等于标记字段的位数。访存时根据标记字段的内容来访问Cache行中的主存块，因而其查找过程是一种“按内容访问”的存取方式，所以是一种“相联存储器”。这种方式的时间开销和硬件开销都较大，不适合大容量Cache。  

### 组相联映射  

>#### pro：组相联映射方式的原理（2009、2016、2018～2020、2023）  

将Cache分成 $\mathcal{Q}$ 个大小相等的组，每个主存块可以装入固定组中的任意一行，即组间采用直接映射、而组内采用全相联映射的方式，如图3.20所示。它是对直接映射和全相联映射的一种折中，当 $Q=1$ 时变为全相联映射，当 $\varrho=$ Cache行数时变为直接映射。路数越大，即每组Cache行的数量越大，发生块冲突的概率越低，但相联比较电路也越复杂。选定适当的数量，可使组相联映射的成本接近直接映射，而性能上仍接近全相联映射。假设每组有 $r$ 个Cache行，则称为 $r$ 路组相联，图3.20中每组有两个Cache行，因此称为二路组相联。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/705d35296eca71ed8eded974c3d677da76008d584c3b528fa5e8971962c6d880.jpg)  
图3.20Cache和主存之间的二路组相联映射方式  

组相联映射的关系可以定义为  

Cache组号 $=$ mod Cache 组数（Q）  

组相联映射的地址结构为  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/16468247b7f68d80ea35bf713452faaeaab1af0cc4620f1f67e90b71bd4d66a4.jpg)  

>#### pro：组相联映射的访存过程及Cache缺失处理过程（2020）  

CPU访存过程如下：首先根据访存地址中间的组号找到对应的Cache组；将对应Cache组中每个行的标记与主存地址的高位标记进行比较；若有一个相等且有效位为1，则访问Cache命中，此时根据主存地址中的块内地址，在对应Cache行中存取信息；若都不相等或虽相等但有效位为0，则不命中，此时CPU从主存中读出该地址所在的一块信息送到对应Cache组的任意一个空闲行中，将有效位置1，并设置标记，同时将该地址中的内容送CPU。  
>#### pro：组相联映射中比较器的个数和位数（2022）  

直接映射因为每块只能映射到唯一的Cache行，因此只需设置1个比较器。而 $r$ 路组相联映射需要在对应分组中与 $r$ 个Cache行进行比较，因此需设置 $r$ 个比较器。  

>#### pro：直接映射、组相联映射相关标记位及总容量的分析（2010）  

【例3.4】假设某个计算机的主存地址空间大小为256MB，按字节编址，其数据Cache有8个Cache行，行长为64B。  

1）若不考虑用于Cache的一致维护性位（脏位）和替换算法控制位，并且采用直接映射方式，则该数据Cache的总容量为多少？2）若该Cache采用直接映射方式，则主存地址为3200（十进制）的主存块对应的Cache行号是多少？采用二路组相联映射时又是多少？3）以直接映射方式为例，简述访存过程（设访存的地址为0123456H）。  

解：  

1）因为Cache包括了可以对Cache中所包含的存储器地址进行跟踪的硬件，即Cache的总容量 $\bar{=}$ 存储容量 $^+$ 标记阵列容量（有效位、标记位），本题不考虑脏位和替换算法位。  

>#### pro：直接映射相关标记位的分析（2015、2021）  

>##### attention：  

每个Cache行对应一个标记项（包括有效位、脏位、替换算法位、标记位），在组相联中，将每组各行的标记项排成一行，将各组从上到下排列，构成一个二维的标记阵列。查找Cache时就是查找标记阵列的标记项是否符合要求。二路组相联的标记阵列如图3.21所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/57f1a99d258e755109902e23acf15b394fc66b1b280f1f9dca674653a358810b.jpg)  
图3.21二路组相联的标记阵列示意图  

因此本题中每行相关的存储器容量如图3.22所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/683ed3f03365e410bb54f631a3aa7975ef5c257a5d5fb4a06bc06596f36764f8.jpg)  
图3.22Cache行的存储容量示意图  

标记字段长度的计算：主存地址有28位 $(256\mathrm{MB}=2^{28}\mathrm{B}$ ），其中6位为块内地址（ $2^{6}\mathrm{B}=$ 64B），3位为行号 $(2^{3}=8)$ ），剩余 $28-6-3=19$ 位为标记字段，故数据Cache的总容量为 $8{\times}(1+19+512)=4256$ 位。  
2）直接映射方式中，主存按照块的大小划分，主存地址3200对应的字块号为 $3200\mathrm{B}/64\mathrm{B}=$ 50。而Cache只有8行，则 $50\;\mathrm{mod}\;8=2$ ，因此对应的Cache行号为2。二路组相联映射方式，实质上就是将两个Cache行合并，内部采用全相联方式，外部采用直接映射方式， $50~\mathrm{mod}\:4=2$ ，对应的组号为2，即对应的Cache行号为4或5。  

3）直接映射方式中，28位主存地址可分为19位的主存标记位，3位的块号，6位的块内地址，即 $0000\:0001\:0010\:0011\:010$ 为主存标记位，001为块号，010110为块内地址。首先根据块号，查Cache（即001号Cache行）中对应的主存标记位，看是否相同。若相同，再看Cache行中的有效位是否为1，若是，称此访问命中，按块内地址010110读出Cache行所对应的单元并送入CPU中，完成访存。若出现标记位不相等或有效位为0的情况，则不命中，访问主存将数据取出并送往CPU和Cache对应块中，把主存地址的高19位写入001行的标记位，并将有效位置1。  

思考： $\textcircled{\scriptsize{1}}$ 若第一问中采用二路组相联，则Cache总容量是多少？ $\textcircled{2}$ 仔细分析主存划分和Cache划分的关系，自行推导二路组相联映射方式的主存地址划分和访存过程。  

三种映射方式中，直接映射的每个主存块只能映射到Cache中的某一固定行；全相联映射可以映射到所有Cache行： $N$ 路组相联映射可以映射到 $N$ 行。当Cache大小、主存块大小一定时，  

1）直接映射的命中率最低，全相联映射的命中率最高。2）直接映射的判断开销最小、所需时间最短，全相联映射的判断开销最大、所需时间最长。3）直接映射标记所占的额外空间开销最少，全相联映射标记所占的额外空间开销最大。  

## Cache中主存块的替换算法  

在采用全相联映射或组相联映射方式时，从主存向Cache传送一个新块，当Cache或Cache组中的空间已被占满时，就需要使用替换算法置换Cache行。而采用直接映射时，一个给定的主存块只能放到唯一的固定Cache行中，所以在对应Cache行已有一个主存块的情况下，新的主存块毫无选择地把原先已有的那个主存块替换掉，因而无须考虑替换算法。  

常用的替换算法有随机（RAND）算法、先进先出（FIFO）算法、近期最少使用（LRU）算法和最不经常使用（LFU）算法。其中最常考查的是LRU算法。  

1）随机算法：随机地确定替换的Cache行。它的实现比较简单，但未依据程序访问的局部性原理，因此可能命中率较低。2）先进先出算法：选择最早调入的Cache行进行替换。它比较容易实现，但也未依据程序访问的局部性原理，因为最早进入的主存块也可能是目前经常要用的。  

>#### pro：组相联映射中LRU算法的命中分析（2012、2021）  

3）近期最少使用算法（LRU）：依据程序访问的局部性原理，选择近期内长久未访问过的Cache行进行替换，其平均命中率要比FlFO的高，是堆栈类算法。  

>#### pro：LRU替换位及其位数的计算（2018、2020）  

LRU算法对每个Cache行设置一个计数器（也称LRU替换位），用计数值来记录主存块的使用情况，并根据计数值选择淘汰某个块，计数值的位数与Cache组大小有关，二路时有1位LRU 位，四路时有2位LRU位。假定采用四路组相联，有5个主存块 $\{1,2,3,4,5\}$ 映射到Cache的同一组，对于主存访问序列 $\{1,2,3,4,1,2,5,1,2,3,4,5\},$ 采用LRU算法的替换过程如图3.23所示。图中左边阴影的数字是对应Cache行的计数值，右边的数字是存放在该行中的主存块号。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/172e58f1cfb7469387af458dc7e49c1ea931605bc2c9081f5e57a4932c9604de.jpg)  
图3.23LRU算法的替换过程示意图  

计数器的变化规则： $\textcircled{\scriptsize{1}}$ 命中时，所命中的行的计数器清零，比其低的计数器加1，其余不变： $\circledcirc$ 未命中且还有空闲行时，新装入的行的计数器置0，其余全加1； $\textcircled{3}$ 未命中且无空闲行时，计数值为3的行的信息块被替换，新装入的行的计数器置0，其余全加1。  

当集中访问的存储区超过Cache组的大小时，命中率可能变得很低，如上例的访问序列变为 $1,2,3,4,5,1,2,3,4,5,\cdots,$ ，而Cache每组只有4行，则命中率为0，这种现象称为抖动。  

4）最不经常使用算法：将一段时间内被访问次数最少的Cache行换出。每行也设置一个计数器，新行装入后从0开始计数，每访问一次，被访问的行计数器加1，需要替换时比较各特定行的计数值，将计数值最小的行换出。这种算法与LRU类似，但不完全相同。  

## Cache的一致性问题  

因为Cache中的内容是主存块副本，当对Cache中的内容进行更新时，就需选用写操作策略使Cache内容和主存内容保持一致。此时分两种情况。  

对于Cache写操作命中（writehit），有两种处理方法。  

>#### pro：直写法的特点（2015）、直写法是否需设修改位（2020）  

1）全写法（直写法、Write-through）。当CPU对Cache写命中时，必须把数据同时写入Cache和主存。当某一块需要替换时，就不必把这一块写回主存了，用新调入的块直接覆盖即可。这种方法实现简单，能随时保持主存数据的正确性。缺点是增加了访存次数，降低了Cache的效率。写缓冲：为减少全写法直接写入主存的时间损耗，在Cache和主存之间加一个写缓冲（WriteBuffer），如下图所示。CPU同时写数据到Cache和写缓冲中，写缓冲再将内容写入主存。写缓冲是一个FO队列，写缓冲可以解决速度不匹配的问题。但若出现频繁写时，会使写缓冲饱和溢出。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f5ab311434521af2d47d204cc146f946fd1d802128ddcf2071dc6828c717e2cc.jpg)  

>#### pro：回写法的修改位（2018、2020）  

2）回写法（write-back）?。当CPU对Cache写命中时，只把数据写入Cache，而不立即写入主存，只有当此块被替换出时才写回主存。这种方法减少了访存次数，但存在数据不一致的隐惠。为了减少写回主存的次数，给每个Cache行设置一个修改位（脏位）。若修改位为1，则说明对应Cache行中的块被修改过，替换时须写回主存；若修改位为0，则 说明对应Cache行中的块未被修改过，替换时无须写回主存。  
全写法和回写法都对应于Cache写命中（要被修改的块在Cache中）时的情况。  

对于Cache写操作不命中，也有两种处理方法。  

1）写分配法（write-allocate）。更新主存单元，然后把这个主存块调入Cache。它试图利用程序的空间局部性，缺点是每次写不命中都要从主存读一个块到Cache中。  

2）非写分配法（not-write-allocate）。只更新主存单元，而不把主存块调入Cache。  

非写分配法通常与全写法合用，写分配法通常和回写法合用。  

>#### pro：  采用分离的指令Cache和数据Cache的主要目的（2014）  

随着指令流水技术的发展，需要将指令Cache和数据Cache分开设计，这就有了分离的Cache结构。统一Cache的优点是设计和实现相对简单，但由于执行部件存取数据时，指令预取部件要从同一Cache读指令，因此会引发冲突。采用分离的Cache结构可以解决这个问题，而且分离的指令和数据Cache还可以充分利用指令和数据的不同局部性来优化性能。  

现代计算机的Cache通常设立多级Cache，假定设2级Cache，按离CPU的远近可各自命名为L1Cache、L2Cache，离CPU越远，访问速度越慢，容量越大。指令Cache与数据Cache分离一般在L1级，此时通常为写分配法与回写法合用。下图是一个含有两级Cache的系统，L1Cache对L2Cache使用全写法，L2Cache对主存使用回写法，由于L2Cache的存在，其访问速度大于主存，因此避免了因频繁写时造成的写缓冲饱和溢出。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/a36a40284b9aa454bc42de878bcab6fe9160cad5f6b92ce9054bac667f2a2cf5.jpg)  
  

# 虚拟存储器  

主存和辅存共同构成了虚拟存储器，二者在硬件和系统软件的共同管理下工作。对于应用程序员而言，虚拟存储器是透明的。虚拟存储器具有主存的速度和辅存的容量。  

## 基本概念  

将主存或辅存的地址空间统一编址，形成一个庞大的地址空间，在这个空间内，用户可以自由编程，而不必在乎实际的主存容量和程序在主存中实际的存放位置。  

用户编程允许涉及的地址称为虚地址或逻辑地址，虚地址对应的存储空间称为虚拟空间或程序空间。实际的主存单元地址称为实地址或物理地址，实地址对应的是主存地址空间，也称实地址空间。虚地址比实地址要大很多。虚拟存储器的地址空间如图3.24所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3f30148f78a751f6de56c12ee740b690d95cef0f05379cb11a3386b06baf0ec8.jpg)  
图3.24虚拟存储器的三个地址空间  

CPU使用虚地址时，先判断这个虚地址对应的内容是否已装入主存。若已在主存中，则通过地址变换，CPU可直接访问主存指示的实际单元；若不在主存中，则把包含这个字的一页或一段调入主存后再由CPU访问。若主存已满，则采用替换算法置换主存中的交换块（页面）。  

>#### pro：虚拟存储器只能采用回写法的原因（2016）  

虚拟存储器也采用和Cache类似的技术，将辅存中经常访问的数据副本存放到主存中。但是缺页（或段）而访问辅存的代价很大，提高命中率是关键，因此虚拟存储机制采用全相联映射，每个虚页面可以存放到对应主存区域的任何一个空闲页位置。此外，当进行写操作时，不能每次写操作都同时写回磁盘，因而，在处理一致性问题时，采用回写法。  
## 页式虚拟存储器  

页式虚拟存储器以页为基本单位。主存空间和虚拟地址空间都被划分成相同大小的页，主存空间中的页称为物理页、实页、页框，虚拟地址空间中的页称为虚拟页、虚页。页表记录了程序的虚页调入主存时被安排在主存中的位置。页表一般长久地保存在内存中。  

### 页表  

图3.25是一个页表示例。有效位也称装入位，用来表示对应页面是否在主存，若为1，则表示该虚拟页已从外存调入主存，此时页表项存放该页的物理页号：若为0，则表示没有调入主存，此时页表项可以存放该页的磁盘地址。脏位也称修改位，用来表示页面是否被修改过，虚存机制中采用回写策略，利用脏位可判断替换时是否需要写回磁盘。引用位也称使用位，用来配合替换策略进行设置，例如是否实现最先调入（FIFO位）或最近最少用（LRU位）策略等。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/b8ab5292e69b51c36468563f144fde40a570b1a370f205fa85c05cc588cbae16.jpg)  
图3.25主存中的页表示例  

>#### pro：数组的分页存放、缺页异常分析及缺页处理过程（2014、2019、2023）  

以图3.25的页表为例，假设CPU欲访问的数据在第1页，对应的有效位为1，说明该页已存放在主存中，再通过地址转换部件将虚拟地址转换为物理地址，然后到相应的主存实页中存取数据。若该数据在第5页，有效位为0，则发生“缺页”异常，需调用操作系统的缺页异常处理程序。缺页处理程序根据对应表项中的存放位置字段，将所缺页面从磁盘调入一个空闲的物理页框。若主存中没有空闲页框，还需要选择一个页面替换。由于采用回写策略，因此换出页面时根据脏位确定是否要写回磁盘。缺页处理过程中需要对页表进行相应的更新。  

页式虚拟存储器的优点是，页面的长度固定，页表简单，调入方便。缺点是，因为程序不可能正好是页面的整数倍，最后一页的零头将无法利用而造成浪费，并且页不是逻辑上独立的实体，所以处理、保护和共享都不及段式虚拟存储器方便。  

### 地址转换  

>#### pro：虚拟地址结构的分析（2011、2019、2021）  

在虚拟存储系统中，指令给出的地址是虚拟地址，因此当CPU执行指令时，要先将虚拟地址转换为主存物理地址，才能到主存中存取指令和数据。虚拟地址分为两个字段：高位为虚页号，低位为页内偏移地址。物理地址也分为两个字段：高位为物理页号，低位为页内偏移地址。由于两者的页面大小相同，因此页内偏移地址是相等的。虚拟地址到物理地址的转换是由页表实现的，页表是一张存放在主存中的虚页号和实页号的对照表。  
>#### pro：虚拟地址主存物理地址（2011、2013、2018、2022）  

每个进程都有一个页表基址寄存器，存放该进程的页表首地址，据此找到对应的页表首地址（对应 $^\mathrm{\textregistered}$ )，然后根据虚拟地址高位的虚拟页号找到对应的页表项（对应 $\mathcal{Q}$ ），若装入位为1，则取出物理页号（对应 $\textcircled{3}$ ），和虚拟地址低位的页内地址拼接，形成实际物理地址（对应 $^{(4)}$ ）。若装入位为0，说明缺页，需要操作系统进行缺页处理。地址变换过程如图3.26所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/8abbc24dc44951166da271761d02b9beff867be6de5e5dc08cc6e6325bcebf8e.jpg)  
图3.26页式虚拟存储器的地址变换过程  

### 快表（TLB）  

由地址转换过程可知，访存时先访问一次主存去查页表，再访问主存才能取得数据。若缺页，则还要进行页面替换、页面修改等，因此采用虚拟存储机制后，访问主存的次数更多了。  

>#### pro：TLB的硬件实现（2018），TLB和Cache的比较（2020）  

依据程序访问的局部性原理，在一段时间内总是经常访问某些页时，若把这些页对应的页表项存放在高速缓冲器组成的快表（TLB）中，则可以明显提高效率。相应地把放在主存中的页表称为慢表（Page）。在地址转换时，首先查找快表，若命中，则无须访问主存中的页表。  

>#### pro：TLB映射方式、地址划分与标记字段：与Cache相同（2016、2021）  

快表用SRAM实现，其工作原理类似于Cache，通常采用全相联或组相联映射方式。TLB表项由页表表项内容和TLB标记组成。全相联映射下，TLB标记就是对应页表项的虚拟页号；组相联方式下，TLB标记则是对应虚拟页号的高位部分，而虚拟页号的低位部分作为TLB组的组号。  

### 具有TLB和Cache的多级存储系统  

图3.27是一个具有TLB和Cache的多级存储系统，其中Cache采用二路组相联方式。CPU给出一个32位的虚拟地址，TLB采用全相联方式，每一项都有一个比较器，查找时将虚页号与每个TLB标记字段同时进行比较，若有某一项相等且对应有效位为1，则TLB命中，此时可直接通过TLB进行地址转换；若未命中，则TLB缺失，需要访问主存去查页表。图中所示的是两级页表方式，虚页号被分成页目录索引和页表索引两部分，由这两部分得到对应的页表项，从而进行地址转换，并将相应表项调入TLB，若TLB已满，则还需要采用替换策略。完成由虚拟地址到物理地址的转换后，Cache机构根据映射方式将物理地址划分成多个字段，然后根据映射规则找到对应的Cache行或组，将对应Cache行中的标记与物理地址中的高位部分进行比较，若相等且对应有效位为1，则Cache命中，此时根据块内地址取出对应的字送给CPU。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/631bb0e61b3bdacef3897c62f9b2563c6e1aa46c348e5f719e87b9db2f47ed57.jpg)  
图3.27TLB和Cache的访问过程  

查找时，快表和慢表也可以同步进行，若快表中有此虚页号，则能很快地找到对应的实页号，并且使慢表的查找作废，从而就能做到虽采用虚拟存储器但访问主存速度几乎没有下降。  

>#### pro：TLB、Cache和Page缺失组合的分析（2010）  

在一个具有TLB和Cache的多级存储系统中，CPU一次访存操作可能涉及TLB、页表、Cache、主存和磁盘的访问，访问过程如图3.28所示。可见，CPU访存过程中存在三种缺失情况： $\textcircled{\scriptsize{1}}$ TLB缺失：要访问的页面的页表项不在TLB中： $\circledcirc$ Cache缺失：要访问的主存块不在Cache中： $\textcircled{3}$ Page缺失：要访问的页面不在主存中。由于TLB只是页表的一部分副本，因此Page缺失时，TLB也必然缺失。同理，Cache也只是主存的一部分副本，页表未命中意味着信息不在主存，因此Page缺失时，Cache也必然缺失。这三种缺失的可能组合情况如表3.3所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/410f211a8065de602231efcdde6fb31482045afcb7cd24653c854c6b447608e7.jpg)  
图3.28带TLB虚拟存储器的CPU访存过程  
表3.3TLB、Page、Cache三种缺失的可能组合情况
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/5449e48e05a1210c3ad8e1dda8ec750f02c257f2e7997847b56ece5d409deea7.jpg)  

最好的情况是第1种组合，此时无须访问主存；第2种和第3种组合都需要访问一次主存；第4种组合需要访问两次主存；第5种组合发生“缺页异常”，需要访问磁盘，并且至少访问两次主存。Cache缺失处理由硬件完成；缺页处理由软件完成，操作系统通过“缺页异常处理程序”来实现：而TLB缺失既可以用硬件，又可以用软件来处理。  

>##### attention：  

在《操作系统考研复习指导》的第3章中，介绍了在同时具有TLB和Cache的存储系统中虚实地址转换的实例，读者可以结合这些内容进行学习。  

## 段式虚拟存储器  

段式虚拟存储器中的段是按程序的逻辑结构划分的，各个段的长度因程序而异。把虚拟地址分为两部分：段号和段内地址。虚拟地址到实地址之间的变换是由段表来实现的。段表是程序的逻辑段和在主存中存放位置的对照表。段表的每行记录与某个段对应的段号、装入位、段起点和段长等信息。因为段的长度可变，所以段表中要给出各段的起始地址与段的长度。  

CPU根据虚拟地址访存时，首先根据段表基地址与段号拼接成对应的段表项，然后根据该段表项的装入位判断该段是否已调入主存（装入位为“1”，表示该段已调入主存；装入位为“0”表示该段不在主存中）。已调入主存时，从段表读出该段在主存中的起始地址，与段内地址（偏移量）相加，得到对应的主存实地址。段式虚拟存储器的地址变换过程如图3.29所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/1b0fa6804dac3b58468ab24b6f02dbc573bbcb4d48f2326802894513dae0c641.jpg)  
图3.29段式虚拟存储器的地址变换过程  

因为段本身是程序的逻辑结构所决定的一些独立部分，因而分段对程序员来说是不透明的：而分页对程序员来说是透明的，程序员编写程序时不需知道程序将如何分页。  

段式虚拟存储器的优点是，段的分界与程序的自然分界相对应，因而具有逻辑独立性，使得它易于编译、管理、修改和保护，也便于多道程序的共享；缺点是因为段长度可变，分配空间不便，容易在段间留下碎片，不好利用，造成浪费。  
## 段页式虚拟存储器  

在段页式虚拟存储器中，把程序按逻辑结构分段，每段再划分为固定大小的页，主存空间也划分为大小相等的页，程序对主存的调入、调出仍以页为基本交换单位。每个程序对应一个段表，每段对应一个页表，段的长度必须是页长的整数倍，段的起点必须是某一页的起点。  

虚地址分为段号、段内页号、页内地址三部分。CPU根据虚地址访存时，首先根据段号得到段表地址；然后从段表中取出该段的页表起始地址，与虚地址段内页号合成，得到页表地址；最后从页表中取出实页号，与页内地址拼接形成主存实地址。  

段页式虚拟存储器的优点是，兼具页式和段式虚拟存储器的优点，可以按段实现共享和保护。缺点是在地址变换过程中需要两次查表，系统开销较大。  

## 虚拟存储器与Cache的比较  

虚拟存储器与Cache既有很多相同之处，又有很多不同之处。  

### 相同之处  

1）最终目标都是为了提高系统性能，两者都有容量、速度、价格的梯度。2）都把数据划分为小信息块，并作为基本的交换单位，虚存系统的信息块更大3）都有地址映射、替换算法、更新策略等问题。4）都依据局部性原理应用“快速缓存”的思想，将活跃的数据放在相对高速的部件中。  

### 不同之处  

1）Cache主要解决系统速度，而虚拟存储器却是为了解决主存容量。  

2）Cache全由硬件实现，是硬件存储器，对所有程序员透明；而虚拟存储器由OS和硬件共同实现，是逻辑上的存储器，对系统程序员不透明，但对应用程序员透明。  

>#### pro：Cache缺失和缺页的处理开销对比（2016）  

3）对于不命中性能影响，因为CPU的速度约为Cache的10倍，主存的速度为硬盘的100倍以上，因此虚拟存储器系统不命中时对系统性能影响更大。  

4）CPU与Cache和主存都建立了直接访问的通路，而辅存与CPU没有直接通路。也就是说在Cache不命中时主存能和CPU直接通信，同时将数据调入Cache；而虚拟存储器系统不命中时，只能先由硬盘调入主存，而不能直接和CPU通信。  
 



# 本章小结  
 

1）存储器系统为何要分这些层次？计算机如何管理这些层次？  

Cache-主存层在存储系统中主要对CPU访存起加速作用，即从整体运行的效果看，CPU访存速度加快，接近于Cache的速度，而寻址空间和位价却接近于主存。主存-辅存层在存储系统中主要起扩容作用，即从程序员的角度看，他所使用的存储器的容量和位价接近于辅存，而速度接近于主存。因此从整个存储系统来看，就达到了速度快、容量大、位价低的效果。  

主存与Cache之间的信息调度全部由硬件自动完成。而主存与辅存的信息调度则采用虚拟存储技术实现，即将主存与辅存的一部分通过软/硬结合的技术组成虚拟存储器，程序员可用这个比主存实际空间（物理地址空间）大得多的虚拟地址空间（逻辑地址空间）编程，当程序运行时，再由软/硬件自动配合完成虚拟地址空间与主存实际物理空间的转换。  

2.影响Cache性能的因素有哪些？  

决定Cache系统访存效率重要因素是命中率，它与很多因素有关。1）命中率与映射方式有关，全相联映射方式的命中率最高，直接映射方式的命中率最低。2）命中率与Cache容量有关，显然Cache容量越大，命中率就越高。3）命中率还与主存块（或Cache行）的大小有关，主存块的大小要适中。  
除上述因素外，系统是采用单级还是采用多级Cache，数据Cache和指令Cache是分离还是合在一起，主存-总线-Cache-CPU之间采用什么架构等，都会影响Cache的总体性能。  

3）虚拟存储系统的页面是设置得大一些好还是设置得小一些好？  

页面大小要适中。页面太小时，平均页内剩余空间较小，可节省存储空间，但会使得页表增大，页面太小时也不能充分利用空间局部性来提高命中率：页面太大时，可减少页表空间，但平均页内剩余空间较大，会浪费较多存储空间，页面太大还会使页面调入/调出的时间较长。  

# 常见问题和易混淆知识点  

- 1.Cache行的大小和命中率之间有什么关系？  

Cache行的长度较大时，能充分利用程序访问的空间局部性，使一个较大的局部空间被一起调到Cache中，因而可以增加命中机会。但是，行长也不能太大，主要原因有两个：  

1）行长大使失效损失变大。也就是说，若未命中，则需花更多时间从主存读块。  

2）行长太大，Cache项数变少，因而命中的可能性变小。  

Cache行的长度较小时，命中率会很低，但好处是存取块的代价较小。  

- 2.发生取指令Cache缺失的处理过程是什么？  

1）程序计数器恢复当前指令的值。  

2）对主存进行读的操作。  

3）将读入的指令写入Cache中，更改有效位和标记位。  

4）重新执行当前指令。  

- 3.Cache总容量与映射方式有何种关系？  

Cache总容量 $=$ [每个Cache行标记项的容量（有效位、脏位、LRU替换位、标记位）+Cache行长xCache总行数。其中，有效位和标记位是所有Cache所必需的；脏位只在Cache采用回写法时才需要设置；LRU替换位只在Cache采用LRU替换算法时才需要设置。  

有效位：占1位，用于说明Cache行中的数据是否有效。脏位（修改位）：占1位，回写法才需要设置，用以说明Cache行中的数据是否被修改过。LRU替换位：位数为 $\log_{2}($ 组内块数），用于LRU替换算法中的访问计数。  

标记位Tag：主存地址结构中的标记字段，其位数取决于所用的映射方式，用于匹配Cache行对应主存中的哪个块。  

Cache容量与映射方式的具体关系如图3.30所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/77d74c7bc0a8fc408aa68057edb2cbdd1c424abbf65fd57e9f4d982659723d0b.jpg)  