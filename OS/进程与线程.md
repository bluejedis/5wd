# above 

## 【考纲内容】  

（一）进程与线程  

进程与线程的基本概念：进程/线程的状态与转换线程的实现：内核支持的线程，线程库支持的线程进程与线程的组织与控制进程间通信：共享内存，消息传递，管道  

（二）CPU调度与上下文切换  

调度的基本概念：调度的目标：调度的实现：调度器/调度程序（scheduler），调度的时机与调度方式（抢占式/非抢占式），闲逛进程，内核级线程与用户级线程调度典型调度算法：先来先服务调度算法：短作业（短进程、短线程）优先调度算法，时间片轮转调度算法，优先级调度算法，高响应比优先调度算法，多级队列调度算法，多级反馈队列调度算法  

上下文及其切换机制  

（三）同步与互斤  

同步与互斥的基本概念  

基本的实现方法：软件方法；硬件方法  

锁；信号量；条件变量  

经典同步问题：生产者-消费者问题，读者-写者问题：哲学家进餐问题  

（四）死锁  

死锁的基本概念：死锁预防死锁避免：死锁检测和解除  

## 【复习提示】  

进程管理是操作系统的核心，也是每年必考的重点。其中，进程的概念、进程调度、信号量机制实现同步和互斥、进程死锁等更是重中之重，必须深入掌握。需要注意的是，除选择题外，本章还容易出综合题，其中信号量机制实现同步和互厅、进程调度算法和死锁等都可能命制综合题，如利用信号量进行进程同步就在往年的统考中频繁出现。  

# 进程与线程  

在学习本节时，请读者思考以下问题：  
1）为什么要引入进程？2）什么是进程？进程由什么组成？  

3）进程是如何解决问题的？  

希望读者带着上述问题去学习本节内容，并在学习的过程中多思考，从而更深入地理解本节内容。进程本身是一个比较抽象的概念，它不是实物，看不见、摸不看，初学者在理解进程概念时存在一定困难，在介绍完进程的相关知识后，我们会用比较直观的例子帮助大家理解。  

## 概念和特征  

### 进程的概念  

在多道程序环境下，允许多个程序并发执行，此时它们将失去封闭性，并具有间断性及不可再现性的特征。为此引入了进程（Process）的概念，以便更好地描述和控制程序的并发执行，实现操作系统的并发性和共享性（最基本的两个特性）。  

为了使参与并发执行的每个程序（含数据）都能独立地运行，必须为之配置一个专门的数据结构，称为进程控制块（ProcessControlBlock，PCB）。系统利用PCB来描述进程的基本情况和运行状态，进而控制和管理进程。相应地，由程序段、相关数据段和PCB三部分构成了进程实体（又称进程映像）。所谓创建进程，就是创建进程的PCB；而撤销进程，就是撤销进程的PCB。  

从不同的角度，进程可以有不同的定义，比较典型的定义有：  

1）进程是一个正在执行程序的实例。  

2）进程是一个程序及其数据从磁盘加载到内存后，在CPU上的执行过程。3）进程是一个具有独立功能的程序在一个数据集合上运行的过程。引入进程实体的概念后，我们可将传统操作系统中的进程定义为：“进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。”读者要准确理解这里说的系统资源。它指CPU、存储器和其他设备服务于某个进程的“时间”，例如将CPU资源理解为CPU的时间片才是准确的。因为进程是这些资源分配和调度的独立单位，即“时间片”分配的独立单位，这就决定了进程一定是一个动态的、过程性的概念。  

### 进程的特征  

进程是由多道程序的并发执行而引出的，它和程序是两个截然不同的概念。程序是静态的，进程是动态的，进程的基本特征是对比单个程序的顺序执行提出的。  

1）动态性。进程是程序的一次执行，它有着创建、活动、暂停、终止等过程，具有一定的生命周期，是动态地产生、变化和消亡的。动态性是进程最基本的特征。2）并发性。指多个进程同存于内存中，能在一段时间内同时运行。引入进程的目的就是使进程能和其他进程并发执行。并发性是进程的重要特征，也是操作系统的重要特征。3）独立性。指进程是一个能独立运行、独立获得资源和独立接受调度的基本单位。凡未建立PCB的程序，都不能作为一个独立的单位参与运行。4）异步性。由于进程的相互制约，使得进程按各自独立的、不可预知的速度向前推进。异步性会导致执行结果的不可再现性，为此在操作系统中必须配置相应的进程同步机制。通常不会直接考查进程有什么特性，所以读者对上面的4个特性不必记忆，只求理解。  

## 组成  

进程是一个独立的运行单位，也是操作系统进行资源分配和调度的基本单位。它由以下三部分组成，其中最核心的是进程控制块（PCB）。  
### 进程控制块  

进程创建时，操作系统为它新建一个PCB，该结构之后常驻内存，任意时刻都可以存取，并在进程结束时删除。PCB是进程实体的一部分，是进程存在的唯一标志。  

进程执行时，系统通过其PCB了解进程的现行状态信息，以便操作系统对其进行控制和管理；进程结束时，系统收回其PCB，该进程随之消亡。  

当操作系统希望调度某个进程运行时，要从该进程的PCB中查出其现行状态及优先级；在调度到某个进程后，要根据其PCB中所保存的CPU状态信息，设置该进程恢复运行的现场，并根据其PCB中的程序和数据的内存始址，找到其程序和数据：进程在运行过程中，当需要和与之合作的进程实现同步、通信或访问文件时，也需要访问PCB；当进程由于某种原因而暂停运行时，又需将其断点的CPU环境保存在PCB中。可见，在进程的整个生命期中，系统总是通过PCB对进程进行控制的，亦即系统唯有通过进程的PCB才能感知到该进程的存在。  

表2.1是一个PCB的实例。PCB主要包括进程描述信息、进程控制和管理信息、资源分配清单和CPU相关信息等。各部分的主要说明如下：  

表2.1PCB通常包含的内容
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/40c9fe37acec0dc1358828cc24c82b9fbaff9608f1d593f7c1605e5a6ae8ff94.jpg)  

1）进程描述信息。进程标识符：标志各个进程，每个进程都有一个唯一的标识号。用户标识符：进程所归属的用户，用户标识符主要为共享和保护服务。  

2）进程控制和管理信息。进程当前状态：描述进程的状态信息，作为CPU分配调度的依据。进程优先级：描述进程抢占CPU的优先级，优先级高的进程可优先获得CPU。  

3）资源分配清单，用于说明有关内存地址空间或虚拟地址空间的状况，所打开文件的列表和所使用的输入/输出设备信息。  

4）处理机相关信息，也称CPU的上下文，主要指CPU中各寄存器的值。当进程处于执行态时，CPU的许多信息都在寄存器中。当进程被切换时，CPU状态信息都必须保存在相应的PCB中，以便在该进程重新执行时，能从断点继续执行。  

在一个系统中，通常存在着许多进程的PCB，有的处于就绪态，有的处于阻塞态，而且阻塞的原因各不相同。为了方便进程的调度和管理，需要将各个进程的PCB用适当的方法组织起来。目前，常用的组织方式有链接方式和索引方式两种。链接方式将同一状态的PCB链接成一个队列，不同状态对应不同的队列，也可将处于阻塞态的进程的PCB，根据其阻塞原因的不同，排成多个阻塞队列。索引方式将同一状态的进程组织在一个索引表中，索引表的表项指向相应的PCB，不同状态对应不同的索引表，如就绪索引表和阻塞索引表等。  

### 程序段  

程序段就是能被进程调度程序调度到CPU执行的程序代码段。注意，程序可被多个进程共享，即多个进程可以运行同一个程序。  
### 数据段  

一个进程的数据段，可以是进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间或最终结果。  

## 进程的状态与转换  

进程在其生命周期内，由于系统中各个进程之间的相互制约及系统的运行环境的变化，使得进程的状态也在不断地发生变化。通常进程有以下5种状态，前3种是进程的基本状态。  

1）运行态。进程正在CPU上运行。在单CPU中，每个时刻只有一个进程处于运行态。  

2）就绪态。进程获得了除CPU外的一切所需资源，一旦得到CPU，便可立即运行。系统中处于就绪态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。  

>#### pro：执行中断处理程序时进程的状态（2023）  

3）阻塞态，又称等待态。进程正在等待某一事件而暂停运行，如等待某个资源可用（不包括CPU）或等待I/O完成。即使CPU空闲，该进程也不能运行。系统通常将处于阻塞态的进程也排成一个队列，甚至根据阻塞原因的不同，设置多个阻塞队列。4）创建态。进程正在被创建，尚未转到就绪态。创建进程需要多个步骤：首先申请一个空白PCB，并向PCB中填写用于控制和管理进程的信息：然后为该进程分配运行时所必须的资源；最后将该进程转入就绪态并插入就绪队列。但是，如果进程所需的资源尚不能得到满足，如内存不足，则创建工作尚未完成，进程此时所处的状态称为创建态。5）终止态。进程正从系统中消失，可能是进程正常结束或其他原因退出运行。进程需要结束运行时，系统首先将该进程置为终止态，然后进一步处理资源释放和回收等工作。  

区别就绪态和阻塞态：就绪态是指进程仅缺少CPU，只要获得CPU就立即运行：而阻塞 态是指进程需要其他资源（除了CPU）或等待某一事件。之所以将CPU和其他资源分开，是因为在分时系统的时间片轮转机制中，每个进程分到的时间片是若干毫秒。也就是说，进程得到CPU的时间很短且非常频繁，进程在运行过程中实际上是频繁地转换到就绪态的；而其他资源（如外设）的使用和分配或某一事件的发生（如I/O完成）对应的时间相对来说很长，进程转换到阻塞态的次数也相对较少。这样来看，就绪态和阻塞态是进程生命周期中两个完全不同的状态。  

>#### pro：引起进程状态转换的事件（2014、2015、2018、2023）  

图2.1说明了5种进程状态的转换，而3种基本状态之间的转换如下：  

就绪态→运行态：处于就绪态的进程被调度后，获得CPU资源（分派CPU的时间片），于是进程由就绪态转换为运行态。 ·运行态→就绪态：处于运行态的进程在时间片用完后，不得不让出CPU，从而进程由运行态转换为就绪态。此外，在可剥夺的操作系统中，当有更高优先级的进程就绪时，调度程序将正在执行的进程转换为就绪态，让更高优先级的进程执行。·运行态一阻塞态：进程请求某一资源（如外设）的使用和分配或等待某一事件的发生（如I/0操作的完成）时，它就从运行态转换为阻塞态。进程以系统调用的形式请求操作系统提供服务，这是一种特殊的、由运行用户态程序调用操作系统内核过程的形式。）阻塞态→就绪态：进程等待的事件到来时，如I/O操作完成或中断结束时，中断处理程序必须将相应进程的状态由阻塞态转换为就绪态。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/2796d43857bddecd8eca8a18aecf8570c278e84dba5e8cfb5c23a1843cc5dc7b.jpg)  
图2.15种进程状态的转换  

需要注意的是，一个进程从运行态变为阻塞态是主动的行为，而从阻塞态变为就绪态是被动的行为，需要其他相关进程的协助。  

## 进程控制  

进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。在操作系统中，一般将进程控制用的程序段称为原语，原语的特点是执行期间不允许中断，它是一个不可分割的基本单位。  

### 进程的创建  

>#### pro：父进程与子进程的关系和特点（2020）  

允许一个进程创建另一个进程，此时创建者称为父进程，被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。当子进程被撤销时，应将其从父进程那里获得的资源还给父进程。此外，在撤销父进程时，通常也会同时撤销其所有的子进程。  

>#### pro：导致创建进程的操作（2010）  

在操作系统中，终端用户登录系统、作业调度、系统提供服务、用户程序的应用请求等都会引起进程的创建。操作系统创建一个新进程的过程如下（创建原语）：  

>#### pro：创建新进程时的操作（2021）  

1）为新进程分配一个唯一的进程标识号，并申请一个空白PCB（PCB是有限的）。若PCB申请失败，则创建失败。2）为进程分配其运行所需的资源，如内存、文件、I/O设备和CPU时间等（在PCB中体现）。这些资源或从操作系统获得，或仅从其父进程获得。如果资源不足（如内存），则并不是创建失败，而是处于创建态，等待内存资源。3）初始化PCB，主要包括初始化标志信息、初始化CPU状态信息和初始化CPU控制信息，以及设置进程的优先级等。4）若进程就绪队列能够接纳新进程，则将新进程插入就绪队列，等待被调度运行。  

### 进程的终止  

引起进程终止的事件主要有： $\textcircled{\scriptsize{1}}$ 正常结束，表示进程的任务已完成并准备退出运行。 $\circledast$ 异常结束，表示进程在运行时，发生了某种异常事件，使程序无法继续运行，如存储区越界、保护错、非法指令、特权指令错、运行超时、算术运算错、I/O敌障等。  $\textcircled{3}$  外界干预，指进程应外界的请 求而终止运行，如操作员或操作系统干预、父进程请求和父进程终止。  

>#### pro：终止进程时的操作（2024）  

操作系统终止进程的过程如下（终止原语）：  

1）根据被终止进程的标识符，检索出该进程的PCB，从中读出该进程的状态。2）若被终止进程处于运行状态，立即终正该进程的执行，将CPU资源分配给其他进程。3）若该进程还有子孙进程，则通常需将其所有子孙进程终止（有些系统无此要求）。  
4）将该进程所拥有的全部资源，或归还给其父进程，或归还给操作系统。5）将该PCB从所在队列（链表）中删除。  

### 进程的阻塞和唤醒  

>#### pro：  

>#### pro：   I/O事件阻塞或唤醒进程的过程（2023）  

进程阻塞的事件与时机（2018、2022、2023）  

正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新任务可做等，进程便通过调用阻塞原语（Block），使自己由运行态变为阻塞态。可见，阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞态。阻塞原语的执行过程如下：  

1）找到将要被阻塞进程的标识号（PID）对应的PCB。2）若该进程为运行态，则保护其现场，将其状态转为阻塞态，停止运行。3）将该PCB插入相应事件的等待队列，将CPU资源调度给其他就绪进程。  

>#### pro：进程唤醒的事件与时机（2014、2019）  

当被阻塞进程所期待的事件出现时，如它所期待的1/0操作已完成或其所期待的数据已到达，由有关进程（比如，释放该I/O设备的进程，或提供数据的进程）调用唤醒原语（Wakeup），将等待该事件的进程唤醒。唤醒原语的执行过程如下：  

1）在该事件的等待队列中找到相应进程的PCB。2）将其从等待队列中移出，并置其状态为就绪态。3）将该PCB插入就绪队列，等待调度程序调度。  

应当注意，Block原语和Wakeup原语是一对作用刚好相反的原语，必须成对使用。如果在某个进程中调用了Block原语，则必须在与之合作的或其他相关的进程中安排一条相应的Wakeup 原语，以便唤醒阻塞进程；否则，阻塞进程将因不能被唤醒而永久地处于阻塞态。  

## 进程的通信  

进程通信是指进程之间的信息交换。PV操作（见2.3节）是低级通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方法主要有以下三类。  

### 共享存储  

在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行写/读操作实现进程之间的信息交换，如图2.2所示。在对共享空间进行写/读操作时，需要使用同步互斥工具（如P操作、V操作）对共享空间的写/读进行控制。共享存储又分为两种：低级方式的共享是基于数据结构的共享：高级方式的共享则是基于存储区的共享。操作系统只负责为通信进程提供可共享使用的存储空间和同步互房工具，而数据交换则由用户自已安排读/写指令完成。  

注意，进程空间一般都是独立的，进程运行期间一般不能访问其他进程的空间，想让两个进程共享空间，必须通过特殊的系统调用实现，而进程内的线程是自然共享进程空间的。  

简单理解就是，申和乙中间有一个大布袋，申和乙交换物品是通过大布袋进行的，申将物品放在大布袋里，乙拿走。但乙不能直接到甲的手中拿东西，甲也不能直接到乙的手中拿东西。  

### 消息传递  

若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方法实现进程通信。在消息传递系统中，进程间的数据交换以格式化的消息（Message）为单位。进程通过操作系统提供的发送消息和接收消息两个原语进行数据交换。这种方式隐藏了通信实现细节，使通信过程对用户透明，简化了通信程序的设计，是当前应用最广泛的进程间通信机制。在微内核操作系统中，微内核与服务器之间的通信就采用了消息传递机制。由于该机制能很好地支持多CPU系统、分布式系统和计算机网络，因此也成为这些领域最主要的通信工具。  
1）直接通信方式。发送进程直接将消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息，如图2.3所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/4e378c14db3ecaf63a9189b82896c975963663cfed48df20335663062fd6dff2.jpg)  

这种中间实体一般称为信箱。该通信方式广泛应用于计算机网络中。  

简单理解就是，甲要将某些事情告诉乙，就要写信，然后通过邮差送给乙。直接通信就是邮差将信直接送到乙的手上：间接通信就是乙家门口有一个邮箱，邮差将信放到邮箱里。  

### 管道通信  

>#### pro：管道通信的特点（2014）  

管道是一个特殊的共享文件，又称pipe文件，数据在管道中是先进先出的。管道通信允许两个进程按生产者-消费者方式进行通信（见图2.4），只要管道不满，写进程就能向管道的一端写入数据；只要管道非空，读进程就能从管道的一端读出数据。为了协调双方的通信，管道机制必须提供三方面的协调能力： $\textcircled{\scriptsize{1}}$ 互斥，指当一个进程对管道进行读/写操作时，其他进程必须等待。 $\circledcirc$ 同步，指写进程向管道写入一定数量的数据后，写进程阻塞，直到读进程取走数据后再将它唤醒：读进程将管道中的数据取空后，读进程阻塞，直到写进程将数据写人管道后才将其唤醒。 $\textcircled{3}$ 确定对方的存在。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/0aa0d9d676a835dc9a42cff1fc91636ab53c2ace9cbc0f3c38960a43f226917a.jpg)  
图2.4管道通信  

在Linux中，管道是一种使用非常频繁的通信机制。从本质上说，管道也是一种文件，但它又和一般的文件有所不同，管道可以克服使用文件进行通信的两个问题，具体表现如下：  

1）限制管道的大小。管道文件是一个固定大小的缓冲区，在Linux中该缓冲区的大小为4KB，这使得它的大小不像普通文件那样不加检验地增长。使用单个固定缓冲区也会带来问题，比如在写管道时可能变满，这种情况发生时，随后对管道的writeO调用将默认地被阻塞，等待某些数据被读取，以便腾出足够的空间供write（O调用。  

2）读进程也可能工作得比写进程快。当管道内的数据已被读取时，管道变空。当这种情况发生时，一个随后的read（调用将被阻塞，等待某些数据的写入。  

管道只能由创建进程所访问，当父进程创建一个管道后，由于管道是一种特殊文件，子进程会继承父进程的打开文件，因此子进程也继承父进程的管道，并可用它来与父进程进行通信。  

>##### attention：  

从管道读数据是一次性操作，数据一旦被读取，就释放空间以使写更多数据。普通管道只允许单向通信，若要实现两个进程双向通信，则需要定义两个管道。  
## 线程和多线程模型  

### 线程的基本概念  

引入进程的目的是更好地使多道程序并发执行，提高资源利用率和系统吞吐量；而引入线程（Threads）的目的则是减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能。  

线程最直接的理解就是轻量级进程，它是一个基本的CPU执行单元，也是程序执行流的最小单元，由线程ID、程序计数器、寄存器集合和堆栈组成。线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的全部资源。一个线程可以创建和撤销另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。线程也有就绪、阻塞和运行三种基本状态。  

引入线程后，进程的内涵发生了改变，进程只作为除CPU外的系统资源的分配单元，而线程则作为CPU的分配单元。由于一个进程内部有多个线程，若线程的切换发生在同一个进程内部，则只需要很少的时空开销。下面从几个方面对线程和进程进行比较。  

### 线程与进程的比较  

>#### pro：进程和线程的比较（2012）  

1）调度。在传统的操作系统中，拥有资源和独立调度的基本单位都是进程，每次调度都要进行上下文切换，开销较大。在引入线程的操作系统中，线程是独立调度的基本单位，而线程切换的代价远低于进程。在同一进程中，线程的切换不会引起进程切换。但从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。2）并发性。在引入线程的操作系统中，不仅进程之间可以并发执行，而且一个进程中的多个线程之间亦可并发执行，甚至不同进程中的线程也能并发执行，从而使操作系统具有更好的并发性，提高了系统资源的利用率和系统的吞吐量。3）拥有资源。进程是系统中拥有资源的基本单位，而线程不拥有系统资源（仅有一点必不可少、能保证独立运行的资源），但线程可以访问其隶属进程的系统资源，这主要表现在属于同一进程的所有线程都具有相同的地址空间。要知道，若线程也是拥有资源的单位，则切换线程就需要较大的时空开销，线程这个概念的提出就没有意义。4）独立性。每个进程都拥有独立的地址空间和资源，除了共享全局变量，不充许其他进程访问。某个进程中的线程对其他进程不可见。同一进程中的不同线程是为了提高并发性及进行相互之间的合作而创建的，它们共享进程的地址空间和资源。5）系统开销。在创建或撤销进程时，系统都要为之分配或回收进程控制块PCB及其他资源，如内存空间、1/O设备等。操作系统为此所付出的开销，明显大于创建或撤销线程时的开销。类似地，在进程切换时涉及进程上下文的切换，而线程切换时只需保存和设置少量寄存器内容，开销很小。此外，由于同一进程内的多个线程共享进程的地址空间，因此这些线程之间的同步与通信非常容易实现，甚至无须操作系统的干预。6）支持多处理器系统。对于传统单线程进程，不管有多少个CPU，进程只能运行在一个CPU上。对于多线程进程，可将进程中的多个线程分配到多个CPU上执行。  

### 线程的属性  

多线程操作系统中的进程已不再是一个基本的执行实体，但它仍具有与执行相关的状态。所谓进程处于“执行”状态，实际上是指该进程中的线程正在执行。线程的主要属性如下：  
>#### pro：线程所拥有资源的特点（2011、2024）  

1）线程是一个轻型实体，它不拥有系统资源，但每个线程都应有一个唯一的标识符和一个线程控制块，线程控制块记录线程执行的寄存器和栈等现场状态。  

2）不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统将它们创建成不同的线程。  

3）同一进程中的各个线程共享该进程所拥有的资源。  

4）线程是CPU的独立调度单位，多个线程是可以并发执行的。在单CPU的计算机系统中，各线程可交替地占用CPU；在多CPU的计算机系统中，各线程可同时占用不同的CPU，若各个CPU同时为一个进程内的各线程服务，则可缩短进程的处理时间。5）一个线程被创建后，便开始了它的生命周期，直至终止。线程在生命周期内会经历阻塞态、就绪态和运行态等各种状态变化。  

为什么线程的提出有利于提高系统并发性？可以这样来理解：由于有了线程，线程切换时，有可能会发生进程切换，也有可能不发生进程切换，平均而言每次切换所需的开销就变小了，因此能够让更多的线程参与并发，而不会影响到响应时间等问题。  

### 线程的状态与转换  

与进程一样，各线程之间也存在共享资源和相互合作的制约关系，致使线程在运行时也具有间断性。相应地，线程在运行时也具有下面三种基本状态。  

执行态：线程已获得CPU而正在运行。  

就绪态：线程已具备各种执行条件，只需再获得CPU便可立即执行。  

阻塞态：线程在执行中因某事件受阻而处于暂停状态。线程这三种基本状态之间的转换和进程基本状态之间的转换是一样的。  

### 线程的组织与控制  

#### 线程控制块  

>#### pro：线程的组织（2019、2024）  

与进程类似，系统也为每个线程配置一个线程控制块TCB，用于记录控制和管理线程的信息。线程控制块通常包括： $\textcircled{\scriptsize{1}}$ 线程标识符： $\circledcirc$ 一组寄存器，包括程序计数器、状态寄存器和通用寄存器： $\textcircled{3}$ 线程运行状态，用于描述线程正处于何种状态： $\textcircled{4}$ 优先级： $\circledast$ 线程专有存储区，线程切换时用于保存现场等： $\textcircled{6}$ 堆栈指针，用于过程调用时保存局部变量及返回地址等。  

同一进程中的所有线程都完全共享进程的地址空间和全局变量。各个线程都可以访问进程地址空间的每个单元，所以一个线程可以读、写或甚至清除另一个线程的堆栈。  

#### 线程的创建  

线程也是具有生命期的，它由创建而产生，由调度而执行，由终止而消亡。相应地，在操作系统中就有用于创建线程和终止线程的函数（或系统调用）。  

用户程序启动时，通常仅有一个称为初始化线程的线程正在执行，其主要功能是用于创建新线程。在创建新线程时，需要利用一个线程创建函数，并提供相应的参数，如指向线程主程序的入口指针、堆栈的大小、线程优先级等。线程创建函数执行完后，将返回一个线程标识符。  

#### 线程的终止  

当一个线程完成自己的任务后，或线程在运行中出现异常而要被强制终止时，由终止线程调用相应的函数执行终止操作。但是有些线程（主要是系统线程）一旦被建立，便一直运行而不会被终止。通常，线程被终止后并不立即释放它所占有的资源，只有当进程中的其他线程执行了分离函数后，被终止线程才与资源分离，此时的资源才能被其他线程利用。  
被终止但尚未释放资源的线程仍可被其他线程调用，以使被终止线程重新恢复运行。  

### 线程的实现方式  

>#### pro: 两种线程的特点与比较（2019）  

用户级线程（User-Level Thread，ULT）和内核级线程（Kermel-LevelThread，KLT)。内核级线程又称内核支持的线程。  

#### 用户级线程（ULT）  

通俗地说，用户级线程就是“从用户视角能看到的线程”。在用户级线程中，有关线程管理（创建、撤销和切换等）的所有工作都由应用程序在用户空间内（用户态）完成，无须操作系统干预，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。通常，应用程序从单线程开始，在该线程中开始运行，在其运行的任何时刻，可以通过调用线程库中的派生例程创建一个在相同进程中运行的新线程。图2.5（a)说明了用户级线程的实现方式。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/53a12e70cc68896b3ad08729bf6efe7fb0936d9f8fc50ad5a1dfe89b5862053c.jpg)  
图2.5用户级线程和内核级线程  

对于设置了用户级线程的系统，其调度仍然以进程为单位进行，各个进程轮流执行一个时间片。假设进程A包含1个用户级线程，进程B包含100个用户级线程，这样，进程A中线程的运行时间将是进程B中各线程运行时间的100倍，因此对线程来说实质上是不公平的。  

这种实现方式的优点如下： $\textcircled{\scriptsize{1}}$ 线程切换不需要转换到内核空间，节省了模式切换的开销。 $\circledcirc$ 调度算法可以是进程专用的，不同的进程可根据自身的需要，对自己的线程选择不同的调度算法。 $\textcircled{3}$ 用户级线程的实现与操作系统平台无关，对线程管理的代码是属于用户程序的一部分。  

这种实现方式的缺点如下： $\textcircled{\scriptsize{1}}$ 系统调用的阻塞问题，当线程执行一个系统调用时，不仅该线程被阻塞，而且进程内的所有线程都被阻塞。 $\circledcirc$ 不能发挥多CPU的优势，内核每次分配给一个进程的仅有一个CPU，因此进程中仅有一个线程能执行。  

#### 内核级线程（KLT）  

在操作系统中，无论是系统进程还是用户进程，都是在操作系统内核的支持下运行的，与内核紧密相关。内核级线程同样也是在内核的支持下运行的，线程管理的所有工作也是在内核空间内（核心态）实现的。操作系统也为每个内核级线程设置一个线程控制块TCB，内核根据该控制块感知某线程的存在，并对其加以控制。图2.5(b)说明了内核级线程的实现方式。  
这种实现方式的优点如下： $\textcircled{\scriptsize{1}}$ 能发挥多CPU的优势，内核能同时调度同一进程中的多个线程并行执行。 $\circledcirc$ 如果进程中的一个线程被阻塞，内核可以调度该进程中的其他线程占用CPU，也可运行其他进程中的线程。 $\textcircled{3}$ 内核支持线程具有很小的数据结构和堆栈，线程切换比较快、开销小。 $\textcircled{4}$ 内核本身也可采用多线程技术，可以提高系统的执行速度和效率。  

这种实现方式的缺点如下：同一进程中的线程切换，需要从用户态转到核心态进行，系统升销较大。这是因为用户进程的线程在用户态运行，而线程调度和管理是在内核实现的。  

#### 组合方式  

有些系统使用组合方式的多线程实现。在组合实现方式中，内核支持多个内核级线程的建立、调度和管理，同时充许用户程序建立、调度和管理用户级线程。一些内核级线程对应多个用户级线程，这是用户级线程通过时分多路复用内核级线程实现的。同一进程中的多个线程可以同时在多CPU上并行执行，且在阻塞一个线程时不需要将整个进程阻塞，所以组合方式能结合KLT和ULT的优点，并且克服各自的不足。图2.5（c展示了这种组合实现方式。  

在线程实现方式的介绍中，提到了通过线程库来创建和管理线程。线程库（threadlibrary）是为程序员提供创建和管理线程的API。实现线程库主要的方法有如下两种：  

$\textcircled{\scriptsize{1}}$ 在用户空间中提供一个没有内核支持的库。这种库的所有代码和数据结构都位于用户空间中。这意味着，调用库内的一个函数只导致用户空间中的一个本地函数的调用。  

$\textcircled{2}$ 实现由操作系统直接支持的内核级的一个库。对于这种情况，库内的代码和数据结构位于内核空间。调用库中的一个API函数通常会导致对内核的系统调用。  

：POSIX P threads、WindowsAPI、Java。P threads POSIX标准的扩展，可以提供用户级或内核级的库。WindowsAPI是用于Windows系统的内核级线程库。Java线程API允许线程在Java程序中直接创建和管理。由于JVM实例通常运行在宿主操作系统之上，Java线程API通常采用宿主系统的线程库来实现，因此在Windows系统中Java线程通常Windows API，UNIX P threads。  

### 多线程模型  

在同时支持用户级线程和内核级线程的系统中，由于用户级线程和内核级线程连接方式的不同，从而形成了下面三种不同的多线程模型。  

1）多对一模型。将多个用户级线程映射到一个内核级线程，如图2.6(a)所示。每个进程只被分配一个内核级线程，线程的调度和管理在用户空间完成。仅当用户线程需要访问内核时，才将其映射到一个内核级线程上，但每次只允许一个线程进行映射。优点：线程管理是在用户空间进行的，无须切换到核心态，因而效率比较高。缺点：如果一个线程在访问内核时发生阻塞，则整个进程都会被阻塞；在任何时刻，只有一个线程能够访问内核，多个线程不能同时在多个CPU上运行。2）一对一模型。将每个用户级线程映射到一个内核级线程，如图2.6(b)所示。每个进程有与用户级线程数量相同的内核级线程，线程切换由内核完成，需要切换到核心态。优点：当一个线程被阻塞后，允许调度另一个线程运行，所以并发能力较强。缺点：每创建一个用户线程，相应地就需要创建一个内核线程，开销较大。  

3）多对多模型。将 $n$ 个用户级线程映射到 $m$ 个内核级线程上，要求 $_{n\geqslant m}$ ，如图2.6（c）所示。特点：既克服了多对一模型并发度不高的缺点，又克服了一对一模型的一个用户进程占用太多内核级线程而开销太大的缺点。此外，还拥有上述两种模型各自的优点。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/b86efe1592c3ce83305d75f921bd586fa96327898e677be35ee886df29c5ce3f.jpg)  
图2.6多线程模型  

##  本节小结  

本节开头提出的问题的参考答案如下。  

### 1）为什么要引入进程？  

在多道程序设计的背景下，进程之间需要共享系统资源，因此会导致各程序在执行过程中出现相互制约的关系，程序的执行会表现出间断性等特征。这些特征都是在程序的执行过程中发生的，是动态的过程，而传统的程序本身是一组指令的集合，是静态的概念，无法描述程序在内存中的执行情况，即无法从程序的字面上看出它何时执行、何时停顿，也无法看出它与其他执行程序的关系，因此，程序这个静态概念已不能如实反映程序并发执行过程的特征。为了深刻描述程序动态执行过程的性质乃至更好地支持和管理多道程序的并发执行，便引入了进程的概念。  

### 2）什么是进程？进程由什么组成？  

进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以审请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码本身，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。  

一个进程实体由程序段、相关数据段和PCB三部分构成，其中PCB是标志一个进程存在的唯一标识，程序段是进程运行的程序的代码，数据段则存储程序运行过程中相关的一些数据。  

### 3）进程是如何解决问题的？  

进程将能够识别程序运行状态的一些变量存放在PCB中，通过这些变量系统能够更好地了解进程的状况，并在适当时机进行进程的切换，以避免一些资源的浪费，甚至划分为更小的调度单位一一线程来提高系统的并发度。  

本节主要介绍什么是进程，并围绕这个问题进行一些阐述和讨论，为下一节讨论的内容做铺垫，但之前未学过相关课程的读者可能会比较费解，到现在为正对进程这个概念还未形成比较清晰的认识。接下来，我们再用一个比较熟悉的概念来类比进程，以便大家能彻底理解本节的内容到底在讲什么，到底解决了什么问题。  

我们用“人的生命历程”来类比进程。首先，人的生命历程一定是一个动态的、过程性的概念，要研究人的生命历程，先要介绍经历这个历程的主体是什么。主体当然是人，相当于经历进程的主体是进程映像，人有自己的身份，相当于进程映像里有PCB；人生历程会经历好几种状态：出生的时候、弥留的时候、充满斗志的时候、发奋图强的时候及失落的时候，相当于进程有创建、撤销、就绪、运行、阻塞等状态，这几种状态会发生改变，人会充满斗志而转向发奋图强，发奋图强获得进步之后又会充满斗志预备下一次发奋图强，或者发奋图强后遇到阻碍会进入失落状态，然后在别人的开导之下又重新充满斗志。类比进程，会由就绪态转向运行态，运行态转向就绪态，或者运行态转向阻塞态，然后在别的进程帮助下返回就绪态。若我们用“人生历程”这个过程的概念去类比进程，则对进程的理解就更深一层。前面生活化的例子可以帮我们理解进程的实质，但它毕竟有不严谨的地方。一种较好的方式是，在类比进程和人生历程后，再看一遍前面较为严谨的书面阐述和讨论，这样对知识的掌握会更加准确而全面。  
这里再给出一些学习计算机科学知识的建议。学习时，很多同学会陷入一个误区，即只注重对定理、公式的应用，而忽视对基础概念的理解。这是我们从小到大应付考试而培养出的一个毛病，因为熟练应用公式和定理对考试有立竿见影的效果。公式、定理的应用固然重要，但基础概念的理解能让我们透彻地理解一门学科，更利于我们产生兴趣，培养创造性思维。  

# CPU调度  

在学习本节时，请读者思考以下问题  

1）为什么要进行CPU调度？  

2）调度算法有哪几种？结合第1章学习的分时操作系统和实时操作系统，思考哪种调度算法比较适合这两种操作系统。  

希望读者能够在学习调度算法前，先自己思考一些调度算法，在学习的过程中注意将自己的想法与这些经典的算法进行比对，并学会计算一些调度算法的周转时间。  
## 调度的概念  

### 调度的基本概念  

在多道程序系统中，进程的数量往往多于CPU的个数，因此进程争用CPU的情况在所难免。CPU调度是对CPU进行分配，即从就绪队列中按照一定的算法（公平、高效的原则）选择一个进程并将CPU分配给它运行，以实现进程并发地执行。  

CPU调度是多道程序操作系统的基础，是操作系统设计的核心问题。  

### 调度的层次  

一个作业从提交开始直到完成，往往要经历以下三级调度，如图2.7所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/7f02ae01d0a171c46a1a035b0848db7cb0ff1cf0d5d243f56b408c781bf2bcb8.jpg)  
图2.7CPU的三级调度  

（1）高级调度（作业调度）  

按照某种规则从外存上处于后备队列的作业中挑选一个（或多个），给它（们）分配内存、1/O设备等必要的资源，并建立相应的进程，以使它（们）获得竞争CPU的权利。简言之，作业调度就是内存与辅存之间的调度。每个作业只调入一次、调出一次。  

多道批处理系统中大多配有作业调度，而其他系统中通常不需要配置作业调度。  

（2）中级调度（内存调度）  

引入中级调度的自的是提高内荐利用率和系统吞吐量。为此，将那些暂时不能运行的进程调至外存等待，此时进程的状态称为挂起态。当它们已具备运行条件且内存文稍有空闲时，由中级调度来决定将外存上的那些已具备运行条件的挂起进程再重新调入内存，并修改其状态为就绪态，挂在就绪队列上等待。中级调度实际上是存储器管理中的对换功能。  

（3）低级调度（进程调度）  

按照某种算法从就绪队列中选取一个进程，将CPU分配给它。进程调度是最基本的一种调度，在各种操作系统中都必须配置这级调度。进程调度的频率很高，一般几十毫秒一次。  

### 三级调度的联系  

作业调度从外存的后备队列中选择一批作业进入内存，为它们建立进程，这些进程被送入就绪队列，进程调度从就绪队列中选出一个进程，并将其状态改为运行态，将CPU分配给它。中级调度是为了提高内存的利用率，系统将那些暂时不能运行的进程挂起来。  

1）作业调度为进程活动做准备，进程调度使进程正常活动起来。2）中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间。  
3）作业调度次数少，中级调度次数略多，进程调度频率最高。4）进程调度是最基本的，不可或缺。  

## 调度的实现  

### 调度程序（调度器）  

用于调度和分派CPU的组件称为调度程序，它通常由三部分组成，如图2.8所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/dfa12b23fc0749597359e6144d67fec5ae58c52eea70cfd649d23e9485a3b0e5.jpg)  
图2.8调度程序的结构  

1）排队器。将系统中的所有就绪进程按照一定的策略排成一个或多个队列，以便于调度程序选择。每当有一个进程转变为就绪态时，排队器便将它插入相应的就绪队列。  

2）分派器。依据调度程序所选的进程，将其从就绪队列中取出，将CPU分配给新进程。  

3）上下文切换器。在对CPU进行切换时，会发生两对上下文的切换操作：第一对，将当前进程的上下文保存到其PCB中，再装入分派程序的上下文，以便分派程序运行；第二对，移出分派程序的上下文，将新选进程的CPU现场信息装入CPU的各个相应寄存器。  

在上下文切换时，需要执行大量load和store指令，以保存寄存器的内容，因此会花费较多时间。现在已有硬件实现的方法来减少上下文切换时间。通常采用两组寄存器，其中一组供内核使用，一组供用户使用。这样，上下文切换时，只需改变指针，让其指向当前寄存器组即可。  

### 调度的时机、切换与过程  

调度程序是操作系统内核程序。请求调度的事件发生后，才可能运行调度程序，调度了新的就绪进程后，才会进行进程切换。理论上这三件事情应该顺序执行，但在实际的操作系统内核程序运行中，若某时刻发生了引起进程调度的因素，则不一定能马上进行调度与切换。  

>#### pro：可以进行CPU调度的事件或时机（2012、2021）  

现代操作系统中，应该进行进程调度与切换的情况如下：  

1）创建新进程后，由于父进程和子进程都处于就绪态，因此需要决定是运行父进程还是运行子进程，调度程序可以合法地决定其中一个进程先运行。2）进程正常结束后或者异常终止后，必须从就绪队列中选择某个进程运行。若没有就绪进程，则通常运行一个系统提供的闲递进程。3）当进程因I/0请求、信号量操作或其他原因而被阻塞时，必须调度其他进程运行。4）当1/O设备完成后，发出1/O中断，原先等待1/O的进程从阻塞态变为就绪态，此时需要决定是让新的就绪进程投入运行，还是让中断发生时运行的进程继续执行。  
此外，在有些系统中，当有更紧急的任务（如更高优先级的进程进入就绪队列）需要处理时，或者当前进程的时间片用完时，也被强行剥夺CPU（被动放弃）。  

进程切换往往在调度完成后立刻发生，它要求保存原进程当前断点的现场信息，恢复被调度进程的现场信息。现场切换时，操作系统内核将原进程的现场信息推入当前进程的内核堆栈来保存它们，并更新堆栈指针。内核完成从新进程的内核栈中装入新进程的现场信息、更新当前运行进程空间指针、重设PC寄存器等相关工作之后，开始运行新的进程。  

不能进行进程的调度与切换的情况如下：  

1）在处理中断的过程中。中断处理过程复杂，在实现上很难做到进程切换，而且中断处理是系统工作的一部分，逻辑上不属于某一进程，不应被剥夺CPU资源。2）需要完全屏蔽中断的原子操作过程中。如加锁、解锁、中断现场保护、恢复等原子操作。在原子过程中，连中断都要屏蔽，更不应该进行进程调度与切换。若在上述过程中发生了引起调度的条件，则不能马上进行调度和切换，应置系统的请求调度标志，直到上述过程结束后才进行相应的调度与切换。  

### 进程调度的方式  

所谓进程调度方式，是指当某个进程正在CPU上执行时，若有某个更为重要或紧道的进程需要处理，即有优先权更高的进程进入就绪队列，此时应如何分配CPU。  

通常有以下两种进程调度方式：  

1）非抢占调度方式，又称非剥夺方式。是指当一个进程正在CPU上执行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在执行的进程继续执行，直到该进程运行完成（如正常结束、异常终止）或发生某种事件（如等待I/O操作、在进程通信或同步中执行了Block原语）而进入阻塞态时，才将CPU分配给其他进程。非抢占调度方式的优点是实现简单、系统开销小，适用于早期的批处理系统，但它不能用于分时系统和大多数的实时系统。2）抢占调度方式，又称剥夺方式。是指当一个进程正在CPU上执行时，若有某个更为重要或紧迫的进程需要使用CPU，则允许调度程序根据某种原则去暂停正在执行的进程，将CPU分配给这个更为重要或紧迫的进程。抢占调度方式对提高系统吞吐率和响应效率都有明显的好处。但“抢占”不是一种任意性行为，必须遵循一定的原则，主要有优先权、短进程优先和时间片原则等。  

### 闲连进程  

在进程切换时，如果系统中没有就绪进程，就会调度闲逛进程（IdleProcess）运行，它的PID为0。如果没有其他进程就绪，该进程就一直运行，并在指令周期后测试中断。闲逛进程的优先级最低，没有就绪进程时才会运行闲逛进程，只要有进程就绪，就会立即让出CPU。  

闲逛进程不需要CPU之外的资源，它不会被阻塞。  

### 两种线程的调度  

1）用户级线程调度。由于内核并不知道线程的存在，所以内核还是和以前一样，选择一个进程，并给予时间控制。由进程中的调度程序决定哪个线程运行。2）内核级线程调度。内核选择一个特定线程运行，通常不用考虑该线程属于哪个进程。对被选择的线程赋予一个时间片，如果超过了时间片，就会强制挂起该线程。  

用户级线程的线程切换在同一进程中进行，仅需少量的机器指令；内核级线程的线程切换需要完整的上下文切换、修改内存映像、使高速缓存失效，这就导致了若干数量级的延迟。  
2.2.3调度的目标  

不同的调度算法具有不同的特性，在选择调度算法时，必须考虑算法的特性。为了比较CPU调度算法的性能，人们提出了很多评价标准，下面介绍其中主要的几种：  

pro：作业执行的相关计算（2012、2016、2018、2019、2023、2024）  

1）CPU利用率。CPU是计算机系统中最重要和昂贵的资源之一，所以应尽可能使CPU保持“忙”状态，使这一资源利用率最高。CPU利用率的计算方法如下：  

CPU有效工作时间CPU的利用率：CPU有效工作时间+CPU空闲等待时间  

>##### attention：  

计算作业完成时间时，要注意CPU与设备、设备与设备之间是可以并行的。  

2）系统吞吐量。表示单位时间内CPU完成作业的数量。长作业需要消耗较长的CPU时间，因此会降低系统的吞吐量。而对于短作业，需要消耗的CPU时间较短，因此能提高系统的吞吐量。调度算法和方式的不同，也会对系统的吞吐量产生较大的影响。  

3）周转时间。指从作业提交到作业完成所经历的时间，是作业等待、在就绪队列中排队、  

在CPU上运行及I/O操作所花费时间的总和。周转时间的计算方法如下：周转时间 $=$ 作业完成时间-作业提交时间  

平均周转时间 $=$ （作业1的周转时间 $+\cdot\cdot+$ 作业 $n$ 的周转时间)/n带权周转时间是指作业周转时间与作业实际运行时间的比值：平均带权周转时间是指多个作业带权周转时间的平均值：平均带权周转时间 $=$ （作业1的带权周转时间 $+\dots+$ 作业 $n$ 的带权周转时间）/n  

4）等待时间。指进程处于等待CPU的时间之和，等待时间越长，用户满意度越低。CPU调度算法实际上并不影响作业执行或1/O操作的时间，只影响作业在就绪队列中等待所花的时间。因此，衡量一个调度算法的优劣，常常只需简单地考察等待时间。  

5）响应时间。指从用户提交请求到系统首次产生响应所用的时间。在交互式系统中，周转时间不是最好的评价准则，一般采用响应时间作为衡量调度算法的重要准则之一。从用户角度来看，调度策略应尽量降低响应时间，使响应时间处在用户能接受的范围之内。  

要想得到一个满足所有用户和系统要求的算法几乎是不可能的。设计调度程序，一方面要满足特定系统用户的要求（如某些实时和交互进程的快速响应要求），另一方面要考虑系统整体效率（如减少整个系统的进程平均周转时间），同时还要考虑调度算法的开销。  

## 进程切换  

>#### pro：进程调度前后CPU模式的变化（2023）  

对于通常的进程而言，其创建、撤销及要求由系统设备完成的I/O操作，都是利用系统调用而进入内核，再由内核中的相应处理程序予以完成的。进程切换同样是在内核的支持下实现的，因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。  
（1）上下文切换  

>#### pro：切换进程时的操作（2024）  

切换CPU到另一个进程需要保存当前进程状态并恢复另一个进程的状态，这个任务称为上下文切换。进程上下文采用进程PCB表示，包括CPU寄存器的值、进程状态和内存管理信息等。当进行上下文切换时，内核将旧进程状态保存在其PCB中，然后加载经调度而要执行的新进程的上下文。在切换过程中，进程的运行环境产生实质性的变化。上下文切换的流程如下：  

1）挂起一个进程，将CPU上下文保存到PCB，包括程序计数器和其他寄存器。  

2）将进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。  

3）选择另一个进程执行，并更新其PCB。  

4）恢复新进程的CPU上下文。  

5）跳转到新进程PCB中的程序计数器所指向的位置执行。  

（2）上下文切换的消耗  

上下文切换通常是计算密集型的，即它需要相当可观的CPU时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间，所以上下文切换对系统来说意味着消耗大量的CPU时间。有些CPU提供多个寄存器组，这样，上下文切换就只需要简单改变当前寄存器组的指针。  

（3）上下文切换与模式切换  

模式切换与上下文切换是不同的，模式切换时，CPU逻辑上可能还在执行同一进程。用户进程最开始都运行在用户态，若进程因中断或异常进入核心态运行，执行完后又回到用户态刚被中断的进程运行。用户态和内核态之间的切换称为模式切换，而不是上下文切换，因为没有改变当前的进程。上下文切换只能发生在内核态，它是多任务操作系统中的一个必需的特性。  

>##### attention：  

调度和切换的区别：调度是指决定资源分配给哪个进程的行为，是一种决策行为；切换是指实际分配的行为，是执行行为。一般来说，先有资源的调度，然后才有进程的切换。  

## 典型的调度算法  

>#### pro：各种调度算法的特点与对比（2009、2011、2014）  

操作系统中存在多种调度算法，有的调度算法适用于作业调度，有的调度算法适用于进程调度，有的调度算法两者都适用。下面介绍几种常用的调度算法。  

### 先来先服务（FCFS）调度算法  

FCFS调度算法是一种最简单的调度算法，它既可用于作业调度，又可用于进程调度。  

pro：FIFO调度算法的思想（2017）  

在作业调度中，FCFS调度算法每次从后备作业队列中选择最先进入该队列的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。  

在进程调度中，FCFS调度算法每次从就绪队列中选择最先进入该队列的进程，将CPU分配给它，使之投入运行，直到运行完成或因某种原因而阻塞时才释放CPU。  

>#### pro：批处理系统中作业完成时间的分析（2012、2016）  

下面通过一个实例来说明FCFS调度算法的性能。假设系统中有4个作业，它们的提交时间分别是 $8,8.4,8.8,9$ ，运行时间依次是 $2,1,0.5,0.2$ ，系统采用FCFS调度算法，这组作业的平均等待时间、平均周转时间和平均带权周转时间见表2.2。  
表2.2FCFS调度算法的性能
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/71bce0079791dd4ca8962d3658de3c744a6b1040134b154650e16bc9cb314fbc.jpg)  
平均等待时间 $t\,{=}\,(0+1.6+2.2+2.5)/4=1.575$ ：平均周转时间 $T\!=(2+2.6+2.7+2.7)/4=2.5$ 平均带权周转时间 $W\!=\!(1+2.6+5.4+13.5)/4=5.625\,\circ$  

FCFS调度算法属于不可剥夺算法。从表面上看，它对所有作业都是公平的，但若一个长作业先到达系统，就会使后面的许多短作业等待很长时间，因此它不能作为分时系统和实时系统的主要调度策略。但它常被结合在其他调度策略中使用。例如，在使用优先级作为调度策略的系统中，往往对多个具有相同优先级的进程按FCFS原则处理。  

FCFS调度算法的特点是算法简单，但效率低；对长作业比较有利，但对短作业不利（相对SJF和高响应比）：有利于CPU繁忙型作业，而不利于I/O繁忙型作业。  

### 短作业优先（SJF）调度算法  

>#### pro：SJF调度算法的思想（2017）  

短作业（进程）优先调度算法是指对短作业（进程）优先调度的算法。短作业优先（SJF）调度算法从后备队列中选择一个或几个估计运行时间最短的作业，将它们调入内存运行；短进程优先（SPF）调度算法从就绪队列中选择一个估计运行时间最短的进程，将CPU分配给它，使之立即执行，直到完成或发生某事件而阻塞时才释放CPU。  

例如，考虑表2.2中给出的一组作业，若系统采用短作业优先调度算法，其平均等待时间、平均周转时间和平均带权周转时间见表2.3。  

表2.3SJF调度算法的性能
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3e627e4443655f02ad8e96b1151a083196d164b190b937102d743f45c4f90bb1.jpg)  

平均等待时间 $t=(0+2.3+1.4+1)/4=1.175$ ：平均周转时间 $T\,{=}\,(2+3.3+1.9+1.2)/4\,{=}\,2.1$ 平均带权周转时间 $\begin{array}{r}{W\!=\!(1+3.3+3.8+6)/4=3.525\,\mathrm{{\circ}}}\end{array}$  

SJF算法也存在不容忽视的缺点：  

1）该算法对长作业不利，由表2.2和表2.3可知，SJF调度算法中长作业的周转时间会增加。更严重的是，若有一长作业进入系统的后备队列，由于调度程序总是优先调度那些（即使是后进来的）短作业，将导致长作业长期不被调度，产生“饥饿”现象（注意区分“死锁”，后者是系统环形等待，前者是调度策略问题）。  

2）该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业会被及时处理。  

3）由于作业的长短是根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。  
SPF算法也可以是抢占式的（若未特别说明，则默认为非抢占式的）。当一个新进程到达就绪队列时，若其估计执行时间比当前进程的剩余时间小，则立即暂停当前进程，将CPU分配给新进程。因此，抢占式SPF调度算法也称最短剩余时间优先调度算法。  

>##### attention：  

短作业（SJF）调度算法的平均等待时间、平均周转时间是最优的。  

### 高响应比优先调度算法  

高响应比优先调度算法主要用于作业调度，是对FCFS调度算法和SJF调度算法的一种综合平衡，同时考虑了每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。  

响应比的变化规律可描述为  

等待时间+要求服务时间响应比 $R_{\mathrm{p}}=$ 要求服务时间  

根据公式可知： $\textcircled{\scriptsize{1}}$ 作业的等待时间相同时，要求服务时间越短，响应比越高，有利于短作业，因而类似于SF。 $\circledcirc$ 要求服务时间相同时，作业的响应比由其等待时间决定，等待时间越长，其响应比越高，因而类似于FCFS。 $\textcircled{3}$ 对于长作业，作业的响应比可以随等待时间的增加而提高，当其等待时间足够长时，也可获得CPU，克服了“饥饿”现象。  

### 优先级调度算法  

优先级调度算法既可用于作业调度，又可用于进程调度。该算法中的优先级用于描述作业的紧迫程度。在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最高的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将CPU分配给它，使之投入运行。  

根据新的更高优先级进程能否抢占正在执行的进程，可将该调度算法分为如下两种：  

>#### pro：非抢占式优先级调度算法的应用分析（2018）  

1）非抢占式优先级调度算法。当一个进程正在CPU上运行时，即使有某个优先级更高的进程进入就绪队列，仍让正在运行的进程继续运行，直到由于其自身的原因而让出CPU时（任务完成或等待事件），才将CPU分配给就绪队列中优先级最高的进程。  

>#### pro：抢占式优先级调度算法的应用分析（2022、2023）  

2）抢占式优先级调度算法。当一个进程正在CPU上运行时，若有某个优先级更高的进程进入就绪队列，则立即暂停正在运行的进程，将CPU分配给优先级更高的进程。而根据进程创建后其优先级是否可以改变，可将进程优先级分为以下两种：  

>#### pro：静态优先级和动态优先级的分析（2016）  

1）静态优先级。优先级是在创建进程时确定的，且在进程的整个运行期间保持不变。确定静态优先级的主要依据有进程类型、进程对资源的要求、用户要求。优点是简单易行，系统开销小；缺点是不够精确，可能出现优先级低的进程长期得不到调度的情况。  

>#### pro：调整进程优先级的合理时机（2010）  

2）动态优先级。创建进程时先赋予进程一个优先级，但优先级会随进程的推进或等待时间的增加而改变，以便获得更好的调度性能。例如，规定优先级随等待时间的增加而提高，于是，对于优先级初值较低的进程，等待足够长的时间后也可获得CPU。  
一般来说，进程优先级的设置可以参照以下原则：1）系统进程 $>$ 用户进程。系统进程作为系统的管理者，理应拥有更高的优先级。  

2）交互型进程 $>$ 非交互型进程（或前台进程 $>$ 后台进程）。大家平时在使用手机时，在前台运行的正在和你交互的进程应该更快速地响应你，因此自然需要被优先处理。  

>#### pro：进程优先级的设置：I/O型和计算型（2013）  

3）1/0型进程 $>$ 计算型进程。所谓1/O型进程，是指那些会频繁使用1/O设备的进程，而计算型进程是那些频繁使用CPU的进程（很少使用I/O设备）。我们知道，I/O设备（如打印机）的处理速度要比CPU慢得多，因此若将I/O型进程的优先级设置得更高，就更有可能让1/O设备尽早开始工作，进而提升系统的整体效率。  

### 时间片轮转（RR）调度算法  

>#### pro:  时间片轮转调度算法的原理（2021、2024）  

时间片轮转（RR）调度算法主要适用于分时系统。在这种算法中，系统将所有的就绪进程按FCFS策略排成一个就绪队列。系统可设置每隔一定的时间（如 $30\mathrm{ms}$ ）便产生一次时钟中断，激活调度程序进行调度，将CPU分配给就绪队列的队首进程，并令其执行一个时间片。在执行完一个时间片后，即使进程并未运行完成，它也必须释放出（被剥夺）CPU给就绪队列的新队首进程，而被剥夺的进程返回到就绪队列的末尾重新排队，等候再次运行。  

在RR调度算法中，若一个时间片尚未用完而当前进程已运行完成，则调度程序会被立即激活；若一个时间片用完，则产生一个时钟中断，由时钟中断处理程序来激活调度程序。  

>#### pro：时间片轮转调度算法的特点（2017）  

在RR调度算法中，时间片的大小对系统性能的影响很大。若时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则时间片轮转调度算法就退化为先来先服务调度算法。若时间片很小，则CPU将在进程间过于频繁地切换，使CPU的开销增大，而真正用于运行用户进程的时间将减少。因此，时间片的大小应选择适当，时间片的长短通常由以下因素确定：系统的响应时间、就绪队列中的进程数目和系统的处理能力。  

### 多级队列调度算法  

前述的各种调度算法，由于系统中仅设置一个进程的就绪队列，即调度算法是固定且单一的，无法满足系统中不同用户对进程调度策略的不同要求。在多CPU系统中，这种单一调度策略实现机制的缺点更为突出，多级队列调度算法能在一定程度上弥补这一缺点。  

该算法在系统中设置多个就绪队列，将不同类型或性质的进程固定分配到不同的就绪队列。每个队列可实施不同的调度算法，因此，系统针对不同用户进程的需求，很容易提供多种调度策略。同一队列中的进程可以设置不同的优先级，不同的队列本身也可以设置不同的优先级。在多CPU系统中，可以很方便为每个CPU设置一个单独的就绪队列，每个CPU可实施各自不同的调度策略，这样就能根据用户需求将多个线程分配到一个或多个CPU上运行。  

### 多级反馈队列调度算法（融合了前几种算法的优点）  

>#### pro：多级反馈队列调度算法的应用分析（2019）  

多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合与发展，如图2.9所示。通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。  
例如，为提高系统吞吐量和缩短平均周转时间而照顾短进程；为获得较好的1/O设备利用率和缩短响应时间而照顾I/O型进程；同时，也不必事先估计进程的执行时间。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3023703bf0e3b363dc5e01064053932a2178825f747e4c88ea109ba1efb82934.jpg)  
图2.9多级反馈队列调度算法  

>#### pro：多级反馈队列调度算法的实现思想（2020）  

多级反馈队列调度算法的实现思想如下：  

1）设置多个就绪队列，并为每个队列赋予不同的优先级。第1级队列的优先级最高，第2级队列的优先级次之，其余队列的优先级逐个降低。时间片就越小。例如，第 $i+1$ 级队列的时间片要比第 $i$ 级队列的时间片长1倍。3）每个队列都采用FCFS算法。新进程进入内存后，首先将它放入第1级队列的末尾，按FCFS原则等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可撤离系统。若它在一个时间片结束时尚未完成，调度程序将其转入第2级队列的末尾等待调度；若它在第2级队列中运行一个时间片后仍未完成，再将它放入第3级队列，以此类推。当进程最后被降到第 $n$ 级队列后，在第 $n$ 级队列中便采用时间片轮转方式运行。4)按队列优先级调度。仅当第1级队列为空时，才调度第2级队列中的进程运行；仅当第1\~  

i-1级队列均为空时，才会调度第 $i$ 级队列中的进程运行。若CPU正在执行第 $i$ 级队列中的某个进程时，又有新进程进入任何一个优先级较高的队列，此时须立即将正在运行的进程放回到第 $i$ 级队列的末尾，而将CPU分配给新到的高优先级进程。  

多级反馈队列的优势有以下几点：  

1）终端型作业用户：短作业优先。2）短批处理作业用户：周转时间较短。3）长批处理作业用户：经过前面几个队列得到部分执行，不会长期得不到处理。  

下表总结了几种常见进程调度算法的特点，读者要在理解的基础上掌握。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3f58ae6aca33d8e74ff64d9d67034421710e0d3eb7e9b23e14633164897d2541.jpg)  
## 本节小结  

本节开头提出的问题的参考答案如下。  

1）为什么要进行CPU调度？  

若没有CPU调度，则意味着要等到当前运行的进程执行完毕后，下一个进程才能执行，而实际情况中，进程时常需要等待一些外部设备的输入，而外部设备的速度与CPU相比是非常缓慢的，若让CPU总是等待外部设备，则对CPU的资源是极大的浪费。而引进CPU调度后，可在运行进程等待外部设备时，将CPU调度给其他进程，从而提高CPU的利用率。用一句简单的话说，就是为了合理地处理计算机的软/硬件资源。  

2）调度算法有哪几种？结合第1章学习的分时操作系统和实时操作系统，思考有没有哪种调度算法比较适合这两种操作系统。  

本节介绍的调度算法有先来先服务调度、短作业优先调度、优先级调度、高响应比优先调度、时间片轮转调度、多级队列调度、多级反馈队列调度7种。  

先来先服务算法和短作业优先算法无法保证及时地接收和处理问题，因此无法保证在规定的时间间隔内响应每个用户的需求，也同样无法达到实时操作系统的及时性需求。优先级调度算法按照任务的优先级进行调度，对于更紧急的任务给予更高的优先级，适合实时操作系统。  

高响应比优先调度算法、时间片轮转调度算法、多级反馈队列调度算法都能保证每个任务在一定时间内分配到时间片，并轮流占用CPU，适合分时操作系统。  

本节主要介绍了CPU调度的概念。操作系统主要管理CPU、内存、文件、设备几种资源，只要对资源的请求大于资源本身的数量，就会涉及调度。例如，在单处理器系统中，CPU只有一个，而请求的进程却有多个，因此就需要CPU调度。出现调度的概念后，又有了一个问题，即如何调度、应该满足谁、应该让谁等待，这是调度算法所面对的问题；而应该满足谁、应该让谁等待，要遵循一定的准则。调度这一概念贯穿于操作系统的始终，读者在接下来的学习中，将接触到几种资源的调度问题。将它们与CPU调度的内容相对比，将发现有异曲同工之妙。  

 

#  同步与互斤  

在学习本节时，请读者思考以下问题：  

1）为什么要引入进程同步的概念？  

2）不同的进程之间会存在什么关系？  

3）当单纯用本节介绍的方法解决这些问题时会遇到什么新的问题吗？  

用PV操作解决进程之间的同步互斥问题是这一节的重点，统考中频繁考查这一内容，请读者务必多加练习，掌握好求解该类问题的方法。  

## 基本概念  

在多道程序环境下，进程是并发执行的，不同进程之间存在着不同的相互制约关系。为了协调进程之间的相互制约关系，引入了进程同步的概念。下面举一个简单的例子来帮大家理解这个概念。例如，让系统计算 $1+2\times3$ ，假设系统产生两个进程：一个是加法进程，一个是乘法进程。  
要让计算结果是正确的，一定要让加法进程发生在乘法进程之后，但实际上操作系统具有异步性，若不加以制约，加法进程发生在乘法进程之前是绝对有可能的，因此要制定一定的机制去约束加法进程，让它在乘法进程完成之后才发生，而这种机制就是本节要讨论的内容。  

### 临界资源  

>#### pro：给定代码的同步互斥分析（2016、2021、2023）  

虽然多个进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程所用，我们将一次仅充许一个进程使用的资源称为临界资源。许多物理设备都属于临界资源，如打印机等。此外，还有许多变量、数据等都可以被若干进程共享，也属于临界资源。  

>#### pro：临界区和临界资源的分析（2024）  

对临界资源的访问，必须互斥地进行，在每个进程中，访问临界资源的那段代码称为临界区。为了保证临界资源的正确使用，可将临界资源的访问过程分成4个部分：  

1）进入区。为了进入临界区使用临界资源，在进入区要检查可否进入临界区，若能进入临界区，则应设置正在访问临界区的标志，以阻止其他进程同时进入临界区。2）临界区。进程中访问临界资源的那段代码，又称临界段。3）退出区。将正在访问临界区的标志清除。  

4）剩余区。代码中的其余部分。  

hile(true){ entry section; critical section; exit section; remainder section;  

//进入区

 /临界区

//退出区

 //剩余区 

### 同步  

同步亦称直接制约关系，是指为完成某种任务而建立的两个或多个进程，这些进程因为需要协调它们的运行次序而等待、传递信息所产生的制药关系。同步关系源于进程之间的相互合作。  

例如，输入进程A通过单缓冲向进程B提供数据。当该缓冲区空时，进程B不能获得所需数据而阻塞，一旦进程A将数据送入缓冲区，进程B就被唤醒。反之，当缓冲区满时，进程A被阻塞，仅当进程B取走缓冲数据时，才唤醒进程A。  

### 互斥  

互斥也称间接制约关系。当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才充许去访问此临界资源。  

例如，在仅有一台打印机的系统中，有两个进程A和进程B，若当进程A需要打印时，系统已将打印机分配给进程B，则进程A必须阻塞。一旦进程B将打印机释放，系统便将进程A唤醒，并将其由阻塞态变为就绪态。  

>#### pro：实现临界区互斥必须遵循的准则（2020）  

为禁止两个进程同时进入临界区，同步机制应遵循以下准则：  

1）空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。

2）忙则等待。当已有进程进入临界区时，其他试图进入临界区的进程必须等待。

3）有限等待。对请求访问的进程，应保证能在有限时间内进入临界区，防止进程无限等待。 

4）让权等待（原则上应该遵循，但非必须）。当进程不能进入临界区时，应立即释放处理器，防止进程忙等待。  

## 实现临界区互斥的基本方法  

>#### pro：   实现互斥的软/硬件方法的特点（2018）  

### 软件实现方法  

在进入区设置并检查一些标志来标明是否有进程在临界区中，若已有进程在临界区，则在进入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。  

#### 单标志法  

该算法设置一个公用整型变量turn，指示允许进入临界区的进程编号，当 $\mathrm{turn}=0$ 时，表示允许 $\mathrm{{P_{0}}}$ 进入临界区；当 $\mathrm{turn}=1$ 时，表示允许 $\mathrm{P}_{1}$ 进入临界区。进程退出临界区时将临界区的使用权赋给另一个进程，当 $\mathrm{P}_{i}$ 退出临界区时，将tum置为 $j$  $\phantom{}_{i}=0$  $j=1$ 或 $i\!=\!1\!\;,\;j\!=\!0$  

进程 $\mathbf{P}_{0}$ 进程 $\mathsf{P}_{1}$ while(turn  $!\!=\!\!0$  ); while(turn  $!\!=\!\!1$  ); //进入区 critical section; critical section; //临界区 turn $_{1}{=}1$ turn $_{:=0}$ //退出区remainder section; remainder section; //剩余区  

该算法可以实现每次只充许一个进程进入临界区。但两个进程必须交替进入临界区，若某个进程不再进入临界区，则另一个进程也将无法进入临界区（违背“空闲让进”准则）。这样很容易造成资源利用不充分。若 $\mathrm{{P_{0}}}$ 顺利进入临界区并从临界区离开，则此时临界区是空闲的，但 $\mathrm{P_{1}}$ 并没有进入临界区的打算，而 $\mathrm{turn}=1$ 一直成立，则 $\mathrm{{P_{0}}}$ 就无法再次进入临界区。  

#### 双标志先检查法  

该算法设置一个布尔型数组flag[2]，用来标记各个进程想进入临界区的意愿，flag[] $=$ true表示 $\mathrm{P}_{i}$ 想要进入临界区（ $i{=}0$ 或1)。 $\mathrm{P}_{i}$ 进入临界区前，先检查对方是否想进入临界区，若想，则等待；否则，将flag[]置为true后，再进入临界区；当 $\mathrm{P}_{i}$ 退出临界区时，将flag[i]置为false。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c8a7b8684c1253055bb582e4d790f92a8ed08ef0eec2c8a606352bef6ef4f4d4.jpg)  

优点：不用交替进入，可连续使用。缺点： $\mathrm{{P_{0}}}$ 和 $\mathrm{P}_{1}$ 可能同时进入临界区。按序列 ${\mathfrak{Q}}{\mathfrak{Q}}{\mathfrak{Q}}{\mathfrak{Q}}{\mathfrak{Q}}{\mathfrak{Q}}$ 执行时，即检查对方标志后和设置自己的标志前可能发生进程切换，结果双方都检查通过，会同时进入临界区（违背“忙则等待”准则）。原因在于检查和设置操作不是一气呵成的。  

#### 双标志后检查法  

算法二先检查对方的标志，再设置自己的标志，但这两个操作又无法一气呵成，于是使得两个进程同时进入临界区的问题。因此，想到先设置后检查法，以避免上述问题。算法三先设置自已的标志，再检查对方的标志，若对方的标志为true，则等待；否则，进入临界区。  

进程 $\mathrm{{P_{0}}}$ flag[0]  $=$  true;  $\begin{array}{c}{\textcircled{1}}\\ {\textcircled{3}}\end{array}$  while(flag[l]); critical section; flag  $[\,0\,]\,=$  false; remainder section;  

进程 $\mathrm{P_{1}}$ ：flag[1]  $=$  true;  $\circledcirc$  //进入区 while(flag[0]);  $\textcircled{4}$  //进入区 critical section; /临界区 flag[1]  $=$  false; /退出区 remainder section; //剩余区  
按序列 $\textcircled{1020304}$ 执行时，即两个进程依次设置自己的标志，并依次检查对方的标志，发现对方也想进入临界区，双方都争着进入临界区，结果谁也进不了（违背“空闲让进”准则），于是因各个进程都长期无法访问临界区而导致“饥饿”现象（违背“有限等待”准则）。  

#### Peterson算法  

>#### pro：Peterson算法实现互斥的分析（2010）  

Peterson算法结合了算法一和算法三的思想，利用flag口解决互斥访问问题，而利用turn解决“饥饿”问题。若双方都争着进入临界区，则可让进程将进入临界区的机会谦让给对方。也就是说，在每个进程进入临界区之前，先设置自己的flag标志，再设置允许进入turn标志；之后，再同时检测对方的flag和turn标志，以保证双方同时要求进入临界区时，只允许一个进程进入。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/9d2b15f4aff86a62f31437cfeddcf39136669afcc3c2023b99d11c01915fbc35.jpg)  

为进入临界区， $\mathrm{P}_{i}$ 先将flag[]置为true，并将turn置为j，表示优先让对方 $\mathrm{P}_{j}$ 进入临界区 $(i=0$  $j\!=\!1$ 或 $i\!=\!1\!\;,\;j\!=\!0\,.$ ）。若双方试图同时进入，则tum几乎同时被置为i和j，但只有一个赋值语句的结果会保持，另一个也会执行，但会被立即重写。变量tumn的最终值决定了哪个进程被允许先进入临界区，若tum的值为 $i$ ，则 $\mathrm{P}_{i}$ 进入临界区。当 $\mathrm{P}_{i}$ 退出临界区时，将flag[置为false，以允许 $\mathrm{P}_{j}$ 进入临界区，则 $\mathrm{P}_{j}$ 在 $\mathrm{P}_{i}$ 退出临界区后很快就进入临界区。若P,不想进入临界区，即flag $=$ false (P)不会陷入while循环），则P就可进入临界区。  

由此可见，Peterson算法很好地遵循了“空闲让进”“忙则等待”“有限等待”三个准则，但依然未遵循“让权等待”准则。相比于前三种算法，该算法是最好的，但依然不够好。  

### 硬件实现方法  

理解本节介绍的硬件实现，对学习后面的信号量很有帮助。计算机提供了特殊的硬件指令，允许对一个字的内容进行检测和修正，或对两个字的内容进行交换等。  

（1）中断屏蔽方法  

>#### pro：关中断指令实现互斥的分析（2021）  

当一个进程正在执行它的临界区代码时，防正其他进程进入其临界区的最简单方法是关中断。因为CPU只在发生中断时引起进程切换，因此屏蔽中断能够保证当前运行的进程让临界区代码顺利地执行完，进而保证互厅的正确实现，然后执行开中断。其典型模式为  

关中断；临界区；开中断；  

这种方法的缺点： $\textcircled{\scriptsize{1}}$ 限制了CPU交替执行程序的能力，因此系统效率会明显降低。 $\circledcirc$ 对内核来说，在它执行更新变量的几条指令期间，关中断是很方便的，但将关中断的权限交给用户则很不明智，若一个进程关中断后不再开中断，则系统可能会因此终止。 $\textcircled{3}$ 不适用于多处理器系统因为在一个CPU上关中断并不能防正进程在其他CPU上执行相同的临界区代码。  
（2）硬件指令方法一TestAndSet指令  

借助一条硬件指令一TestAndSet指令（简称TS指令）实现互斥，这条指令是原子操作。其功能是读出指定标志后将该标志设置为真。指令的功能描述如下：  

boolean TestAndSet(boolean \*lock) {  

boolean old; old  $=\star$  lock; //old用来存放lock的l旧值 \*lock  $=$  true; //无论之前是否已加锁，都将lock置为true returnold; //返回lock的l日值  

>#### pro：TestAndSet指令实现互斥的分析（2016）  

当用TS指令管理临界区时，为每个临界资源设置一个共享布尔变量lock，表示该资源的两种状态：true表示正被占用（已加锁）；false表示空闲（未加锁），初值为false，所以可将lock视为一把锁。进程在进入临界区之前，先用TS指令检查lock值： $\textcircled{\scriptsize{1}}$ 若为false，则表示没有进程在临界区，可以进入，并将lock置为true，这意味着关闭了临界资源（加锁），使任何进程都不能进入临界区； $\textcircled{2}$ 若为true，则表示有进程在临界区中，进入循环等待，直到当前访问临界区的进程退出时解锁（将lock置为false）。利用TS指令实现互斥的过程描述如下：  

while TestAndSet（&lock);//加锁并检查进程的临界区代码段；lock=false; //解锁 进程的其他代码；  

相比于软件实现方法，TS指令将“加锁”和“检查”操作用硬件的方式变成了一气呵成的原子操作。相比于关中断方法，由于“锁”是共享的，这种方法适用于多处理器系统。缺点是，暂时无法进入临界区的进程会占用CPU循环执行TS指令，因此不能实现“让权等待”。  

（3）硬件指令方法一一Swap指令  

Swap指令的功能是交换两个字（字节）的内容。其功能描述如下：  

Swap(boolean\*a,boolean\*b）{ boolean temp  $\mathbf{\beta}=\mathbf{\beta}$  \*a;  $\star\mathsf{a}\!=\!\star\mathsf{b}$  \*b=temp;  

>##### attention：  

以上对TS和Swap指令的描述仅为功能描述，它们由硬件逻辑实现，不会被中断。  

>#### pro：Swap指令与函数实现的分析（2023）  

用Swap指令管理临界区时，为每个临界资源设置一个共享布尔变量lock，初值为false；在每个进程中再设置一个局部布尔变量key，初值为true，用于与 lock 交换信息。从逻辑上看，Swap指令和TS 指令实现互斥的方法并无太大区别，都先记录此时临界区是否已加锁（记录在变量key中），再将锁标志lock置为true，最后检查key，若key为false，则说明之前没有其他进程对临界区加锁，于是跳出循环，进入临界区。其处理过程描述如下：  

boolean key=true; while（key! $=$ false)Swap（&lock,&key); 进程的临界区代码段；lock=false; 进程的其他代码；  
用硬件指令方法实现互厅的优点： $\textcircled{\scriptsize{1}}$ 简单、容易验证其正确性： $\textcircled{2}$ 适用于任意数目的进程，支持多处理器系统； $\textcircled{3}$ 支持系统中有多个临界区，只需为每个临界区设立一个布尔变量。缺点： $\textcircled{\scriptsize{1}}$ 等待进入临界区的进程会占用CPU执行while循环，不能实现“让权等待”； $\circledcirc$ 从等待进程中随机选择一个进程进入临界区，有的进程可能一直选不上，从而导致“饥饿”现象。  

无论是软件实现方法还是硬件实现方法，读者都需要理解它的执行过程，特别是软件实现方法。以上的代码实现与我们平时在编译器上写的代码意义不同，以上的代码实现是为了描述进程实现同步和互厅的过程，并不是说计算机内部实现同步互厅的就是这些代码。  

## 互斥锁  

解决临界区最简单的工具就是互斥锁（mutexlock)。一个进程在进入临界区时调用acquire()函数，以获得锁；在退出临界区时调用release（函数，以释放锁。每个互斥锁有一个布尔变量available，表示锁是否可用。如果锁是可用的，调用acquire(会成功，且锁不再可用。当一个进程试图获取不可用的锁时，会被阻塞，直到锁被释放。其过程描述如下：  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/6ca1d9e89f710eed2244894c9e3ddcf6cf093b3086a42dd982c28bcf739ad6f6.jpg)  

acquireO或releaseO的执行必须是原子操作，因此互斥锁通常采用硬件机制来实现。  

上面描述的互斥锁也称自旋锁，其主要缺点是忙等待，当有一个进程在临界区时，任何其他进程在进入临界区前必须连续循环调用acquire(。类似的还有前面介绍的单标志法、TS指令和Swap指令。当多个进程共享同一CPU时，这种连续循环显然浪费了CPU周期。因此，互斥锁通常用于多处理器系统，一个线程可以在一个处理器上旋转，而不影响其他线程的执行。自旋锁的优点是，进程在等待锁期间，没有上下文切换，若上锁的时间较短，则等待代价不高。  

本节后面，将研究如何使用互斥锁解决经典同步问题。  

## 信号量  

信号量机制是一种功能较强的机制，可用来解决互斥与同步问题，它只能被两个标准的原语waitO和signalO访问，也可简写为PO和VO，或者简称P操作和V操作。  

原语是指完成某种功能且不被分割、不被中断执行的操作序列，通常可由硬件来实现。例如，前述的TS指令和Swap指令就是由硬件实现的原子操作。原语功能的不被中断执行特性在单处理机上可由软件通过屏蔽中断方法实现。原语之所以不能被中断执行，是因为原语对变量的操作过程若被打断，可能会去运行另一个对同一变量的操作过程，从而出现临界段问题。  

>#### pro：信号量的含义（2010）  

### 整型信号量  

整型信号量被定义为一个用于表示资源数目的整型量S，相比于普通整型变量，对整型信号量的操作只有三种：初始化、wait操作和signal操作。wait操作和signal操作可描述为  

wait(S){//相当于进入区while(  $s{<=}0$  ）; //若资源数不够，则一直循环等待  
$\scriptstyle{\mathrm{S}}={\mathrm{S}}-1$ /若资源数够，则占用一个资源signal(S)(//相当于退出区 $_{\mathrm{S=S+1}}$ //使用完后，就释放一个资源  

在整型信号量机制中的wait操作，只要信号量 $S{\leqslant}0$ ，就会不断循环测试。因此，该机制并未遵循“让权等待”的准则，而是使进程处于“忙等”的状态。  

### 记录型信号量  

记录型信号量机制是一种不存在“忙等”现象的进程同步机制。除了需要一个用于代表资源数目的整型变量vahue外，再增加一个进程链表L，用于链接所有等待该资源的进程。记录型信号量得名于采用了记录型的数据结构。记录型信号量可描述为  

type def struct{ intvalue; struct process \*L; )semaphore;  

相应的wait（S）和signal（S）的操作如下。  

void wait(semaphore S){/相当于申请资源S.value--;if(S.value<0)( add this process to S.L; block(S.L);  

>#### pro：wait0操作导致线程状态的变化（2023）  

>#### pro：遵循“让权等待”的互斥方法（2018）  

对信号量S的一次P操作，表示进程请求一个该类资源，因此执行S.value--，使系统中可供分配的该类资源数减1。当S.value $<0$ 时，表示该类资源已分配完毕，因此应调用block原语进行自我阻塞（当前运行的进程：运行态 $\rightarrow$ 阻塞态），主动放弃CPU，并插入该类资源的等待队列S.L，可见该机制遵循了“让权等待”准则。  

void signal(semaphore S){/相当于释放资源S.value++; if(s.value  ${<=}0$  remove a process P from S.L; wakeup(P);  

对信号量S的一次V操作，表示进程释放一个该类资源，因此执行S.value $^{++}$ ，使系统中可供分配的该类资源数加1。若加1后仍是S.value ${\leqslant}0$ ，则表示仍有进程在等待该类资源，因此应调用wakeup原语将SL中的第一个进程唤醒（被唤醒进程：阻塞态→就绪态）。  

### 利用信号量实现进程互斤  

>#### pro：利用信号量实现互斥的实现（2024）  

为了使多个进程能互厅地访问某个临界资源，需要为该资源设置一个互厅信号量S，其初值为1（可用资源数为1），然后将各个进程访问该资源的临界区置于P（S）和V（S）之间。这样，每个要访问该资源的进程在进入临界区之前，都要先对S执行P操作，若该资源此刻未被访问，则本次P操作必然成功，进程便可进入自己的临界区。这时，若再有其他进程也要进入自己的临界区，由于对S执行P操作必然失败，因此主动阻塞，从而保证了该资源能被互斥访问。当访问该资源的进程退出临界区后，要对S执行√操作，以便释放该临界资源。其实现如下：  
semaphore $_\mathrm{S=1}$ //初始化信号量，初值为1P1(）{ P(S); //准备访问临界资源，加锁 进程P1的临界区；V(S); //访问结束，解锁 P2(）{ P(S); 准备访问临界资源，加锁 进程P2的临界区；V(S); //访问结束，解锁  

S的取值范围为 $(-1,0,1)$ 。当 $\mathrm{S}=1$ 时，表示两个进程都未进入临界区；当 $\mathrm{S}=0$ 时，表示有一个进程已进入临界区：当 $\mathrm{S}=-1$ 时，表示有一个进程正在临界区，另一个进程因等待而阻塞在阻塞队列中，需要被当前已在临界区中运行的进程退出时唤醒。  

>##### attention：  

$\textcircled{\scriptsize{1}}$ 对不同的临界资源需要设置不同的互斥信号量。 $\circledcirc$ P(S）和V(S)必须成对出现，缺少P(S）就不能保证对临界资源的互斥访问；缺少V(S会使临界资源永远不被释放，从而使因等待该资源而阻塞的进程永远不能被唤醒。 $\textcircled{3}$ 考试还会考查多个资源的问题，有多少资源就将信号量初值设为多少，申请资源时执行P操作，释放资源时执行V操作。  

### 利用信号量实现同步  

pro：利用信号量实现同步（2024）  

同步源于进程之间的相互合作，需要让本来异步的并发进程相互配合，有序推进。例如，进程 $\mathrm{P_{1}}$ 和 $\mathrm{P}_{2}$ 并发执行，由于存在异步性，因此二者推进的次序是不确定的，若 $\mathrm{P}_{2}$ 的语句y要使用 $\mathrm{P}_{1}$ 的语句 $_\mathrm{x}$ 的运行结果，则必须保证语句y一定在语句x之后执行。为了实现这种同步关系，需要设置一个同步信号量S，其初值为0（可以这么理解：刚开始没有这种资源， $\mathrm{P}_{2}$ 需要使用这种资源，而它又只能由 $\mathrm{P}_{1}$ 产生这种资源）。其实现如下：  

semaphore  $s{=}0$  //初始化信号量，初值为0 P1(）{ x; /执行语句x V(S);//告诉进程P2，语句 $_\mathrm{x}$ 已经完成P2(）{ P(S);//检查语句 $_\mathrm{x}$ 是否运行完成y; /获得  $_\mathrm{x}$  的运行结果，执行语句y  
若先执行到V(S），则执行 $\mathrm{S++}$ 后 $\mathrm{S}=1$ 。之后 $\mathrm{P}_{2}$ 执行到P(S）时，由于 $S=1$ ，表示此时有可用资源，执行S--后 $\mathrm{S}=0$ ，P操作不执行block原语，而继续往下执行语句y。  

若先执行到P(S），执行S--后 $\mathrm{S}=-1$ ，表示此时没有可用资源，因此P操作中会执行block原语， $\mathrm{P}_{2}$ 请求阻塞。 $\mathrm{P}_{1}$ 的语句 $_\mathrm{x}$ 执行完后，执行V（S)，执行 $\mathrm{S++}$ 后 $S=0$ ，因此V操作中会执行wakeup原语，唤醒在该信号量对应的阻塞队列中的 $\mathrm{P}_{2}$ ，这样 $\mathrm{P}_{2}$ 就可以继续执行语句y。  

PV操作实现同步互厅的简单总结：在同步问题中，若某个行为会提供某种资源，则在这个行为之后√这种资源：若某个行为要用到这种资源，则在这个行为之前P这种资源。在互斥问题中，PV操作要紧夹使用临界资源的那个行为，中间不能有其他允余代码。  

### 利用信号量实现前驱关系  

>#### pro：信号量实现前驱关系的应用题（2020、2022）  

信号量也可用来描述程序或语句之间的前驱关系。图2.10给出了一个前驱图，其中 $\mathrm{S_{1}},\mathrm{S_{2}},\mathrm{S_{3}},\cdots$  $\mathrm{S}_{6}$ 是简单的程序段（只有一条语句）。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/7b8c21ad5698140e1c8ff7d4a669ea5acb4c62209064712bcf68ad67f3e5d278.jpg)  
图2.10前驱关系举例  

其实，每对前驱关系都是一个同步问题，因此要为每对前驱关系设置一个同步信号量，其初值均为0，在“前驱操作”之后，对相应的同步信号量执行V操作，在“后继操作”之前，对相应的同步信号量执行P操作。为保证 $\mathrm{S_{1}{\rightarrow}S_{2},S_{1}{\rightarrow}S_{3},S_{2}{\rightarrow}S_{4},S_{2}{\rightarrow}S_{5},S_{3}{\rightarrow}S_{6},S_{4}{\rightarrow}S_{6},S_{5}{\rightarrow}S_{6}}$ 的前驱关系，需分别设置同步信号量a12，a13，a24，a25，a36.a46，a56。其实现如下：  

semaphore $\mathsf{a12}\mathsf{=}\mathsf{a13}\mathsf{=}\mathsf{a24}\mathsf{=}\mathsf{a25}\mathsf{=}\mathsf{a36}\mathsf{=}\mathsf{a46}\mathsf{=}\mathsf{a56}\mathsf{=}\mathsf{0}$ ；//初始化信号量  

S1()V(a12);V（a13);//S1已经运行完成S2(){ P（a12);//检查S1是否运行完成V（a24);V（a25);s2已经运行完成S3() P（a13);//检查S1是否已经运行完成V(a36);I/S3已经运行完成S4()P(a24);//检查S2是否已经运行完成V(a46);IIS4已经运行完成S5() P（a25）;//检查s2是否已经运行完成  
V(a56);//s5已经运行完成S6()  P(a36);//检查S3是否已经运行完成P(a46);//检查S4是否已经运行完成P（a56);//检查S5是否已经运行完成  

### 分析进程同步和互斥问题的方法步骤  

1）关系分析。找出问题中的进程数，并分析它们之间的同步和互斥关系。同步、互斥、前驱关系直接按照上面例子中的经典范式改写。2）整理思路。找出解决问题的关键点，并根据做过的题目找出求解的思路。根据进程的操作流程确定P操作、V操作的大致顺序。3）设置信号量。根据上面的两步，设置需要的信号量，确定初值，完善整理。  

这是一个比较直观的同步问题，以图2.10为例， $\mathrm{S}_{2}$ 是 $\mathrm{S}_{1}$ 的后继，要用到 $\mathrm{S}_{1}$ 的资源，在前面总结过，在同步问题中，要用到某种资源，就要在行为之前P这种资源。 $\mathrm{S}_{2}$ 是 $\mathrm{S}_{4},$  $\mathrm{S}_{5}$ 的前驱，给 $\mathrm{S}_{4},$  $\mathrm{S}_{5}$ 提供资源，因此要在 $\mathrm{S}_{2}$ 的语句之后V由 $\mathrm{S}_{4}$ 和 $\mathrm{S}_{5}$ 所产生的资源。  

## 经典同步问题  

>#### pro: 程序并发执行的分析（2011、2018）  

>#### pro: PV操作的应用题（2009、2011、2013、2014、2015、2017、2019）  

### 生产者-消费者问题  

#### 问题描述：  

一组生产者进程和一组消费者进程共享一个初始为空、大小为 $n$ 的缓冲区。只有当缓冲区不满时，生产者才能将消息放入缓冲区：否则必须阻塞，等待消费者从缓冲区中取出消息后将其唤醒。只有当缓冲区不空时，消费者才能从缓冲区中取出消息；否则必须等待，等待生产者将消息放入缓冲区后将其唤醒。由于缓冲区是临界资源，因此必须互斥访问。  

#### 问题分析：  

1）关系分析。生产者和消费者对缓冲区互斥访问是互斥关系，同时生产者和消费者又是一个相互协作的关系，只有生产者生产之后，消费者才能消费，它们也是同步关系。2）整理思路。这里比较简单，只有生产者和消费者两个进程，正好是这两个进程存在着互斥关系和同步关系。那么需要解决的是互斥和同步PV操作的位置。3）信号量设置。信号量mutex作为互斥信号量，用于控制互斥访问缓冲池，互厅信号量初值为1；信号量full用于记录当前缓冲池中的“满”缓冲区数，初值为0。信号量empty用于记录当前缓冲池中的“空”缓冲区数，初值为 $n$  

我们对同步互斥问题的介绍是一个循序渐进的过程。上面介绍了一个同步问题的例子和一个互斥问题的例子，下面来看生产者-消费者问题的例子是什么样的。  

生产者-消费者进程的描述如下：  

semaphore mute x  $_{:=1}$  semaphore empty  $\tt=n$  semaphore full  $=\!0$  producer(){ while(l){  

/临界区互斥信号量

//空闲缓冲区

//缓冲区初始化为空

//生产者进程  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/7907f44e0f07cc490b94b73acf0169c10d3c8daac89709231cb49f2145e37ab6.jpg)  

该类问题要注意对缓冲区大小为 $n$ 的处理，当缓冲区中有空时，便可对empty变量执行P操作，一旦取走一个产品便要执行V操作以释放空闲区。对empty和full变量的P操作必须放在对mutex的P操作之前。若生产者进程先执行P（mutex)，然后执行P（empty)，消费者执行P（mutex)，然后执行P（full），这样可不可以？答案是否定的。设想生产者进程已将缓冲区放满，消费者进程并没有取产品，即 ${\mathrm{empty}}=0$ ，当下次仍然是生产者进程运行时，它先执行P（mutex）封锁信号量，再执行P（empty）时将被阻塞，希望消费者取出产品后将其唤醒。轮到消费者进程运行时，它先执行P（mutex)，然而由于生产者进程已经封锁mutex信号量，消费者进程也会被阻塞，这样一来生产者、消费者进程都将阻塞，都指望对方唤醒自己，因此陷入了无休止的等待。同理，若消费者进程已将缓冲区取空，即 $\mathrm{full}=0$ ，下次若还是消费者先运行，也会出现类似的死锁。不过生产者释放信号量时，mutex，full先释放哪一个无所谓，消费者先释放mutex或empty都可以。  

其实生产者-消费者问题只是一个同步互斥问题的综合而已下面再看一个较为复杂的生产者-消费者问题。  

#### 问题描述：  

桌子上有一个盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等吃盘子中的橘子，女儿专等吃盘子中的苹果。只有盘子为空时，爸爸或妈妈才可向盘子中放一个水果；仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出。  

#### 问题分析：  

1）关系分析。由每次只能向盘中放一个水果可知，爸爸和妈妈是互斥关系。爸爸和女儿、妈妈和儿子是同步关系，而且这两对进程必须连起来，儿子和女儿之间没有互厅和同步关系，因为他们是选择条件执行，不可能并发，如图2.11所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/6ca23faa0313ec798575240909ed9cd726157fb6661276b2ade50932077638ab.jpg)  
图2.11进程之间的关系  
2）整理思路。这里有4个进程，实际上可抽象为两个生产者和两个消费者被连接到大小为1的缓冲区上。  

3）信号量设置。首先将信号量plate设置互厅信号量，表示是否允许向盘子放入水果，初值为1表示允许放入，且只允许放入一个。信号量apple表示盘子中是否有苹果，初值为0表示盘子为空，不许取，apple $=1$ 表示可以取。信号量orange表示盘子中是否有橘子，初值为0表示盘子为空，不许取，orange $=1$ 表示可以取。  

解决该问题的代码如下：  

semaphore plate  $\mathbf{\Phi}=\mathbb{1}$  ,apple  $=\!0$  ,orange  $=\!0$  dad()//父亲进程while(l){ prepare an apple; P(plate); 互斥向盘中取、放水果 putthe appleon the plate; //向盘中放苹果 V(apple);1//允许取苹果mom(）(//母亲进程while(l){ prepare anorange; P(plate); 互斥向盘中取、放水果 put the orange on the plate; /向盘中放橘子 v(orange);1/允许取橘子son(){/儿子进程while(l){ P(orange); /互斥向盘中取橘子 take anorange from the plate; V(plate); //允许向盘中取、放水果 eat the orange; daughter() /女儿进程 while(1){ P(apple);//互斥向盘中取苹果take an apple from the plate; V(plate); //允许向盘中取、放水果 eat the apple;  

进程间的关系如图2.11所示。dad0和daughter0、momO和sonO必须连续执行，正因为如此，也只能在女儿拿走苹果后或儿子拿走橘子后才能释放盘子，即V（plate）操作。  

### 读者一写者问题  

#### 问题描述：  

有读者和写者两组并发进程，共享一个文件，当两个或以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。因此要求： $\textcircled{\scriptsize{1}}$ 充许多个读者可以同时对文件执行读操作； $\circledcirc$ 只充许一个写者往文件中写信息： $\textcircled{3}$ 任意一个写者在完成写操作之前不允许其他读者或写者工作： $\textcircled{4}$ 写者执行写操作前，应让已有的读者和写者全部退出。  
#### 问题分析：  

1）关系分析。由题目分析读者和写者是互厅的，写者和写者也是互斥的，而读者和读者不存在互斥问题。  

2）整理思路。两个进程，即读者和写者。写者是比较简单的，它和任何进程互斥，用互斥信号量的P操作、V操作即可解决。读者的问题比较复杂，它必须在实现与写者互厅的同时，实现与其他读者的同步，因此简单的一对P操作、V操作是无法解决问题的。这里用到了一个计数器，用它来判断当前是否有读者读文件。当有读者时，写者是无法写文件的，此时读者会一直占用文件，当没有读者时，写者才可以写文件。同时，这里不同读者对计数器的访问也应该是互厅的。  

3）信号量设置。首先设置信号量count为计数器，用于记录当前读者的数量，初值为0：设 置mutex为互斥信号量，用于保护更新count变量时的互斥：设置互斥信号量rw，用于保证读者和写者的互厅访问。  

代码如下：  

int count $=\!0$ /用于记录当前的读者数量semaphore mutex $^{=1}$ /用于保护更新count变量时的互厅semaphore rw $^{=1}$ /用于保证读者和写者互厅地访问文件writer(){/写者进程while(1){ P（rw);互斥访问共享文件writing;/写入V(rw);释放共享文件reader(){//读者进程while(1){ P(mutex);//互厅访问count变量if(count $==0$ 当第一个读进程读共享文件时P（rw); //阻止写进程写 count  $^{++}$  //读者计数器加1 V（mutex);//释放互斥变量countreading; /读取 P（mutex);//互斥访问count变量count--; //读者计数器减1 if(count $==0$ 当最后一个读进程读完共享文件V(rw); /允许写进程写 V(mutex);//释放互斥变量count  

在上面的算法中，读进程是优先的，即当存在读进程时，写操作将被延迟，且只要有一个读进程活跃，随后而来的读进程都将被充许访问文件。这样的方式会导致写进程可能长时间等待且存在写进程“饿死”的情况。  

若希望写进程优先，即当有读进程正在读共享文件时，有写进程请求访向，这时应禁正后续读进程的请求，等到已在共享文件的读进程执行完毕，立即让写进程执行，只有在无写进程执行的情况下才允许读进程再次运行。为此，增加一个信号量并在上面程序的writerO和reader（函数中各增加一对PV操作，就可以得到写进程优先的解决程序。  
int count $=\!0$ //用于记录当前的读者数量semaphore mutex $^{=1}$ //用于保护更新count变量时的互斥semaphore $_{x w=1}$ //用于保证读者和写者互厅地访问文件semaphore  $_{w=1}$  //用于实现“写优先” writer(){/写者进程while(1){ P（W);1/在无写进程请求时进入P(rw);//互厅访问共享文件writing;/写入V(rw);//释放共享文件V(w); //恢复对共享文件的访问 reader(){//读者进程while(1){ P（W);//在无写进程请求时进入P(mutex);//互斥访问count变量if（count $==0$ //当第一个读进程读共享文件时P（rw); /阻止写进程写 count  $^{++}$  //读者计数器加1 V(mutex);/释放互斥变量countV（w);//恢复对共享文件的访问reading; //读取 P(mutex);//互斥访问count变量count--; //读者计数器减1 if（count $==0$ //当最后一个读进程读完共享文件V（rw):1/允许写进程写V(mutex);//释放互斥变量count  

这里的写进程优先是相对而言的，有些书上将这个算法称为读写公平法，即读写进程具有一样的优先级。当一个写进程访问文件时，若先有一些读进程要求访问文件，后有另一个写进程要求访问文件，则当前访问文件的进程结束对文件的写操作时，会是一个读进程而不是一个写进程占用文件（在信号量w的阻塞队列上，因为读进程先来，因此排在阻塞队列队首，而V操作唤醒进程时唤醒的是队首进程），所以说这里的写优先是相对的，想要了解如何做到真正写者优先，可参考其他相关资料。  

读者-写者问题有一个关键的特征，即有一个互斥访问的计数器count，因此遇到一个不太好解决的同步互斥问题时，要想一想用互斥访问的计数器count能否解决问题。  

### 哲学家进餐问题  

#### 问题描述：  

一张圆桌边上坐看5名哲学家，每两名哲学家之间的桌上摆一根筷子，两根筷子中间是一碗米饭，如图2.12所示。哲学家们倾注毕生精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根地拿起）。若筷子已在他人手上，则需要等待。饥饿的哲学家只有同时拿到了两根筷子才可以开始进餐，进餐完毕后，放下筷子继续思考。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/567eb1efeb3cc2f9ca660455e2c6d5ab14a621176352deb48365ab56996ee8d6.jpg)  
图2.125名哲学家进餐  

#### 问题分析：  

1）关系分析。5名哲学家与左右邻居对其中间筷子的访问是互斥关系。  

2）整理思路。显然，这里有5个进程。本题的关键是如何让一名哲学家拿到左右两根筷子哲学家的动作制定规则，避免饥饿或死锁现象的发生。3）信号量设置。定义互斥信号量数组chopstick[5] $=\{1,1,1,1,1\}$ ，用于对5个筷子的互斥访问。哲学家按顺序编号为 $_{0\sim4}$ ，哲学家 $i$ 左边筷子的编号为i，哲学家右边筷子的编号为 $(i+1)\%5$  semaphore chopstick $[\,5\,]=\{\,1\,,\,1\,,\,1\,,\,1\,\}$ ；//定义信号量数组chopstick[5]，并初始化Pi(）{//i号哲学家的进程dol P(chopstick[i]);//取左边筷子P（chopstick[（i+1)%5]);/取右边筷子eat; /进餐 V(chopstick[i]);放回左边筷子V（chopstick[(i+l)o5]);/放回右边筷子think;/思考}while（l);  

该算法存在以下问题：当5名哲学家都想要进餐并分别拿起左边的筷子时（都恰好执行完wait（chopstick[i]）：）筷子已被拿光，等到他们再想拿右边的筷子时（执行wait（chopstick $[(\mathrm{i}+1)\%5])$ ;）就全被阻塞，因此出现了死锁。  

为防止死锁发生，可对哲学家进程施加一些限制条件，比如至多允许4名哲学家同时进餐：仅当一名哲学家左右两边的筷子都可用时，才充许他抓起筷子：对哲学家顺序编号，要求奇数号哲学家先拿左边的筷子，然后拿右边的筷子，而偶数号哲学家刚好相反。  

制定的正确规则如下：假设采用第二种方法，当一名哲学家左右两边的筷子都可用时，才允许他抓起筷子。  

semaphore chopstick $[\,5\,]=\{\,1\,,\,1\,,\,1\,,\,1\,\}$ ；7/初始化信号量semaphore mutex $^{=1}$ /设置取筷子的信号量Pi(）{//i号哲学家的进程dof P(mutex);在取筷子前获得互厅量P(chopstick[i]);//取左边筷子P(chopstick[（i+1)85]）;//取右边筷子V(mutex);/释放取筷子的信号量eat; /进餐  
V(chopstick[i]);/放回左边筷子V（chopstick[（i+1)%5]);/放回右边筷子think;//思考while（l);  

熟悉ACM或有过相关训练的读者都应知道贪心算法，哲学家进餐问题的思想其实与贪心算法的思想截然相反，贪心算法强调争取眼前认为最好的，而不考虑后续会有什么后果。若哲学家进餐向题用贪心算法来解决，即只要眼前有筷子能拿起就拿起的话，就会出现死锁。然而，若不 仅考虑眼前的一步，而且考虑下一步，即不因为有筷子能拿起就拿起，而考虑能不能一次拿起两根筷子才做决定的话，就会避免死锁问题，这就是哲学家进餐问题的思维精髓。  

大部分习题和真题用消费者-生产者模型或读者-写者问题就能解决，但对哲学家进餐问题仍然要熟悉。考研复习的关键在于反复多次和全面，“偷工减料”是要吃亏的。  

### 吸烟者问题  

#### 问题描述：  

假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉它，但要卷起并抽掉一支烟，抽烟者需要有三种材料：烟草、纸和胶水。三个抽烟者中，第一个拥有烟草，第二个拥有纸，第三个拥有胶水。供应者进程无限地提供三种材料，供应者每次将两种材料放到桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者一个信号告诉已完成，此时供应者就将另外两种材料放到桌上，如此重复（让三个抽烟者轮流地抽烟）。  

#### 问题分析：  

1）关系分析。供应者与三个抽烟者分别是同步关系。由于供应者无法同时满足两个或以上的抽烟者，三个抽烟者对抽烟这个动作互斥（或由三个抽烟者轮流抽烟得知）。2）整理思路。显然这里有4个进程。供应者作为生产者向三个抽烟者提供材料。3）信号量设置。信号量offer1.offer2.offer3分别表示烟草和纸组合的资源、烟草和胶水组合的资源、纸和胶水组合的资源。信号量finish用于互厅进行抽烟动作。  

代码如下：  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/bd5b548d53c5c6177ed7838bce4b43d990cea070b913efcc9de738968c216af0.jpg)  
while(l){ P(offer3); 拿纸和胶水，卷成烟，抽掉；V(finish); processP3(){/拥有纸者while(l){ P（offer2); 拿烟草和胶水，卷成烟，抽掉；V(finish); processP4()/拥有胶水者while(l)( P（offerl); 拿烟草和纸，卷成烟，抽掉；V（finish); }  

## 管程  

在信号量机制中，每个要访问临界资源的进程都必须自备同步的PV操作，大量分散的同步操作给系统管理带来了麻烦，且容易因同步操作不当而导致系统死锁。于是，便产生了一种新的进程同步工具一一管程。管程的特性保证了进程互厅，无须程序员自己实现互厅，从而降低了死锁发生的可能性。同时管程提供了条件变量，可以让程序员灵活地实现进程同步。  

### 管程的定义  

>#### pro：管程的特点（2016）  

系统中的各种硬件资源和软件资源，均可用数据结构抽象地描述其资源特性，即用少量信息和对资源所执行的操作来表征该资源，而忽略它们的内部结构和实现细节。  

利用共享数据结构抽象地表示系统中的共享资源，而将对该数据结构实施的操作定义为一组过程。进程对共享资源的申请、释放等操作，都通过这组过程来实现，这组过程还可以根据资源清况，或接受或阻塞进程的访问，确保每次仅有一个进程使用共享资源，这样就可以统一管理对共享资源的所有访问，实现进程互厅。这个代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序，称为管程（monitor）。管程定义了一个数据结构和能为并发进程所执行（在该数据结构上）的一组操作，这组操作能同步进程和改变管程中的数据。  

由上述定义可知，管程由4部分组成  

  $\textcircled{1}$ 管程的名称：  

$\circledcirc$ 局部于管程内部的共享数据结构说明： $\textcircled{3}$ 对该数据结构进行操作的一组过程（或函数）；  

$\textcircled{4}$ 对局部于管程内部的共享数据设置初始值的语句。  

管程的定义描述举例如下：  

monitor Dem of $^{\prime\textregistered}$ 定义一个名称为Demo的管程//②定义共享数据结构，对应系统中的某种共享资源共享数据结构S；：  
$/\!/(4)$ 对共享数据结构初始化的语句init_code(）{  $s{=}5$  //初始资源数等于5 takeaway(){ $^{\prime\prime(3)}$ 过程1：申请一个资源对共享数据结构 $_\mathrm{x}$ 的一系列处理；S--;/可用资源数-1giveback(){1③过程2：归还一个资源对共享数据结构 $\mathbf{x}$ 的一系列处理； $_{S++}$  /可用资源数+1  

熟悉面向对象程序设计的读者看到管程的组成后，会立即联想到管程很像一个类（class）。  

1）管程将对共享资源的操作封装起来，管程内的共享数据结构只能被管程内的过程所访问。一个进程只有通过调用管程内的过程才能进入管程访问共享资源。对于上例，外部进程只能通过调用take_awayO过程来申请一个资源；归还资源也类似。  

2）每次仅允许一个进程进入管程，从而实现进程互斥。若多个进程同时调用take_awayOgivebackO，则只有某个进程运行完它调用的过程后，下一进程才能开始运行它调用的过程。即各进程只能事行执行管程内的过程，这一特性保证了进程互斥访问S。  

### 条件变量  

当一个进程进入管程后被阻塞，直到阻塞的原因解除时，在此期间，如果该进程不释放管程，那么其他进程无法进入管程。为此，将阻塞原因定义为条件变量condition。通常，一个进程被阻塞的原因可以有多个，因此在管程中设置了多个条件变量。每个条件变量保存了一个等待队列，用于记录因该条件变量而阻塞的所有进程，对条件变量只能进行两种操作，即wait和signal。  

x.wait：当x对应的条件不满足时，正在调用管程的进程调用x.wait将自已插入 $_\mathrm{x}$ 条件的等待队列，并释放管程。此时其他进程可以使用该管程。  

x.signal：x对应的条件发生了变化，则调用x.signal，唤醒一个因x条件而阻塞的进程。  

下面给出条件变量的定义和使用：  

monitor Demo 共享数据结构S;condition x;//定义一个条件变量xinit_code(){ take_away() if（ $\scriptstyle{\mathtt{S}}<=0$ ) $\mathbf{x}$ .wait();/资源不够，在条件变量x上阻塞等待资源足够，分配资源，做一系列相应处理；giveback(){ 归还资源，做一系列相应处理；if（有进程在等待）x.signal（）；//唤醒一个阻塞进程  

条件变量和信号量的比较：相似点：条件变量的wait/signal操作类似于信号量的P/V操作，可以实现进程的阻塞/唤醒。  
不同点：条件变量是“没有值”的，仅实现了“排队等待”功能；而信号量是“有值”的信号量的值反映了剩余资源数，而在管程中，剩余资源数用共享数据结构记录。  

## 本节小结  

本节开头提出的问题的参考答案如下。  

1）为什么要引入进程同步的概念？在多道程序共同执行的条件下，进程与进程是并发执行的，不同进程之间存在不同的相互制约关系。为了协调进程之间的相互制约关系，引入了进程同步的概念。  

2）不同的进程之间会存在什么关系？进程之间存在同步与互厅的制约关系。  

同步是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而等待、传递信息所产生的制约关系。  

互厅是指当一个进程进入临界区使用临界资源时，另一个进程必须等待，当占用临界资源的进程退出临界区后，另一进程才允许去访问此临界资源。  

3）当单纯用本节介绍的方法解决这些问题时会遇到什么新的问题吗？  

当两个或两个以上的进程在执行过程中，因占有一些资源而又需要对方的资源时，会因为争夺资源而造成一种互相等待的现象，若无外力作用，它们都将无法推进下去。这种现象称为死锁，具体介绍和解决方案请参考下一节。  



# 死锁  

在学习本节时，请读者思考以下问题：  

1）为什么会产生死锁？产生死锁有什么条件？  

2）有什么办法可以解决死锁问题？  

学完本节，读者应了解死锁的由来、产生条件及基本解决方法，区分避免死锁和预防死锁。  

## 概念  

### 死锁的定义  

在多道程序系统中，由于进程的并发执行，极大提升了系统效率。然而，多个进程的并发执行也带来了新的问题一一死锁。所谓死锁，是指多个进程因竞争资源而造成的一种僵局（互相等待对方手里的资源），使得各个进程都被阻塞，若无外力干涉，这些进程都无法向前推进。  

下面通过一些实例来说明死锁现象。  

先看生活中的一个实例。在一条河上有一座桥，桥面很窄，只能容纳一辆汽车通行。若有两辆汽车分别从桥的左右两端驶上该桥，则会出现下述冲突情况：此时，左边的汽车占有桥面左边 的一段，右边的汽车占有桥面右边的一段，要想过桥则需等待左边或右边的汽车向后行驶以退出桥面。但若左右两边的汽车都只想向前行驶，则两辆汽车都无法过桥。  

在计算机系统中也存在类似的情况。例如，某计算机系统中只有一台打印机和一台输入设备，进程 $\mathrm{P}_{1}$ 正占用输入设备，同时又提出使用打印机的请求，但此时打印机正被进程 $\mathrm{P}_{2}$ 所占用，而 $\mathrm{P}_{2}$ 在未释放打印机之前，又提出请求使用正被 $\mathrm{P}_{1}$ 占用的输入设备。这样，两个进程相互无休止地等待下去，均无法继续向前推进，此时两个进程陷入死锁状态。  

### 死锁与饥饿  

一组进程处于死锁状态是指组内的每个进程都在等待一个事件，而该事件只可能由组内的另一个进程产生。与死锁相关的另一个问题是饥饿，即进程在信号量内无穷等待的情况。  
产生饥饿的主要原因是：当系统中有多个进程同时审请某类资源时，由分配策略确定资源分配给进程的次序，有的分配策略可能是不公平的，即不能保证等待时间上界的存在。在这种情况下，即使系统未发生死锁，某些进程也可能长时间等待。当等待时间给进程的推进带来明显影响时，称发生了饥饿。例如，当有多个进程需要打印文件时，若系统分配打印机的策略是最短文件优先，则长文件的打印任务将因短文件的源源不断到来而被无限期推迟，最终导致饥饿，甚至“饿死”。饥饿并不表示系统一定死锁，但至少有一个进程的执行被无限期推迟。  

死锁和饥饿的共同点都是进程无法顺利向前推进的现象。  

死锁和饥饿的主要差别： $\textcircled{\scriptsize{1}}$ 发生饥饿的进程可以只有一个；而死锁是因循环等待对方手里的资源而导致的，因此，如果有死锁现象，那么发生死锁的进程必然大于或等于两个。 $\circledcirc$ 发生饥饿的进程可能处于就绪态（长期得不到CPU，如SF算法的问题），也可能处于阻塞态（如长期得不到所需的I/O设备，如上述举例）：而发生死锁的进程必定处于阻塞态。  

### 死锁产生的原因  

>#### pro: 单类资源竞争时发生死锁的临界条件的分析（2009、2014）  

#### 系统资源的竞争  

通常系统中拥有的不可剥夺资源（如磁带机、打印机等），其数量不足以满足多个进程运行的需要，使得进程在运行过程中，会因争夺资源而陷入僵局。只有对不可剥夺资源的竞争才可能产生死锁，对可剥夺资源（如CPU和主存）的竞争是不会引起死锁的。  

#### 进程推进顺序非法  

请求和释放资源的顺序不当，也同样会导致死锁。例如，进程 $\mathrm{P}_{1},\mathrm{P}_{2}$ 分别保持了资源 $\mathbb{R}_{1},\mathbb{R}_{2}$ 而 $\mathrm{P}_{1}$ 申请资源 $\mathbb{R}_{2}$  $\mathrm{P}_{2}$ 申请资源 $\mathsf{R}_{1}$ 时，两者都会因为所需资源被占用而阻塞，于是导致死锁。  

信号量使用不当也会造成死锁。进程间彼此相互等待对方发来的消息，也会使得这些进程无法继续向前推进。例如，进程A等待进程B发的消息，进程B又在等待进程A发的消息，可以看出进程A和B不是因为竞争同一资源，而是在等待对方的资源导致死锁。  

### 死锁产生的必要条件  

产生死锁必须同时满足以下4个条件，只要其中任一条件不成立，死锁就不会发生。  

1）互斥条件。进程要求对所分配的资源（如打印机）进行排他性使用，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。 2）不可剥夺条件。进程所获得的资源在未使用完之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放）。3）请求并保持条件。进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。4）循环等待条件。存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。即存在一个处于等待态的进程集合 $\{\mathrm{P}_{1},\mathrm{P}_{2},\cdots,\mathrm{P}_{n}\}$ ，其中 $\mathrm{P}_{i}$ 等待的资源被 ${\mathrm{P}}_{i+1}\,\,\left(i=0,\,1,\cdots,n-1\,\right)$ 占有， $\mathrm{P}_{n}$ 等待的资源被 $\mathrm{{P_{0}}}$ 占有，如图2.13所示。  

直观上看，循环等待条件似乎和死锁的定义一样，其实不然。按死锁定义构成等待环所要求的条件更严，它要求 $\mathrm{P}_{i}$ 等待的资源必须由 $\mathrm{P}_{i+1}$ 来满足，而循环等待条件则无此限制。例如，系统中有两台输出设备， $\mathrm{{P_{0}}}$ 和 $\mathrm{P}_{K}$ 各占有一台，且 $K$ 不属于集合 $\{0,1$  $\cdots,n\}$ 。 $\mathrm{P}_{n}$ 等待一台输出设备，它可从 $\mathrm{{P_{0}}}$ 或 $\mathrm{P}_{K}$ 获得。因此，虽然 $\mathrm{P}_{n},\,\mathrm{P}_{0}$ 和其他一些进程形成了等待环，但 $\mathbf{P}_{K}$ 不在圈内，若 $\mathbf{P}_{K}$ 释放了输出设备，则可打破循环等待，如图2.14所示。因此循环等待只是死锁的必要条件。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/8382f5327fbc8823d52780a2673570e56eed41df9c30bb9c88f94f8a9c2dd8bf.jpg)  
图2.13循环等待  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/70b26273296eb44fa64f010de91910da39cd2519c4626ecd3dc2a1c826139085.jpg)  
图2.14满足条件但无死锁  

资源分配图含圈而系统又不一定有死锁的原因是，同类资源数大于1。但若系统中每类资源都只有一个资源，则资源分配图含圈就变成了系统出现死锁的充分必要条件。  

要注意区分不可剥夺条件与请求并保持条件。下面用一个简单的例子进行说明：若你手上拿着一个苹果（即便你不打算吃），别人不能将你手上的苹果拿走，则这就是不可剥夺条件；若你左手拿着一个苹果，充许你右手再去拿一个苹果，则这就是请求并保持条件。  

### 死锁的处理策略  

为使系统不发生死锁，必须设法破坏产生死锁的4个必要条件之一，或充许死锁产生，但当死锁发生时能检测出死锁，并有能力实现恢复。  

1）死锁预防。设置某些限制条件，破坏产生死锁的4个必要条件中的一个或几个。2）避免死锁。在资源的动态分配过程中，用某种方法防止系统进入不安全状态。  

3）死锁的检测及解除。无须采取任何限制性措施，允许进程在运行过程中发生死锁。通过系统的检测机构及时地检测出死锁的发生，然后采取某种措施解除死锁。  

预防死锁和避免死锁都属于事先预防策略，预防死锁的限制条件比较严格，实现起来较为简单，但往往导致系统的效率低，资源利用率低；避免死锁的限制条件相对宽松，资源分配后需要通过算法来判断是否进入不安全状态，实现起来较为复杂。  

死锁的几种处理策略的比较见表2.4。  

表2.4死锁处理策略的比较
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/66a9b4bf08130fd2eed0f5eceaf0f8e8b965b0314dc89eeca7ada07badd65762.jpg)  

## 死锁预防  

>#### pro：死锁预防的特点（2019）  

预防死锁的发生只需破坏死锁产生的4个必要条件之一即可。  

### 破坏互斥条件  

如果将只能互斥使用的资源改造为允许共享使用，那么系统不会进入死锁状态。但有些资源根本不能同时访问，如打印机等临界资源只能互斥使用。所以，破环互厅条件而预防死锁的方法不太可行，而且为了系统安全，很多时候还必须保护这种互斥性。  
### 破坏不可剥夺条件  

当一个已经保持了某些不可剥夺资源的进程，请求新的资源而得不到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。这意味着，进程已占有的资源会被暂时释放，或 者说是被剥夺了，从而破坏了不可剥夺条件。  

该策略实现起来比较复杂。释放已获得的资源可能造成前一阶段工作的失效，因此这种方法常用于状态易于保存和恢复的资源，如CPU的寄存器及内存资源，一般不能用于打印机之类的资源。反复地申请和释放资源既影响进程推进速度，又增加系统开销，进而降低系统吞吐量。  

### 破坏请求并保持条件  

要求进程在请求资源时不能持有不可剥夺资源，可以通过两种方法实现  

1）采用预先静态分配方法，即进程在运行前一次申请完它所需要的全部资源。在它的资源未满足前，不让它投入运行。在进程的运行期间，不会再提出资源请求，从而破坏“请求”条件。在等待期间，进程不占有任何资源，从而破坏了“保持”条件。2）允许进程只获得运行初期所需的资源后，便可开始运行。进程在运行过程中再逐步释放已分配给自已且已使用完毕的全部资源后，才能请求新的资源。  

方法一的实现简单，但缺点也显而易见，系统资源被严重浪费，其中有些资源可能仅在运行初期或快结束时才使用。而且还会导致“饥饿”现象，由于个别资源长期被其他进程占用，将导致等待该资源的进程迟迟不能开始运行。方法二则改进了这些缺点。  

### 破坏循环等待条件  

为了破坏循环等待条件，可以采用顺序资源分配法。首先给系统中的各类资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源（编号相同的资源）一次申请完。也就是说，一个进程只在已经占有小编号的资源时，才有资格申请更大编号的资源。按此规则，已持有大编号资源的进程不可能再逆向申请小编号的资源，因此不会产生循环等待的现象。  

这种方法的缺点：编号必须相对稳定，因此不便于增加新类型设备；尽管在编号时已考虑到大多数进程使用这些资源的顺序，但是进程实际使用资源的顺序还是可能和编号的次序不一致，这就会造成资源的浪费：此外，必须按规定次序申请资源，也会给用户编程带来麻烦。  

## 死锁避免  

避免死锁同样属于事先预防策略，但并不是事先采取某种限制措施破坏死锁的必要条件，而是在每次分配资源的过程中，都要分析此次分配是否会带来死锁风险，只有在不产生死锁的情况下，系统才会为其分配资源。这种方法所施加的限制条件较弱，可以获得较好的系统性能。  

### 系统安全状态  

避免死锁的方法中，充许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配的安全性。若此次分配不会导致系统进入不安全状态，则充许分配：否则让进程等待。  

所谓安全状态，是指系统能按某种进程推进顺序 $(\mathrm{P}_{1},\mathrm{P}_{2},\cdots,\mathrm{P}_{n})$ 为每个进程 $\mathbf{P}_{i}$ 分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利完成。此时称 $\mathrm{{\bfP}_{1},}$  $\mathrm{P}_{2},\cdots$  $\mathrm{P}_{n}$ 为安全序列（可能有多个）。若系统无法找到一个安全序列，则称系统处于不安全状态。  

>#### pro：系统安全状态的分析（2018）  

假设系统有三个进程 $\mathrm{P}_{1},\mathrm{P}_{2}$ 和 $\mathrm{P}_{3}$ ，共有12台磁带机。 $\mathrm{P_{1}}$ 需要10台， $\mathrm{P}_{2}$ 和 $\mathrm{P}_{3}$ 分别需要4台和9台。假设在 $T_{0}$ 时刻， $\mathrm{P}_{1},\mathrm{P}_{2}$ 和 $\mathrm{P}_{3}$ 已分别获得5台、2台和2台，尚有3台未分配，见表2.5。  
表2.5资源分配
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/bc78c805d412e3379a3876bc6c4a9a0145fa28c2d183574e3049744050b454f2.jpg)  

在 $T_{0}$ 时刻是安全的，因为存在一个安全序列 $\mathrm{P}_{2},\mathrm{P}_{1},\mathrm{P}_{3}$ ，只要系统按此进程序列分配资源，那么每个进程都能顺利完成。也就是说，当前可用资源数为3，先将3台分配给  $\mathrm{P}_{2}$  以满足其最大需 求， $\mathrm{P}_{2}$ 结束并归还资源后，系统有5台可用：接下来给 $\mathrm{P}_{1}$ 分配5台以满足其最大需求， $\mathrm{P}_{1}$ 结束并归还资源后，剩余10台可用；最后分配7台给 $\mathrm{P}_{3}$ ，这样 $\mathrm{P}_{3}$ 也能顺利完成。  

若在 $T_{0}$ 时刻后，系统分配1台给 $\mathrm{P}_{3}$ ，剩余可用资源数为2，此时系统进入不安全状态，因为此时已无法再我到一个安全序列。当系统进入不安全状态后，便可能导致死锁。例如，将剩下的2台分配给 $\mathrm{P}_{2}$ ，这样， $\mathrm{P}_{2}$ 完成后只能释放4台，既不能满足 $\mathrm{P}_{1}$ 又不能满足 $\mathrm{P}_{3}$ ，致使它们都无法推进到完成，彼此都在等待对方释放资源，陷入僵局，即导致死锁。  

如果系统处于安全状态，则一定不会发生死锁；若系统进入不安全状态，则有可能发生死锁（处于不安全状态未必发生死锁，但发生死锁时一定是处于不安全状态）。  

### 银行家算法  

>#### pro：银行家算法的特点（2013、2019）  

银行家算法是最著名的死锁避免算法，其思想是：将操作系统视为银行家，操作系统管理的资源视为银行家管理的资金，进程请求资源相当于用户向银行家贷款。进程运行之前先声明对各种资源的最大需求量，其数目不应超过系统的资源总量。当进程在运行中审请资源时，系统必须先确定是否有足够的资源分配给该进程。若有，再进一步试探在将这些资源分配给进程后，是否会使系统处于不安全状态。如果不会，才将资源分配给它，否则让进程等待。  

#### 数据结构描述  

假设系统中有 $n$ 个进程， $m$ 类资源，在银行家算法中需要定义下面4个数据结构。1）可利用资源向量Available：含有 $m$ 个元素的数组，其中每个元素代表一类可用的资源数目。Available[] $=K$ 表示此时系统中有 $K$ 个 $\mathrm{R}_{j}$ 类资源可用。2）最大需求矩阵Max： $_{n\times m}$ 矩阵，定义系统中 $n$ 个进程中的每个进程对 $m$ 类资源的最大需 $\mathrm{Max}[i,j]=K$   $\mathrm{P}_{i}$   $\mathrm{R}_{j}$   $K$  3）Allocation： $n{\times}m$ 矩阵，定义系统中每类资源当前已分配给每个进程的资源数。Allocation $\left[i,j\right]\mathrm{=}K$ 表示进程 $\mathrm{P}_{i}$ 当前已分得 $\mathbb{R}_{j}$ 类资源的数目为K。4）需求矩阵Need： $n{\times}m$  $\displaystyle{[\mathrm{eed}[i,j]=K}$ 示进程 $\mathrm{P}_{i}$ 还需要 $\mathsf{R}_{j}$ 类资源的数目为 $K_{\circ}$  

上述三个矩阵间存在下述关系：  

$$
\mathrm{Ned}=\mathrm{Max}\!-\!\mathrm{Allreduce}
$$  

通常，Max矩阵和Allocation矩阵是题中的已知条件，而求出Need矩阵是解题的第一步。  

#### 银行家算法描述  

设Request,是进程P,的请求向量，Request[] $=K$ 表示进程 $P_{j}$ 需要 $j$ 类资源 $K$ 个。当 $\mathrm{P}_{i}$ 发出资源请求后，系统按下述步骤进行检查：  

$\textcircled{\scriptsize{1}}$  $\leqslant$  $^{;(2)}$ ；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值。  
$\circledcirc$ 若Request[i] $\leqslant$ Available[]，则转向步骤 $\textcircled{3}$ ：否则，表示尚无足够资源， $\mathrm{P}_{i}$ 必须等待。 $\textcircled{3}$ 系统试探着将资源分配给进程 $\mathrm{P}_{i}$ ，并修改下面数据结构中的数值：  

Available  $=$  Available-Request,; Allocation[i,j]  $=$  Allocation[i,j]+Request,[]  $\mathrm{Ned}[i,j]=\mathrm{Ned}[i,j]-\mathrm{Reqest}_{i}[j];$  

$\textcircled{4})$ 系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式将资源分配给进程 $\mathrm{P}_{i},$ 以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程 $\mathrm{P}_{i}$ 等待。  

#### 安全性算法  

设置工作向量Work，表示系统中的剩余可用资源数目，它有 $m$ 个元素，在执行安全性算法前，令Work $=$ Available。  

$\textcircled{\scriptsize{1}}$ 初始时安全序列为空。  

$\circledcirc$ 从Need矩阵中找出符合下面条件的行：该行对应的进程不在安全序列中，而且该行小于或等于Work向量，找到后，将对应的进程加入安全序列：若找不到，则执行步骤 $^{(4)}$  

$\circledast$ 进程 $\mathrm{P}_{i}$ 进入安全序列后，可顺利执行，直至完成，并释放分配给它的资源，所以应执行Work $=$ Work $^+$ Allocation[i]，Allocation[i]Allocation，返回步骤 $\circledcirc$  $\textcircled{4}$ 若此时安全序列中已有所有进程，则系统处于安全状态，否则系统处于不安全状态。看完上面对银行家算法的过程描述后，可能会有眼花缭乱的感觉，现在通过举例来加深理解。  

### 安全性算法举例  

pro：银行家算法的安全序列分析（2011、2012、2018、2020、2022）  

假定系统中有5个进程 $\{\,\mathrm{P}_{0},\,\mathrm{P}_{1},\,\mathrm{P}_{2},\,\mathrm{P}_{3},\,\mathrm{P}_{4}\,\}$ 和三类资源{A，B,C)，各种资源的数量分别为10，5,7，在 $T_{0}$ 时刻的资源分配情况见表2.6。  

$T_{0}$ 时刻的安全性。利用安全性算法对 $T_{0}$ 时刻的资源分配进行分析。  

表2.6 $T_{0}$ 时刻的资源分配表
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/a8adbee6a8825ebe4dcf6c32cbd452fbdefa774952f8c76667dbb0a512dbe973.jpg)  

$\textcircled{\scriptsize{1}}$ 从题目中我们可以提取Max矩阵和Allocation矩阵，这两个矩阵相减可得到Need矩阵：  
$\circledcirc$ 然后，将Work向量与Need矩阵的各行进行比较，找出比Work矩阵小的行。例如，在初始时，  

$$
\begin{array}{r}{(3,3,2)>(1,2,2)}\\ {(3,3,2)>(0,1,1)}\end{array}
$$  

对应的两个进程分别为 $\mathrm{P_{1}}$ 和 $\mathrm{P}_{3}$ ，这里我们选择 $\mathrm{P}_{1}$ （也可选择 $\mathrm{P}_{3}$ ）暂时加入安全序列。 $\textcircled{3}$ 释放 $\mathrm{P_{1}}$ 所占的资源，即将 $\mathrm{P}_{1}$ 进程对应的Allocation矩阵中的一行与Work向量相加：  

$$
{\left(\begin{array}{l l l l}{3}&{3}&{2}\end{array}\right)}+{\left(\begin{array}{l l l}{2}&{0}&{0}\end{array}\right)}={\left(\begin{array}{l l l}{5}&{3}&{2}\end{array}\right)}=\operatorname{Work}
$$  

此时需求矩阵更新为（去掉了 $\mathrm{P}_{1}$ 对应的一行）：  

$$
\begin{array}{r}{\begin{array}{l l l}{\mathbf{P}_{0}\left[7}&{4}&{3}\\ {\mathbf{P}_{2}\left[6}&{0}&{0}\\ {\mathbf{P}_{3}\left[0}&{1}&{1}\\ {\mathbf{P}_{4}\left[4}&{3}&{1}\right]}\end{array}\right]}\end{array}
$$  

再用更新的Work向量和Need矩阵重复步骤 $\textcircled{2}$ 。利用安全性算法分析 $T_{0}$ 时刻的资源分配情况如表2.7所示，最后得到一个安全序列 $\{\mathrm{P_{1}},\mathrm{P_{3}},\mathrm{P_{4}},\mathrm{P_{2}},\mathrm{P_{0}}\}$  

表2.7 $T_{0}$ 时刻的安全序列的分析
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/934bf38cec4146d12fb5d939e6937668939e21fdacbbcdd945edd27be3a1bdfa.jpg)  

### 银行家算法举例  

安全性算法是银行家算法的核心，在银行家算法的题目中，一般会有某个进程的一个资源请求向量，读者只要执行上面所介绍的银行家算法的前三步，马上就会得到更新的Allocation 矩阵和Need矩阵，再按照上例的安全性算法判断，就能知道系统能否满足进程提出的资源请求。  

假设当前系统中资源的分配和剩余情况如表2.6所示。  

(1) $\mathrm{P_{1}}$ 请求资源： $\mathrm{P_{1}}$ Request $\mathbf{\Phi}_{1}(1,0,2)$ ，系统按银行家算法进行检查Request  $_1(1,0,2){\leqslant}\mathrm{Ned}_{1}(1,2,2)$  Reque  $\mathrm{st}_{1}(1,0,2){\leqslant}\mathrm{Available}_{1}(3,3,2)$  系统先假定可为 $\mathrm{P}_{1}$ 分配资源，并修改Available  $\mathbf{\Psi}=\mathbf{A}\mathbf{v}\mathbf{a}\mathbf{i}\mathbf{l}\mathbf{o}\mathbf{l}\mathbf{e}-\mathbf{R}\mathbf{e}\mathbf{q}\mathbf{e}\mathbf{s}\mathbf{t}_{1}\mathbf{=}(2,3,0)$  Alloc  $\mathrm{action}_{1}\!=\!\mathrm{Allreduce}_{1}+\mathrm{Recong}_{1}\!=\!(3,0,2)$   $\mathrm{Ned}_{1}\,{=}\,\mathrm{Ned}_{1}\,{-}\,\mathrm{Reqest}_{1}\,{=}\,(0,\,2,\,0)$  由此形成的资源变化情况如表2.6中的圆括号所示。令Work $=$ Available $\mathbf{\chi}=(2,3,0)$ ，再利用安全性算法检查此时系统是否安全，如表2.8所示。  
表2.8 $\mathbf{P}_{1}$ 申请资源时的安全性检查
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/11daabec04206bf68237fabfdbb67ee829540e13d552a5b8b4ac587ea8d7319c.jpg)  

由所进行的安全性检查得知，可找到一个安全序列 $\{\mathrm{P}_{1},\mathrm{P}_{3},\mathrm{P}_{4},\mathrm{P}_{0},\mathrm{P}_{2}\}$ 。因此，系统是安全的，可以立即将 $\mathrm{P}_{1}$ 所申请的资源分配给它。分配后系统中的资源情况如表2.9所示。  

表2.9为 $\mathbf{P}_{1}$ 分配资源后的有关资源数据
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/334aa28832f016418a963592eb9b59ff66a14a150d66d6179335758c310f4c07.jpg)  

（2) $\mathrm{P_{4}}$ 请求资源： $\mathrm{{P_{4}}}$ 发出请求向量Request4（3，3，0），系统按银行家算法进行检查Request  $(3,3,0){\leqslant}\mathrm{Ned}_{4}(4,3,1)$  Request $(3,3,0)\!>$ Available（2,3，0)，让 $\mathrm{{P_{4}}}$ 等待。(3) $\mathrm{{P_{0}}}$ 请求资源： $\mathrm{{P_{0}}}$ Re qu st $\phantom{}_{0}(0,2,0)$ ，系统按银行家算法进行检查：Request  $_{0}(0,2,0){\leqslant}\mathrm{Ned}_{0}(7,4,3)$  Requesto（0,2,0)≤Available（2,3,0) 系统暂时先假定可为 $\mathrm{{P_{0}}}$ 分配资源，并修改有关数据：Available  $=$  Available-Requesto=(2,1,0)  $\mathrm{Alllocation}_{0}\,{=}\,\mathrm{Alllocation}_{0}\,{+}\,\mathrm{Recong}_{0}\,{=}\,(0,3,0)$  Need $_0=$ Needo-Reques $\mathfrak{t}_{0}\!=\!(7,2,3)$ ，结果如表2.10所示。  

表2.10为 $\mathbf{P_{0}}$ 分配资源后的有关资源数据
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/6c035c506edf8b4ea581fe8a4957b7dc4d56ce1adbecab24ac8bff3825a908fb.jpg)  

进行安全性检查：可用资源Available $(2,1,0)$ 已不能满足任何进程的需要，系统进入不安全状态，因此拒绝 $\mathrm{{P_{0}}}$ 的请求，让 $\mathrm{{P_{0}}}$ 等待，Available，Allocation o，Need o。  

## 死锁检测和解除  

pro：死锁避免和死锁检测的区分（2015）  

前面介绍的死锁预防和避免算法，都是在为进程分配资源时施加限制条件或进行检测，若系统为进程分配资源时不采取任何预防或避免措施，则应该提供死锁检测和解除的手段。  
### 死锁检测  

>#### pro：死锁避免和死锁检测对比（2015）  

死锁避免和死锁检测的对比。死锁避免需要在进程的运行过程中一直保证之后不可能出现列锁，因此需要知道进程从开始到结束的所有资源请求。而死锁检测检测某个时刻是否发生死锁，不需要知道进程在整个生命周期中的资源请求，只需知道对应时刻的资源请求。  

>#### pro：多在资源竞争时发生死锁的临界条件分析（2016、2021)  

可用资源分配图来检测系统所处的状态是否为死锁状态。如图2.15（a所示，用圆圈表示一个进程，用框表示一类资源。由于一种类型的资源可能有多个，因此用框中的一个圆表示一类资源中的一个资源。从进程到资源的有向边称为请求边，表示该进程申请一个单位的该类资源；从资源到进程的边称为分配边，表示该类资源已有一个资源分配给了该进程。  

在图2.15(a)所示的资源分配图中，进程 $\mathrm{P_{1}}$ 已分得了两个 $\mathrm{R_{l}}$ 资源，并又请求一个 $\scriptstyle\mathrm{\mathrm{~R}}_{2}$ 资源；进程 $\mathrm{P}_{2}$ 分得了一个 $\mathsf{R}_{1}$ 资源和一个 $\mathrm{R}_{2}$ 资源，并又请求一个 $\mathrm{R_{1}}$ 资源。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/77b5c15fac24c0dd51fd809180026878402240b17f0e37a3fc36084e15d76733.jpg)  
图2.15资源分配示例  

简化资源分配图可检测系统状态S是否为死锁状态。简化方法如下：  

1）在资源分配图中，找出既不阻塞又不孤立的进程 $\mathrm{P}_{i}$ （找出一条有向边与它相连，且该有向边对应资源的申请数量小于或等于系统中已有的空闲资源数量，如在图2.15(a)中， $\mathrm{R}_{1}$ 没有空闲资源， $\mathbb{R}_{2}$ 有一个空闲资源。若所有连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源）。消去它所有的请求边和分配边，使之成为孤立的节点。在图2.15(a)中， $\mathrm{P}_{1}$ 是满足这一条件的进程节点，将 $\mathrm{P}_{1}$ 的所有边消去，便得到图2.15(b)所示的情况。  

这里要注意一个问题，判断某种资源是否有空闲，应该用它的资源数量减去它在资源分配图中的出度，例如在图2.15(a)中， $\mathsf{R}_{1}$ 的资源数为3，而出度也为3，所以 $\mathsf{R}_{1}$ 没有空闲资源， $\mathbb{R}_{2}$ 的资源数为2，出度为1，所以 $\scriptstyle\mathrm{\mathrm{~R}}_{2}$ 有一个空闲资源。  

2）进程 $\mathrm{P}_{i}$ 所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在图2.15(a中， $\mathrm{P}_{2}$ 就满足这样的条件。根据1）中的方法进行一系列简化后，若能消去图中所有的边，则称该图是可完全简化的，如图2.15（c所示。  

S为死锁的条件是当且仅当S状态的资源分配图是不可完全简化的，该条件为死锁定理。  

### 死锁解除  

>#### pro：解除死锁的方式（2019）  

一旦检测出死锁，就应立即采取相应的措施来解除死锁。死锁解除的主要方法有：  
1）资源剥夺法。挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源而处于资源乏的状态。  

>##### attention：  

在资源分配图中，用死锁定理化简后，还有边相连的那些进程就是死锁进程。  

2）撤销进程法。强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。这种方式实现简单，但付出的代价可能很大，因为有些进程可能已经接近结束，一旦被终止，以后还得从头再来。  

3）进程回退法。让一个或多个死锁进程回退到足以回避死锁的地步，进程回退时自愿释放资源而非被剥夺。要求系统保持进程的历史信息，设置还原点。  

## 本节小结  

本节开头提出的问题的参考答案如下。  

1）为什么会广生死锁！广生死锁有什么余件？  

由于系统中存在一些不可剥夺资源，当两个或两个以上的进程占有自身的资源并请求对方的资源时，会导致每个进程都无法向前推进，这就是死锁。死锁产生的必要条件有4个，分别是互厅条件、不剥夺条件、请求并保持条件和循环等待条件。  

互斥条件是指进程要求分配的资源是排他性的，即最多只能同时供一个进程使用。  

不剥夺条件是指进程在使用完资源之前，资源不能被强制夺走。请求并保持条件是指进程占有自身本来拥有的资源并要求其他资源。循环等待条件是指存在一种进程资源的循环等待链。  

2）有什么办法可以解决死锁问题？  

死锁的处理策略可以分为预防死锁、避免死锁及死锁的检测与解除。死锁预防是指通过设立一些限制条件，破坏死锁的一些必要条件，让死锁无法发生。死锁避免指在动态分配资源的过程中，用一些算法防止系统进入不安全状态，从而避免死锁，死锁的检测和解除是指在死锁产生前不采取任何措施，只检测当前系统有没有发生死锁，若有，则采取一些措施解除死锁。  



# 本章疑难点  

### 进程与程序的区别与联系  

1）进程是程序及其数据在计算机上的一次运行活动，是一个动态的概念。进程的运行实体是程序，离开程序的进程没有存在的意义。从静态角度看，进程是由程序、数据和进程控制块（PCB）三部分组成的。而程序是一组有序的指令集合，是一种静态的概念。  

2）进程是程序的一次执行过程，它是动态地创建和消亡的，具有一定的生命周期，是暂时存在的：而程序则是一组代码的集合，是永久存在的，可长期保存。  

3）一个进程可以执行一个或几个程序，一个程序也可构成多个进程。进程可创建进程，而程序不可能形成新的程序。  

4）进程与程序的组成不同。进程的组成包括程序、数据和PCB。  

### 银行家算法的工作原理  

银行家算法的主要思想是避免系统进入不安全状态。在每次进行资源分配时，它首先检查系统是否有足够的资源满足要求，若有则先进行试分配，并对分配后的新状态进行安全性检查。若新状态安全，则正式分配上述资源，否则拒绝分配上述资源。这样，它保证系统始终处于安全状态，从而避免了死锁现象的发生。  

### 进程同步、互斥的区别和联系  

并发进程的执行会产生相互制约的关系：一种是进程之间竞争使用临界资源，只能让它们遂个使用，这种现象称为互斥，是一种竞争关系；另一种是进程之间协同完成任务，在关键点上等待另一个进程发来的消息，以便协同一致，是一种协作关系。  