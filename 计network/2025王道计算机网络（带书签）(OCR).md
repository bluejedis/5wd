
# 第1章计算机网络体系结构  

# 【考纲内容】  

（一）计算机网络概述计算机网络的概念、组成与功能；计算机网络的分类：计算机网络的性能指标二）计算机网络体系结构与参考模型计算机网络分层结构：计算机网络协议、接口、服务的概念：ISO/OSI TCP/IP模型  

# 【复习提示】  

本章主要介绍计算机网络体系结构的基本概念，读者可以在理解的基础上适当地记忆。重点掌握网络的分层结构（包括5层和7层结构），尤其是ISO/OSI参考模型各层的功能，以及相关协议、接口和服务等概念。熟悉有关网络的各种性能指标，特别是时延、带宽、速率等的计算。  

# 1.1计算机网络概述  

# 1.1.1计算机网络的概念  

一般认为，计算机网络是一个将众多分散的、自治的计算机系统，通过通信设备与线路连接起来，由功能完善的软件实现资源共享和信息传递的系统。  

计算机网络（简称网络）由若干结点（node，或译为节点）和连接这些结点的链路（link）组成。网络中的结点可以是计算机、集线器、交换机或路由器等。网络之间还可通过路由器互连构成一个覆盖范围更广的计算机网络，这样的网络称为互连网（internet）。于是，我们可以这样理解：网络把许多计算机连在一起，而互连网则把许多网络通过路由器连在一起。  

请读者注意以下两个意思相差很大的名词：internet和Internet。  

internet（互连网）是一个通用名词，泛指由多个计算机网络互连而成的计算机网络。在这些网络之间可以使用任意的通信协议作为通信规则，不一定非要使用TCP/IP协议。  

Internet（互联网或因特网）则是一个专用名词，指当前全球最大的、开放的、由众多网络和路由器互连而成的特定计算机网络，它采用TCP/IP协议族作为通信规则。  

# 1.1.2计算机网络的组成  

从不同的角度看，可将计算机网络的组成分为如下几类。  
1）从组成部分看，计算机网络主要由硬件、软件、协议三大部分组成。硬件主要由主机（也称端系统）、通信链路（如双绞线、光纤）、交换设备（如路由器、交换机等）和通信处理机（如网卡）等组成。软件主要包括各种实现资源共享的软件和方便用户使用的各利工具软件（如E-mail程序、FTP程序、聊天程序等）。协议是计算机网络的核心，如同交通规则制约汽车驾驶一样，协议规定了网络传输数据时所遵循的规范。  

2）从工作方式看，计算机网络（这里主要指Intermet，即互联网）可分为边缘部分和核心部分。边缘部分由所有连接到互联网上的供用户直接使用的主机组成，用来进行通信（如传输数据、音频或视频）和资源共享；核心部分由大量网络和连接这些网络的路由器组成，它为边缘部分提供连通性和交换服务。图1.1给出了这两部分的示意图。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/287998ad20487ffe1402b983737c30bf30a87d0899b167101b7b13670e260760.jpg)  
图1.1互联网的核心部分与边缘部分  

3）从功能组成看，计算机网络由通信子网和资源子网组成。通信子网由各种传输介质、通信设备和相应的网络协议组成，它使网络具有数据传输、交换、控制和存储的能力，实现联网计算机之间的数据通信。资源子网是实现资源共享功能的设备及其软件的集合，向网络用户提供共享其他计算机上的硬件资源、软件资源和数据资源的服务。  

# 1.1.3计算机网络的功能  

计算机网络的功能很多，现今的很多应用都与网络有关。主要有以下五大功能。  

# 1.数据通信  

数据通信是计算机网络最基本和最重要的功能，用来实现联网计算机之间各种信息的传输：并联系分散在不同地理位置的计算机，进行统一的调配、控制和管理。例如，文件传输、电子邮件等应用，离开了计算机网络就无法实现。  

# 2.资源共享  

资源共享既可是软件共享、数据共享，又可是硬件共享。它使计算机网络中的资源互通有无、分工协作，从而极大地提高了硬件资源、软件资源和数据资源的利用率。  

# 3.分布式处理  

当计算机网络中的某个计算机系统负荷过重时，可将其处理的某个复杂任务分配给网络中的其他计算机系统，从而利用空闲计算机资源来提高整个系统的利用率。  

# 4.提高可靠性  

计算机网络中的各台计算机可以通过网络互为替代机。  

# 5.负载均衡  

将工作任务均衡地分配给计算机网络中的各台计算机。  
除了以上几大主要功能，计算机网络还可实现电子化办公与服务、远程教育、娱乐等功能，满足了社会的需求，方便了人们的学习、工作和生活，具有巨大的经济效益。  

# 1.1.4 电路交换、报文交换与分组交换  

在网络核心部分起重要作用的是路由器（router），它对收到的分组进行存储转发来实现分组交换。要了解分组交换的原理，首先就要学习电路交换的相关概念。  

# 1.电路交换  

最典型的电路交换网是传统电话网，如图1.2所示。从通信资源分配的角度看，交换就是按照某种方式动态地分配传输线路的资源。电路交换分为三步：连接建立、数据传输和连接释放。在进行数据传输前，两个结点之间必须先建立一条专用（双方独占）的物理通信路径（由通信双方之间的交换设备和链路逐段连接而成），该路径可能经过许多中间结点。在数据传输过程中，这一物理通信路径始终被用户独占，直到通信结束后才被释放。  

在电路交换的整个通信阶段，比特流连续地从源点直达终点，就好像在一个管道中传送。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f245e6639db9fb4e87d89db234663c1b92adb3022eb928c2b1f53e57f1c3bbcc.jpg)  
图1.2电路交换示意图  

电路交换技术的优点如下：  

1）通信时延小。因为通信线路为通信双方专用，数据直达，所以传输时延非常小。2）有序传输。双方通信时按发送顺序传送数据，不存在失序问题。3）没有冲突。不同的通信双方拥有不同的信道，不会出现争用物理信道的问题。4）适用范围广。电路交换既适用于传输模拟信号，又适用于传输数字信号。5）实时性强。通信双方之间的物理通路一旦建立，双方就可随时通信。6）控制简单。电路交换的交换设备（交换机等）及控制均较简单。  

电路交换技术的缺点如下：  

1）建立连接时间长。电路交换的平均连接建立时间对计算机通信来说太长。2）线路利用率低。物理通路被通信双方独占，即使线路空闲，也不能供其他用户使用。3）灵活性差。物理通路中的任何一点出现故障，就必须重新拨号建立新的连接。4）难以规格化。不同类型、不同规格、不同速率的终端很难相互进行通信。5）难以实现差错控制。中间结点不具备存储和检验数据的能力，无法发现并纠正错误。  

注意，在电路交换中，电路建立后，除源结点和目的结点外，电路上的任何结点都采取“直通方式”接收数据和发送数据，即不存在存储转发所耗费的时间。  

# 2.报文交换  

>#### pro：报文交换网中存储转发、数据传送时间的计算（2013）  

数据交换的单位是报文，用户数据加上源地址、目的地址等信息后，后封装成报文（message）。报文交换采用存储转发技术，整个报文先传送到相邻的结点，全部存储后查找转发表，转发到下一个结点，如此重复，直至到达目的结点。每个报文都可单独选择到达目的结点的路径。  
报文交换技术的优点如下：  

1）无须建立连接。通信前无须建立连接，没有建立连接时延，用户可随时发送报文。2）动态分配线路。交换设备存储整个报文后，选择一条合适的空闲线路，转发报文。3）线路可靠性高。若某条传输路径发生故障，则可重新选择另一条路径传输数据。4）线路利用率高。报文在哪段链路上传送时才占用这段链路的通信资源。5）提供多目标服务。一个报文可以同时发送给多个目的地址。  

报文交换技术的缺点如下：  

1）转发时延高。交换结点要将报文整体接收完后，才能查找转发表转发到下一个结点。 2）缓存开销大。报文的大小没有限制，这就要求交换结点拥有较大的缓存空间。3）错误处理低效。报文较长时，发生错误的概率相对更大，重传整个报文的代价也很大。  

# 3.分组交换  

>#### pro：分组交换网中存储转发、数据传送时间的计算（2010、2013、2023）  

分组交换也采用存储转发技术，但解决了报文交换中报文过长的问题。若报文太长，则对交换结点的缓存容量就有很大的需求，在错误处理方面也比较低效。源结点在发送之前，先把较长的报文划分成若干较小的等长数据段，在每个数据段前面添加一些由必要控制信息（如源地址、目的地址和编号信息等）组成的首部，构成分组（Packet），如图1.3所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/2d299f322302399b30b0f2b21d0337245ceeccac10e0720f8635d7b7c8877980.jpg)  
图1.3构成分组的过程  

源结点将分组发送到分组交换网中，分组交换网中的分组交换机收到一个分组后，先将其缓存，然后从其首部中提取目的地址，据此查找自己的转发表，再后将分组转发给下一个分组交换机。经过多个分组交换机的存储转发后，分组最终到达目的结点。  

分组交换技术的优点如下：  

1）无建立时延。通信前无须建立连接，没有建立连接时延，用户可随时发送分组。  

2）线路利用率高。分组在哪段链路上传送时才占用这段链路的通信资源。相比采用电路交 换传送突发式的计算机数据，分组交换的通信线路利用率大大提高。  

3）简化了存储管理（相对于报文交换）。因为分组的长度固定，相应缓冲区的大小也固定，在交换结点中存储器的管理通常被简化为对缓冲区的管理，相对比较容易。  

4）加速传输。分组是逐个传输的，可以使后一个分组的存储操作与前一个分组的转发操作并行，这种流水线方式减少了报文的传输时间。此外，传输一个分组比传输一次报文所需的缓冲区小得多，这样，因缓冲区不足而等待发送的概率及时间必然也少得多。  

5）减小了出错概率和重发数据量。因为分组较短，其出错概率必然减小，所以每次重发的数据量也就大大减少，这样不仅提高了可靠性，而且减小了传输时延。  

分组交换技术的缺点如下：  

1）存在存储转发时延。尽管分组交换比报文交换的传输时延小，但相对于电路交换仍存在  
存储转发时延，且其结点交换机必须具有更强的处理能力。2）需要传输额外的信息量。每个小数据段都要加上控制信息以构成分组，这使得传送的信息量增大了  $5\%\!\sim\!10\%$  ，进而使得控制复杂，降低了通信效率，增大了处理的时延。 3）当分组交换网采用数据报服务时，可能出现失序、丢失或重复分组的情况，分组到达目的结点时，要对分组按编号进行排序等工作，而这些工作很麻烦。若采用虚电路服务，则虽然没有失序问题，但有呼叫建立、数据传输和虚电路释放三个过程。  

图1.4给出了三种数据交换方式的比较。当要传送的数据量很大且其传送时间远大于呼叫时间时，采用电路交换较为合适。当端到端的通路由多段链路组成时，采用分组交换传送数据较为 合适。从提高整个网络的信道利用率看，报文交换和分组交换优于电路交换，其中分组交换比报文交换的时延小，尤其适合计算机之间的突发式数据通信。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/cc1c6c84bafb4c42ddde56da97766fa80096e449b7643d1105d033c641008b5a.jpg)  
图1.4三种数据交换方式的比较  

# 1.1.5计算机网络的分类  

# 1.按分布范围分类  

1）广域网（WAN）。广域网的任务是提供长距离通信，运送主机所发送的数据，其覆盖范围通常是直径为几十到几千千米的区域。广域网是互联网的核心部分。连接广域网的各结点交换机的链路一般都是高速链路，具有较大的通信容量。  

2）城域网（MAN)。城域网的覆盖范围可以跨越几个街区甚至整个城市，覆盖区域的直径为 $5{\sim}50\mathrm{km}$ 。城域网大多采用以太网技术，因此有时也常并入局域网的范围讨论。  

3）局域网（LAN）。局域网一般用主机通过高速线路相连，覆盖范围较小，通常是直径为几十到几千米的区域。传统上，局域网使用广播技术，而广域网使用交换技术。  

4）个人区域网（PAN)。个人区域网是指在个人工作的地方将消费电子设备（如平板电脑、智能手机等）用无线技术连接起来的网络，也称无线个人区域网（WPAN）。  

# 2.按传输技术分类  

1）广播式网络。所有联网计算机都共享一个公共通信信道。当一台计算机利用共享通信信道发送报文分组时，所有其他计算机都会“收听”到这个分组。接收到该分组的计算机将通过检查目的地址来决定是否接收该分组。局域网基本上都采用广播式通信技术，广域  
两中的元绒、上生通后两网给世木用厂猫式通后权不。  

2）点对点网络。每条物理线路连接一对计算机。若通信的两台主机之间没有直接连接的线路，则它们之间的分组传输就要通过中间结点进行存储和转发，直至目的结点。  

# 3.按拓扑结构分类  

网络拓扑结构是指由网中结点（路由器、主机等）与通信线路之间的几何关系表示的网络结构，主要指通信子网的拓扑结构。按网络的拓扑结构，可分为总线形、星形、环形和网状网络等，如图1.5所示。星形、总线形和环形网络多用于局域网，网状网络多用于广域网。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/03dad756ed141050172e537aa8bcf856a949704d26cadf944b7715839d605a68.jpg)  
图1.5几种不同的网络拓扑结构  

1）总线形网络。用单根传输线把计算机连接起来。优点是建网容易、增/减结点方便、节省线路。缺点是重负载时通信效率不高、总线任意一处对故障敏感。2）星形网络。每个终端或计算机都以单独的线路与中央设备相连。中央设备一般是交换机或路由器。优点是便于集中控制和管理。缺点是成本高、中央设备对故障敏感。3）环形网络。所有计算机接口设备连接成一个环。环形网络最典型的例子是令牌环局域网。环既可以是单环，又可以是双环，环中信号是单向传输的。4）网状网络。一般情况下，每个结点至少有两条路径与其他结点相连，多用在广域网中。其有规则型和非规则型两种。优点是可靠性高。缺点是控制复杂、线路成本高。  

以上4种基本的网络拓扑结构可以互连为更复杂的网络。  

# 4.按使用者分类  

1）公用网（PublicNetwork）。指电信公司出资建造的大型网络。“公用”的意思是指所有愿意按电信公司的规定缴纳费用的人都可使用这种网络。2）专用网（PrivateNetwork）。指某个部门为满足本单位特殊业务的需要而建造的网络。这种网络不向本单位外的人提供服务，如铁路、电力、军队等部门的专用网。  

# 5.按传输介质分类  

传输介质可分为有线和无线两大类，因此网络可分为有线网络和无线网络。有线网络又可分为双绞线网络、同轴电缆网络等，而无线网络又可分为蓝牙、微波、无线电等类型。  

# 1.1.6计算机网络的性能指标  

性能指标从不同方面度量计算机网络的性能。常用的性能指标如下。  

1）速率（Speed）。指连接到网络上的结点在数字信道上传送数据的速率，也称数据传输速率、数据传输率、数据率或比特率，单位为b/s（比特/秒）或bit/s（有时也写为bps）。当数据率较高时，可用 $\mathrm{{kb/s}}$  $(\mathrm{k}=10^{3}$ )、 $\mathrm{{Mb/s}}$  $(\mathbf{M}=10^{6})$ ）或Gb/s（ $\mathrm{{(G}}\mathrm{{=}}{10}^{\mathrm{{9}}}\mathrm{{)}}$ ）表示。2）带宽（Bandwidth）。带宽原本表示通信线路允许通过的信号频率范围，单位是赫兹 $\mathrm{(Hz}$ 但在计算机网络中，带宽表示网络的通信线路所能传送数据的能力，是数字信道所能传送的“最高数据传输速率”的同义语，单位是比特/秒（b/s）。  
3）吞吐量（Throughput）。指单位时间内通过某个网络（或信道、接口）的实际数据量。吞吐量常用在对实际网络的测量中，受网络带宽的限制。  

4）时延（Delay）。指数据（一个报文或分组）从网络（或链路）的一端传送到另一端所需的总时间，它由4部分构成：发送时延、传播时延、处理时延和排队时延。  

>#### pro：分组交换网中各种时延的计算（2010、2013、2023）  

发送时延，也称传输时延。结点将分组的所有比特推向链路所需的时间，即从发送分组的第一个比特算起，到该分组的最后一个比特发送完毕所需的时间。发送时延 $=$ 分组长度/发送速率传播时延。电磁波在信道（传输介质）中传播一定的距离所花的时间，即一个比特从链路的一端传播到另一端所需的时间。传播时延 $=$ 信道长度/电磁波在信道上的传播速率  

# 注意  

区分传输时延和传播时延。传输时延是路由器将分组推出所需的时间，是分组长度和链路传输速率的函数。传播时延是一个比特从一台路由器传播至另一台路由器所需的时间，是两台路由器之间距离的函数，而与分组长度或链路传输速率无关。  

处理时延。数据在交换结点为存储转发而进行的一些必要处理所花的时间。例如，分析分组的首部、从分组中提取数据、差错检验或查找合适的路由等。排队时延。分组在进入路由器后要先在输入队列中排队等待处理。路由器确定转发 端口后，还要在输出队列中排队等待转发。这就产生了排队时延。  

因此，数据在网络中经历的总时延就是以上4部分时延之和：总时延 $=$ 发送时延 $^+$ 传播时延 $^+$ 处理时延 $^+$ 排队时延  

# 注意  

处理时延和排队时延通常可忽略不计（除非另有说明）。  

5）时延带宽积。指发送端发送的第一个比特即将到达终点时，发送端已发出了多少比特，又称以比特为单位的链路长度，即时延带宽积 $=$ 传播时延 $\times$ 信道带宽。  

如图1.6所示，考虑一个代表链路的圆柱形管道，其长度表示链路的传播时延，横截面积表示链路带宽，则时延带宽积表示该管道可以容纳的比特数量。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/e564fa3d8c71bff7066a52d237c4d5c1866dd55d3140f45a2653a5b0f92a936d.jpg)  
图1.6链路就像一条空心管道  

6）往返时延（Round-TripTime，RTT）。指从发送端发出一个短分组，到发送端收到来自接收端的确认（接收端收到数据后立即发送确认）总共经历的时延。在互联网中，往返时延还包括各中间结点的处理时延、排队时延及转发数据时的发送时延。  

7）信道利用率。用以指出某个信道有百分之多少的时间是有数据通过的。信道利用率 $=$ 有数据通过时间/（有+无）数据通过时间  
 
# 1.2计算机网络体系结构与参考模型  

# 1.2.1计算机网络分层结构  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/96aa5fefc2bfd988ed66f2d6416a1098a86c3623d25175b86cac320a265ba74c.jpg)  

网络体系结构的定义（2010）  

计算机网络的各层及其协议的集合称为网络的体系结构（Architecture）。换言之，计算机网络的体系结构就是这个计算机网络及其所应完成的功能的精确定义。要强调的是，这些功能究竟是用何种硬件或软件完成的，是一个遵循这种体系结构的实现（Implementation）问题。体系结构是抽象的，而实现则是具体的，是真正在运行的计算机硬件和软件。计算机网络体系结构通常都具有可分层的特性，它将复杂的大系统分成若干较容易实现的层次。  

分层的基本原则如下：  

1）每层都实现一种相对独立的功能，降低大系统的复杂度。  

2）各层之间的接口自然清晰，易于理解，相互交流尽可能少。  

3）各层功能的精确定义独立于具体的实现方法，可以采用最合适的技术来实现，  

4）保持下层对上层的独立性，上层单向使用下层提供的服务。  

5）整个分层结构应能促进标准化工作。  

在计算机网络分层结构中，第 $n$ 层中的活动元素通常称为第 $n$ 层实体。具体来说，实体指任何可发送或接收信息的硬件或软件进程，通常是某个特定的软件模块。不同机器上的同一层称为对等层，同一层的实体称为对等实体。第 $n$ 层实体实现的服务为第 $n+1$ 层所用。在这种情况下，第 $n$ 层称为服务提供者，第 $n+1$ 层则服务于用户。  

在计算机网络体系结构中，对等层之间传送的数据单位称为该层的协议数据单元（PDU），第 $n$ 层的PDU记为 $n$ -PDU。各层的PDU都分为数据和控制信息两部分。  

服务数据单元（SDU)：为完成用户所要求的功能而传送的数据。第 $n$ 层的SDU记为 $n$ SDU。协议控制信息（PCI)：控制协议操作的信息。第 $n$ 层的PCI记为 $n$ PCI  

每层的协议数据单元都有一个通俗的名称，如物理层的PDU称为比特流，数据链路层的PDU称为顿，网络层的PDU称为分组，传输层的PDU称为报文段。  

当在各层之间传输数据时，将从第 $n+1$ 层收到的PDU作为第 $n$ 层的SDU，加上第 $n$ 层的PCI，就封装成了第 $n$ 层的PDU，交给第 $n-1$ 层后作为SDU发送，接收方接收时做相反的处理因此可知三者的关系为 $n{\mathrm{-SDU}}+n{\mathrm{-CI}}=n{\mathrm{-PDU}}\,{=}\,(n-1)$ -SDU，其变换过程如图1.7所示。  

具体地，层次结构的含义包括如下几方面：  

1）第 $n$ 层的实体不仅要使用第 $n-1$ 层的服务来实现自身定义的功能，而且要向第 $n+1$ 层提供本层的服务，该服务是第 $n$ 层及其下面各层提供的服务总和。  

2）最低层只提供服务，是整个层次结构的基础：最高层面向用户提供服务。3）上一层只能通过相邻层间的接口使用下一层的服务，而不能调用其他层的服务。  

4）当两台主机通信时，对等层在逻辑上有一个直接信道，表现为能直接将信息传送到对方。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/b77b831057ee90ae6a2d9b9cae1dcbd0c76b5de0a6deea4a2c4d15026db44075.jpg)  
图1.7网络各层数据单元的联系  

# 1.2.2计算机网络协议、接口、服务的概念  

# 1.协议  

要在网络中做到有条不紊地交换数据，就必须遵循一些事先约定好的规则，其规定了所交换数据的格式及有关的同步问题。为了在网络中进行数据交换而建立的这些规则、标准或约定称为网络协议（NetworkProtocol），是控制在对等实体之间进行通信的规则的集合，是水平的。不对等实体之间是没有协议的，如用TCP/IP协议栈通信的两个结点A和结点B，结点A的传输层和结点B的传输层之间存在协议，但结点A的传输层和结点B的网络层之间不存在协议。  

协议由语法、语义和同步三部分组成  

>#### pro：同步的定义（2020）  

1）语法。数据与控制信息的格式。例如，TCP报文段格式就是由TCP协议的语法定义的。  

2）语义。即需要发出何种控制信息、完成何种动作及做出何种应答。例如，在建立TCP连接的三次握手时所执行的操作就是由TCP协议的语义定义的。  

3）同步（或时序）。执行各种操作的条件、时序关系等，即事件实现顺序的详细说明。例如，建立TCP连接的三次握手操作的时序关系就是由TCP协议的同步定义的。  

# 2.接口  

同一结点内相邻两层的实体交换信息的逻辑接口称为服务访问点（ServiceAccessPoint，SAP）。每层只能为紧邻的层之间定义接口，而不能跨层定义接口。服务是通过SAP提供给上层使用的，第 $n$ 层的SAP就是第 $n+1$ 层可以访问第 $n$ 层服务的地方。例如，在本书描述的5层体系结构中，数据链路层的服务访问点为帧的“类型”字段，网络层的服务访问点为IP数据报的“协议”字段，传输层的服务访问点为“端口号”字段。  

# 3.服务  

服务是指下层为紧邻的上层提供的功能调用，是垂直的。对等实体在协议的控制下，使得本层能为上层提供服务，但要实现本层协议，还需要使用下层提供的服务。当上层使用下层提供的服务时，必须与下层交换一些命令，这些命令称为服务原语。  
OSI参考模型将原语划分为四类：  

1）请求（Reguest）。由服务用户发往服务提供者，请求完成某项工作。2）指示（Indication）。由服务提供者发往服务用户，指示用户做某件事情。3）响应（Response）。由服务用户发往服务提供者，作为对指示的响应。  

4）证实（Confirmation）。由服务提供者发往服务用户，作为对请求的证实。  

这四类原语用于不同的功能，如建立连接、传输数据和断开连接等。有应答服务包括全部四类原语，而无应答服务则只有请求和指示两类原语。四类原语的关系如图1.8所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c465c00fecdaace844348a56599b0bfb30ca06ba294b146e002eeb1081a634b4.jpg)  
图1.8四类原语的关系  

注意，协议和服务概念上是不一样的。首先，只有本层协议的实现才能保证向上一层提供服务。本层的服务用户只能看见服务而无法看见下面的协议，即下面的协议对上层的服务用户是透明的。其次，协议是“水平的"，即协议是控制对等实体之间通信的规则。但是，服务是“垂真的”，即服务是由下层通过层间接口向上层提供的。另外，并非在一层内完成的全部功能都称为服务，只有那些能够被高一层实体“看得见”的功能才称为服务。  

协议、接口、服务三者之间的关系如图1.9所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/626bd9b77ec2839f6bcc9d127b243ba971ad814f5bd6d44cd4ca7a6a1070033c.jpg)  
图1.9协议、接口、服务三者之间的关系  

计算机网络提供的服务可按以下三种方式分类。  

（1）面向连接服务与无连接服务  

在面向连接服务中，通信前双方必须先建立连接，分配相应的资源（如缓冲区），以保证通信能正常进行，传输结束后释放连接和占用的资源。因此这种服务可分为连接建立、数据传输和连接释放三个阶段。例如，TCP就是一种面向连接服务的协议。  

在无连接服务中，通信前双方不需要先建立连接，需要发送数据时可直接发送，将每个带有目的地址的包（报文分组）传送到线路上，由系统选定路线进行传输。这种服务常被描述为“尽最大努力交付”，是一种不可靠的服务。例如，IP、UDP就是一种无连接服务的协议。  

# （2）可靠服务和不可靠服务  

可靠服务是指网络具有纠错、检错、应答机制，能保证数据正确、可靠地传送到目的地。不可靠服务是指网络只是尽量让数据正确、可靠地传送到目的地，是一种尽力而为的服务。  

对于提供不可靠服务的网络，其网络的正确性、可靠性要由应用或用户来保障。例如，用户收到信息后要判断信息的正确性，若不正确，则用户就要把出错信息报告给信息的发送者，以便发送者采取纠正措施。通过用户的这些措施，可将不可靠服务变成可靠服务。  
（3）有应答服务和无应答服务  

有应答服务是指接收方在收到数据后向发送方给出相应的应答，该应答由传输系统内部自动实现，而不由用户实现。发送的应答既可以是肯定应答，又可以是否定应答，通常在接收到的数据有错误时发送否定应答。例如，文件传输服务就是一种有应答服务。  

无应答服务是指接收方收到数据后不自动给出应答。若需要应答，则由高层实现。例如，对于WWW服务，客户端收到服务器发送的页面文件后不给出应答。  

# 1.2.3ISO/OSI TCP/IP模型  

# 1.OSI参考模型  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/e61874f66877634089b440c5badd16d8f1dc349ad0cb374eb5585eaf353af0a5.jpg)  

OSI参考模型的通信子网各层所包含的中继设备（2016）  

国际标准化组织（ISO）提出的网络体系结构模型称为开放系统互连参考模型（OSI/RM），通常简称为OSI参考模型。OSI参考模型有7层，自下而上依次为物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。低三层统称通信子网，是为联网而附加的通信设备，完成数据的传输功能；高三层统称资源子网，相当于计算机系统，完成数据的处理等功能。传输层承上启下。0SI参考模型的层次结构如图1.10所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/0007f90cfeedff7909c783165de40e20f9808e61a22237bdf22d1010c48418c4.jpg)  
图1.10OSI参考模型的层次结构  

下面详述OSI参考模型各层的功能。  

>#### pro：OSI参考模型的层次结构（2013、2014、2017、2019）  

（1）物理层（Physical Layer）  

物理层的传输单位是比特，功能是在物理介质上为数据端设备透明地传输原始比特流。物理层主要定义数据终端设备（DTE）和数据通信设备（DCE）的物理与逻辑连接方法。  

物理层接口标准很多，如EIA-232C、EIA/TIARS-449、CCITT的X.21等。图1.11表示的是两个通信结点及它们间的一段通信链路，物理层主要研究以下内容  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/95bdedaa52206e2c534c5ce90c2d9a507b96d7293774f6465464cbfd14036917.jpg)  
图1.11两个通信结点及它们间的一段通信链路  

$\textcircled{\scriptsize{1}}$ 通信链路与通信结点的连接需要一些电路接口，物理层规定了这些接口的一些参数，如机械形状和尺寸、交换电路的数量和排列等，例如笔记本电脑上的网线接口。  
$\textcircled{2}$ 物理层规定了通信链路上所传输的信号的意义和电气特征。例如，若规定信号X代表数字0，则当结点传输0时就发出信号X，而当结点接收到信号X时就知道收到的是0。  

注意，传输信息所用的一些物理介质（如双绞线、光缆、无线信道等）并不在物理层协议之内，而在物理层协议下面。因此，有人将物理介质当作第0层。  

（2）数据链路层（Data Link Layer）  

>#### pro：OSI参考模型的数据链路层的功能（2022）  

数据链路层的传输单位是顿。两台主机之间的数据传输总是在一段一段的链路上传送的，这就需要使用专门的链路层协议。数据链路层将网络层交来的IP分组封装成顿，并且可靠地传输到相邻结点的网络层。主要作用是加强物理层传输原始比特流的功能，将物理层提供的可能出错的物理连接改造为逻辑上无差错的数据链路，使之对网络层表现为一条无差错的链路。  

因为外界噪声的干扰，所以原始的物理连接在传输比特流时可能发生错误。如图1.11所示，结点A想向结点B传输数字0，于是发出信号X：但在传输过程中受到于扰，信号X变成了信号Y，而信号Y又刚好代表1，结点B接收到信号Y时，误以为结点A传送了数字1，从而发生差错。数据链路层协议应能检测出这些差错，然后将收到的错误信息丢弃。  

如图1.11所示，在两个相邻结点之间传送数据时，结点A的发送速率可能比结点B的接收速率快，若不加以控制，则结点B就会丢充很多来不及接收的正确数据，造成传输线路效率下降。流量控制可以协调两个结点的速率，使结点A的发送速率刚好是结点B的接收速率。  

广播式网络在数据链路层还要处理新的问题，即如何控制对共享信道的访问。数据链路层的一个特殊子层一一介质访问子层就是专门处理这个问题的。  

典型的数据链路层协议有SDLC、HDLC、PPP、STP和帧中继等。  

（3）网络层（Network Layer）  

网络层的传输单位是数据报。它关心的是通信子网的运行控制，主要任务是将网络层的协议数据单元（分组）从源结点传输到目的结点，为分组交换网上的不同主机提供通信服务。关键问题是对分组进行路由选择，并实现流量控制、拥塞控制、差错控制和网际互连等功能。  

# 注意  

无论是在哪一层传送的数据单元，都可以笼统地用“分组”来表示。  

如图1.12所示，当结点A向结点B传输一个分组时，既可经过边a、C、g，又可经过边b、h,有多条可以选择的路由，而网络层的作用是根据网络的情况，利用相应的路由算法计算出一条合适的路径，使这个分组可以顺利地到达结点B。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/64b7691ecbb524c8f922741a5e0d7779d28ceed9a6a1897443247262e677bc2b.jpg)  
图1.12某网络结构图  

流量控制与数据链路层的流量控制的含义一样，都是协调A的发送速率和B的接收速率。  

差错控制是通信结点之间约定的特定检错规则，接收方根据该规则检查接收到的分组是否出错，若出错，则能纠错就纠错，不能纠错就丢弃，确保向上层提交的数据都是无误的。  
若图1.12中的结点都来不及接收分组而丢弃大量分组，导致结点间无法正常通信，那么网络就处于拥塞状态。网络层要采取措施来缓解这种拥塞，这就是拥塞控制。  

互联网是由大量异构网络通过路由器相互连接起来的。互特网使用的网络层协议是无连接的网际协议（IP）和许多种路由选择协议，因此互联网的网络层也称网际层或IP层。  

网络层的协议有IP、IPX、ICMP、IGMP、ARP、RARP、RIP和OSPF等。  

（4）传输层（Transport Layer）  

>#### pro：OSI参考模型的传输层的功能（2009）  

传输层也称运输层，负责主机中两个进程之间的通信，功能是为端到端连接提供可靠的传输服务，即为端到端连接提供流量控制、差错控制、服务质量、数据传输管理等服务。  

数据链路层提供的是点到点通信，传输层提供的是端到端通信，两者不同。  

通俗地说，点到点可理解为主机和主机之间的通信，一个点是指一个硬件地址或IP地址，网络中参与通信的主机是通过硬件地址或IP地址来标识的：端到端通信是指运行在不同主机内的两个进程之间的通信，一个进程由一个端口来标识，所以称为端到端通信。  

通过传输层的屏蔽，高层用户看不到通信子网的交替和变化。因为一台主机可同时运行多个进程，所以传输层具有复用和分用的功能。复用是指多个应用层进程可同时使用下面传输层的服务，分用是指传输层将收到的信息分别交付给上面应用层中相应的进程。  

传输层的协议有TCP、UDP。（5）会话层（Session Layer）  

>#### pro：OSI参考模型的会话层的功能（2019）  

会话层充许不同主机上的各个进程之间进行会话。这种服务主要为表示层实体或用户进程建立连接，并在连接上有序地传输数据，这就是会话，也称建立同步（SYN）。会话层负责管理主机间的会话进程，包括建立、管理和终正进程间的会话。会话层包含一种称为检查点的机制来维持可靠会话，使通信会话在通信失效时从检查点继续恢复通信，即断点下载的原理。  

（6）表示层（Presentation Layer）  

>#### pro：OSI参考模型的表示层的功能（2013）  

表示层主要处理在两个通信系统中交换信息的表示方式。不同机器采用的编码和表示方法不同，为了使不同表示方法的数据和信息之间能够互相交换，表示层采用抽象的标准方法定义数据结构，并采用标准的编码形式。此外，数据压缩、加密和解密也是表示层的功能。  

（7）应用层（Application Layer）  

应用层是OSI参考模型的最高层，是用户与网络的接口。应用层为特定类型的网络应用提供访向OS参考模型环境的手段。用户的实际应用多种多样，这就要求应用层采用不同的应用协议来解决不同类型的应用要求，因此应用层是最复杂的一层，使用的协议也最多。典型的协议有用于文件传送的FTP、用于电子邮件的SMTP、用于万维网的HTTP等。  

# 2.TCP/IP模型  

>#### pro：TCP/IP模型的各层的顺序（2021）  

TCP/IP模型从低到高依次为网络接口层（对应OSI参考模型的物理层和数据链路层）、网际层、传输层和应用层（对应OSI参考模型的会话层、表示层和应用层）。TCP/IP因为得到广泛应用而成为事实上的国际标准。TCP/IP模型的层次结构及各层的主要协议如图1.13所示。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c14a9addbd31bfab185f7ddf31fee34a7a506bbe4d93206e83711b8f80157e3f.jpg)  
图1.13TCP/IP模型的层次结构及各层的主要协议  

网络接口层的功能类似于OSI参考模型的物理层和数据链路层。它表示与物理网络的接口，但实际上TCP/IP本身并未真正描述这一部分，只是指出主机必须使用某种协议与网络连接，以便在其上传输IP分组。具体的物理网络既可是各种类型的局域网，如以太网、令牌环网、令牌总线网等，又可是诸如电话网、SDH、X.25、帧中继和ATM等公共数据网络。网络接口层的作用是从主机或结点接收IP分组，并将它们发送到指定的物理网络上。  

>#### pro：TCP/IP模型的网际层的功能（2011、2021）  

网际层（主机-主机）是TCP/IP体系结构的关键部分，功能上它与OSI参考模型的网络层非常相似。网际层将分组发往任何网络，并为其独立地选择合适的路由，但不保证各个分组有序地到达，各个分组的有序和可靠交付由高层负责。网际层定义了标准的分组格式和协议，即IP。当前采用的IP是第4版，即IPv4，它的下一版本是IPv6。  

传输层（应用-应用或进程-进程）的功能同样与OSI参考模型中的传输层类似，即使得发送端和目的端主机上的对等实体进行会话。传输层主要使用以下两种协议：  

1）传输控制协议（Transmission Control Protocol，TCP）。它是面向连接的，传输数据之前必须先建立连接，能够提供可靠的交付。数据传输的单位是报文段。2）用户数据报协议（UserDatagramProtocol，UDP）。它是无连接的，不保证提供可靠的交付，只能提供“尽最大努力交付”。数据传输的单位是用户数据报。  

应用层（用户-用户）包含所有的高层协议，如虚拟终端协议（Telnet）、文件传输协议（FTP）域名解析服务（DNS）、电子邮件协议（SMTP）和超文本传输协议（HTTP）。  

由图1.13可以看出，IP是互联网中的核心协议；TCP/IP可为各式各样的应用提供服务（所everything over IP），TCP/IP IP（所谓IPovereverything）。因此，互联网才会发展到今天的规模。  

# 3.TCP/IP模型与OSI参考模型的比较  

TCP/IP模型与OSI参考模型有许多相似之处。  

首先，二者都采取分层的体系结构，且分层的功能也大体相似，  

其次，二者都是基于独立的协议栈的概念。  

最后，二者都可解决异构网络的互连，实现不同厂家生产的计算机之间的通信。  

两个模型除了具有这些基本的相似之处，也有很多差别。  

第一，OSI参考模型的最大贡献是精确定义了三个主要概念：服务、协议和接口，这与现代的面向对象程序设计思想非常吻合。而TCP/IP模型在这三个概念上没有明确区分。  
第二，OSI参考模型是7层模型，而TCP/IP模型是4层结构。TCP/IP模型将OSI参考模型的表示层和会话层的功能合并到了应用层，还将数据链路层和物理层合并为网络接口层。  

第三，OSI参考模型先有模型，后有协议规范，通用性良好，适合描述各种网络。TCP/IP模型正好相反，即先有协议栈，后建立模型，因此不适合任何其他的非TCP/IP网络。  

第四，OSI参考模型在网络层支持无连接和面向连接的通信，但在传输层仅有面向连接的通信。而TCP/P模型认为可靠性是端到端的向题，因此它在网际层仅有一种无连接的通信模式，但传输层支持无连接和面向连接两种模式。这个不同点常常作为考查点。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/a20b555348c66a1d86d4fd42dd6992721d73608bd7121635c924dba4b9b8c816.jpg)  
图1.14TCP/IP模型与OSI参考模型的层次对应关系  

OSI参考模型和TCP/IP模型都不是完美的，对二者的批评都很多。OSI参考模型的设计者从一开始就试图建立一个全世界的计算机网络都要遵循的统一标准。从技术角度看，他们追求一种完美的理想状态，导致基于OSI参考模型的软件效率极低。OSI参考模型缺之市场与商业动力，结构复杂，运行效率低，这是它未能达到预期目标的重要原因。  

学习计算机网络时，我们往往采取折中的办法，即综合OSI参考模型和TCP/IP模型的优点，采用一种如图1.15所示的只有5层协议的体系结构，本书也采用这种体系结构进行讨论。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/ec6112de998bfabbd24993f5950da08fa636670fe503551cad0412179dfdb9ac.jpg)  
图1.15网络的5层协议体系结构模型  

>#### pro：应用层DNS报文逐层封装的关系（2021）  

最后简单介绍使用协议栈进行通信的数据传输过程。每个协议栈的顶端都是一个面向用户的接口，下面各层是为通信服务的协议。用户传输的数据通常是用户能够理解的自然语言，通过应用层将自然语言转化为用于通信的通信数据。通信数据到达传输层，作为传输层的数据部分（传输层SDU），加上传输层的控制信息（传输层PCI），组成传输层的PDU：下放到网络层后，就成为网络层的SDUJ，加上网络层的PCI，又组成了网络层的PDU；下放到数据链路层..·就这样层层下放，层层包裹，最后形成的数据包通过通信线路传输，到达接收方结点协议栈，接收方逆向逐层地拆开“包裹”，然后将收到的数据提交给用户，如图1.16所示。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/0c26307fd09bd47a50dd8f5a89155680090dda15a93f2b1ab530a1e0943cba84.jpg)  
图1.16协议栈的通信过程示例  
 

# 1.3 本章小结及疑难点  

1.互联网使用的IP协议是无连接的，因此其传输是不可靠的。这样容易使人们感到互联网很不可靠。为什么当初不把互联网的传输设计为可靠的呢？  

传统电信网的主要用途是电话通信，且普通电话机不是智能的，因此电信公司必须花费巨大的代价将电信网设计得非常可靠，以保证用户的通信质量。  

数据的传送显然必须可靠。当初设计ARPAnet时，很重要的讨论内容之一是“谁应当负责数据传输的可靠性？”一种意见是主张像电信网那样，由通信网络负责数据传输的可靠性（因为电信网的发展史及技术水平已经证明，人们可将网络设计得相当可靠）。另一种意见则主张由用户主机负责数据传输的可靠性，理由是这样可使计算机网络便宜、灵活。  

计算机网络的先驱认为，计算机网络和电信网的一个重大区别是终端设备的性能差别很大。于是，他们采用了“端到端的可靠传输”策略，即在传输层使用面向连接的TCP协议，这样既能使网络部分价格便宜且灵活可靠，又能保证端到端的可靠传输。  

# 2.端到端通信和点到点通信有什么区别？  

本质上说，由物理层、数据链路层和网络层组成的通信子网为网络环境中的主机提供点到点的服务，而传输层为网络中的主机提供端到端的通信。  

直接相连的结点之间的通信称为点到点通信，它只提供一台机器到另一台机器之间的通信，不涉及程序或进程的概念。同时，点到点通信并不能保证数据传输的可靠性，也不能说明源主机与目的主机之间是哪两个进程正在通信，这些工作都由传输层来完成。  

端到端通信建立在点到点通信的基础上，由一段段点到点通信信道构成，以完成应用程序（进程）之间的通信。“端”是指用户程序的端口，端口号标识了应用层中的不同进程。  

# 3.如何理解传输速率和传播速率？  

传输速率是指主机或路由器在数字信道上发送数据的速率，也称传输率、数据率或比特率，单位是比特/秒（b/s），或干比特/秒（kb/s）、兆比特/秒（Mb/s）、吉比特/秒（Gb/s）等。  
# 注意  

在通信领域中表示速率时， $\mathbf{k}\!=\!10^{3}$  $\mathrm{M}\!=\!10^{6}$  $G\!=\!10^{9}$  $\mathrm{T}=10^{12}$ 。表示存储容量或文件大小时， $\mathtt{K}\!=\!2^{10}\!=\!1024$  $\scriptstyle\mathbf{M}\,=\,2^{20}$  $\mathrm{G}\!=\!2^{30}$  $\mathrm{T}\!=\!2^{40}$ ，这与通信领域中的表示方式不同。  

传播速率是指电磁波在信道中传播的速率，单位是米/秒（ $._{\mathrm{m/s}}$ ）或千米/秒（ $(\mathrm{km}/\mathrm{s})$  

在图1.17中，假定链路的传播速率为 $2{\times}10^{8}\mathrm{m/s}$ ，这相当于电磁波在该介质中 $1\upmu\mathrm{s}$ 可向前传播 $200\mathrm{m}$ 。若链路带宽为 $1\mathrm{{Mb/s}}$ ，则主机在 $1\upmu\mathrm{s}$ 内可向链路发送1比特的数据。当 $t\!=\!0$ 时，开始向链路发送数据：当 $t\!=\!1\upmu\mathrm{s}$ 时，信号传播到 $200\mathrm{m}$ 处，注入链路1比特：当 $t\!=\!2\upmu\mathrm{s}$ 时，信号传播到 $400\mathrm{m}$ 处，注入链路共2比特：当 $t\!=\!3\upmu\mathrm{s}$ 时，信号传播到 $600\mathrm{m}$ 处，注入链路共3比特。  

从图1.17可以看出，在一段时间内链路中有多少比特取决于带宽（或传输速率），而1比特“跑”了多远取决于传播速率。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/0f85059af28cb65ea81407dcb3fc5444431a016956a56fcf332ccd22ecceba5f.jpg)  
图1.17传输速率、带宽和传播速率三者的区别  
# 第2章物理层  

# 【考纲内容】  

（一）通信基础  

信道、信号、带宽、码元、波特、速率、信源与信宿等基本概念：奈奎斯特定理与香农定理：编码与调制：电路交换、报文交换与分组交换：数据报与虚电路  

（二）传输介质双绞线、同轴电缆、光纤与无线传输介质：物理层接口的特性  

（三）物理层设备  

中继器：集线器  

# 【复习提示】  

物理层考虑的是怎样才能在连接各台计算机的传输介质上传输数据比特流，而不是具体的传输介质。本章概念较多，易出选择题，复习时应抓住重点，如奈奎斯特定理和香农定理的应用、编码与调制技术、数据交换方式，以及电路交换、报文交换与分组交换技术等。  

# 2.1 通信基础  

# 2.1.1基本概念  

# 1.数据、信号与码元  

通信的目的是传输信息，如文字、图像和视频等。数据是指传送信息的实体。信号则是数据的电气或电磁表现，是数据在传输过程中的存在形式。数据和信号都有模拟或数字之分： $\textcircled{\scriptsize{1}}$ 模拟数据（或模拟信号）的取值是连续的； $\textcircled{2}$ 数字数据（或数字信号）的取值是离散的。  

在通信系统中，常用一个固定时长的信号波形（数字脉冲）表示一位 $k$ 进制数字，代表不同离散数值的基本波形就称为码元。码元是数字通信中数字信号的计量单位，这个时长内的信号称为 $k$ 进制码元，而该时长称为码元宽度。1码元可携带若干比特的信息量。例如，在使用二进制编码时，只有两种不同的码元：一种代表0状态，另一种代表1状态。  

# 2.信源、信道与信宿  

图2.1所示为一个单向通信系统的模型，实际的通信系统大多数是双向的，可进行双向通信。  
数据通信系统主要划分为信源、信道和信宿三部分。信源是产生和发送数据的源头，信宿是接收数据的终点，它们通常都是计算机或其他数字终端装置。信道是信号的传输介质，一条双向通信的线路包含一个发送信道和一个接收信道。发送端信源发出的信息需要通过变换器转换成适合在信道上传输的信号，而通过信道传输到接收端的信号首先由反变换器转换成原始信息，然后发送给信宿。噪声源是信道上的噪声及分散在通信系统其他各处的噪声的集中表示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/d49cc4d7da6d319d17512b142cd5e47536c50eba359e66e26492dd13c96427b0.jpg)  
图2.1通信系统模型  

信道按传输信号形式的不同，分为传送模拟信号的模拟信道和传送数字信号的数字信道两大类；信道按传输介质的不同分为无线信道和有线信道。  

信道上传送的信号有基带信号和宽带信号之分。基带信号首先将数字信号1和0直接用两利不同的电压表示，然后送到数字信道上传输（称为基带传输）；宽带信号首先将基带信号进行调制，形成频分复用模拟信号，然后送到模拟信道上传输（称为宽带传输）。  

数据传输方式分为串行传输和并行传输。事行传输是指逐比特地按序依次传输，并行传输是指若干比特通过多个通信信道同时传输。串行传输适用于长距离通信，如计算机网络。并行传输适用于近距离通信，常用于计算机内部，如CPU与主存之间。  

从通信双方信息的交互方式看，可分为三种基本方式：1）单向通信。只有一个方向的通信而没有反方向的交互，如无线电广播、电视广播等。2）半双工通信。通信双方都可发送或接收信息，但任何一方都不能同时发送和接收信息。3）全双工通信。通信双方可同时发送和接收信息。单向通信只需一个信道，而半双工通信或全双工通信都需要两个信道，每个方向一个信道。  

# 3.速率、波特与带宽  

速率是指数据传输速率，表示单位时间内传输的数据量，常有两种描述形式。  

>#### pro：调制速率的概念（2014）  

1）码元传输速率。又称波特率，表示单位时间内数字通信系统所传输的码元数（也称调制速率或符号速率），单位是波特（Baud)。1波特表示数字通信系统每秒传输1个码元。码元既可以是多进制的，又可以是二进制的，码元速率与进制数无关。  

2）信息传输速率。又称比特率，表示单位时间内数字通信系统传输的二进制码元数（即比特数），单位是比特/秒（b/s）。  

# 注意  

波特和比特是两个不同的概念，但波特率与比特率在数量上又有一定的关系。若一个码元携带 $n$ 比特的信息量，则波特率 $M$ Baud对应的比特率为 $\begin{array}{r}{M n\,{\sf b}/{\sf s}_{\circ}}\end{array}$  

在模拟信号系统中，带宽（又称频率带宽）用来表示某个信道所能传输信号的频率范围，即最高频率与最低频率之差，单位是赫兹（H）。在计算机网络中，带宽用来表示网络的通信线路所能传输数据的能力，即最高数据率；显然，此时带宽的单位不再是Hz，而是b/s。  
# 2.1.2信道的极限容量  

任何实际的信道都不是理想的，信号在信道上传输时会不可避免地产生失真。但是，只要接收端能够从失真的信号波形中识别出原来的信号，这种失真对通信质量就没有影响。但是，若信号失真很严重，则接收端就无法识别出每个码元。码元的传输速率越高，或者信号的传输 距离越远，或者噪声干扰越大，或者传输介质的质量越差，接收端波形的失真就越严重。  

# 1.奈奎斯特定理（奈氏准则）  

>#### pro：  

# 无噪声信道的最大数据传输速率（2009、2022、2023）  

具体的信道所能通过的频率范围总是有限的。信号中的许多高频分量往往不能通过信道，否则在传输中就会衰减，导致接收端收到的信号波形失去码元之间的清晰界限，这种现象称为码间串扰。奈奎斯特定理规定：在理想低通（没有噪声、带宽有限）信道中，为了避免码间串扰，极限码元传输速率为 $2W$ 波特，其中 $W$ 是信道的频率带宽（单位为 $\mathrm{Hz}$ 。若用 $V$ 表示每个码元的离散电平数目（码元的离散电平数目是指有多少种不同的码元，若有16种不同的码元，则需要4个二进制位，因此数据传输速率是码元传输速率的4倍），则极限数据率为  

理想低通信道下的极限数据传输速率 $=2W\log_{2}V$ （单位为b/s）  

对于奈氏准则，有以下结论：  

1）在任何信道中，码元传输速率是有上限的。若传输速率超过上限，则会出现严重的码间串扰问题，使得接收端不可能完全正确地识别码元。2）信道的频带越宽（即通过的信号高频分量越多），就越可用更高的速率有效地传输码元。3）奈氏准则给出了码元传输速率的限制，但并未限制信息传输速率，即未对一个码元可以对应多少个二进制位给出限制。  

因为码元传输速率受奈氏准则制约，所以要提高数据传输速率，就要设法使每个码元携带更多比特的信息量，此时需要采用多元制的调制方法。  

# 2.香农定理  

>#### pro：有噪声信道的实际数据传输速率（2016）  

实际的信道会有噪声，噪声是随机产生的。香农定理给出了带宽受限且有高斯噪声干扰的信道的极限数据传输速率，当用该速率传输数据时，不会产生误差。香农定理定义为  

信道的极限数据传输速率 $=W\mathrm{log}_{2}(1+S/N)$ （单位为b/s）  

式中， $W$ 为信道的频率带宽（单位为 $\mathrm{Hz}$ )， $S$ 为信道内所传输信号的平均功率， $N$ 为信道内的高斯噪声功率。SIN为信噪比，即信号的平均功率与噪声的平均功率之比，信噪比 $=10\mathrm{log}_{10}(S/N)$ （单位为dB）。例如，当 $S/N\!=\!10$ 时，信噪比为10dB；而当 $S/N\!=\!1000$ 时，信噪比为30dB。  

>#### pro：信道数据传输速率的影响因素分析（2014）  

对于香农定理，有以下结论：  

1）信道的带宽或信道中的信噪比越大，信息的极限传输速率越高。2）对一定的传输带宽和一定的信噪比，信息传输速率的上限是确定的。3）只要信息传输速率低于信道的极限传输速率，就能找到某种方法实现无差错的传输。4）香农定理得出的是极限信息传输速率，实际信道能达到的传输速率要比它低不少。  
>#### pro：奈氏准则和香农定理的对比分析（2017）  

奈氏准则只考虑了带宽与极限码元传输速率之间的关系，而香农定理不仅考虑了带宽，也考虑了信噪比。这从另一个侧面表明，一个码元对应的二进制位数是有限的。  

# 2.1.3编码与调制  

信号是数据的具体表示形式，数据无论是数字的还是模拟的，为了传输的目的，都要转换成信号。将数据转换为模拟信号的过程称为调制，将数据转换为数字信号的过程称为编码。  

数字数据可通过数字发送器转换为数字信号传输，也可通过调制器转换成模拟信号传输；同样，模拟数据可通过PCM编码器转换成数字信号传输，也可通过放大器调制器转换成模拟信号传输。这样，就形成了如下4种编码与调制方式。  

# 1.数字数据编码为数字信号  

数字数据编码用于基带传输中，即在基本不改变数字数据信号频率的情况下，直接传输数字信号。具体用什么样的数字信号表示0及用什么样的数字信号表示1，就是所谓的编码。编码的规则有多种，只要能有效区分0和1即可。常用的数字数据编码有以下几种，如图2.2所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/6328c430a19cd2ee823cbd2821a49bdecf3d765b187fe98e01a4fe7bd2d22cac.jpg)  
图2.2常用的数字数据编码  

1）归零（RZ）编码。用高电平表示1、低电平表示0（或者相反），每个码元的中间均跳变到零电平（归零），接收方根据该跳变调整本方的时钟基准，这就为收发双方提供了自同步机制。因为归零需要占用一部分带宽，所以传输效率受到了一定的影响。  

>#### pro： 非归零编码和反向非归零编码的波形记忆（2015）  

2）非归零（NRZ）编码。与RZ编码的区别是不用归零，一个时钟全部用来传输数据，编码效率最高。但NRZ编码的收发双方存在同步问题，为此需要双方都带有时钟线。  

3）反向非归零（NRZI）编码。与NRZ编码的区别是用电平的跳变表示O、电平保持不变表示1。跳变信号本身可作为一种通知机制。这种编码方式集成了前两种编码的优点，既能传输时钟信号，又能尽量不损失系统带宽。USB2.0的编码方式就是NRZI编码。  
>#### pro：曼彻斯特编码的波形记忆（2013、2015）  

4）曼彻斯特编码。每个码元的中间都发生电平跳变，电平跳变既作为时钟信号（用于同步），又作为数据信号。可用向下跳变表示1、向上跳变表示0，或者采用相反的规定。  

>#### pro：差分曼彻斯特编码的波形记忆（2021）  

5）差分曼彻斯特编码。每个码元的中间都发生电平跳变，与曼彻斯特编码不同的是，电平跳变仅表示时钟信号，而不表示数据。数据的表示在于每个码元开始处是否有电平跳变：无跳变表示1，有跳变表示0。差分曼彻斯特编码拥有更强的抗干扰能力。  

曼彻斯特编码和差分曼彻斯特编码在每个码元的中间都发生电平跳变，相当于将一个码元一分为二，编码速率是码元速率的2倍，二者所占的频带宽度是原始基带宽度的2倍。标准以太网使用的就是曼彻斯特编码，而差分曼彻斯特编码则被广泛用于宽带高速网中。  

# 2.模拟数据编码为数字信号  

主要包括三个步骤，即采样、量化和编码，常用于对音频信号进行编码的PCM编码。  

首先介绍采样定理：在将模拟信号转换成数字信号时，假设原始信号中的最大频率为f，那么采样率f采必须大于或等于最大频率  $f$  的2倍，才能保证采样后的数字信号完整保留原模拟信 号的信息（只需记住结论）。另外，采样定理又称奈奎斯特定理。  

1）采样是指对模拟信号进行周期性扫描，将时间上连续的信号变成时间上离散的信号。  

2）量化是指将采样得到的电平幅值按照一定的分级标度转换为对应的数值并取整，这样就将连续的电平幅值转换为了离散的数字量。采样和量化的实质就是分割和转换。  

3）编码是指将量化得到的离散整数转换为与之对应的二进制编码。  

# 3.数字数据调制为模拟信号  

数字数据调制技术在发送端将数字信号转换为模拟信号，而在接收端将模拟信号还原为数字信号，分别对应于调制解调器的调制和解调过程。图2.3中显示了数字调制的三种方式。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/fdf0f699eda49c38bad96dea6527302a5202b07e045d5b6c0970c2d0b46c0000.jpg)  
图2.3数字调制的三种方式  
>#### pro：采用调幅技术时码元的比特位数（2022）  

1）调幅（AM）或幅移键控（ASK)。通过改变载波的振幅来表示数字信号1和0。例如，用有载波和无载波输出分别表示1和0。这种方式比较容易实现，但抗干扰能力差。  

2）调频（FM）或频移键控（FSK）。通过改变载波的频率来表示数字信号1和0。例如，用频率 $f_{1}$ 和频率f分别表示1和0。这种方式容易实现，抗干扰能力强，目前应用较广泛。  

>#### pro：采用调相技术时比特率和波特率的转化（2011）  

3）调相（PM）或相移键控（PSK)。通过改变载波的相位来表示数字信号1和0，又分为绝对调相和相对调相。例如，用相位0和 $\pi$ 分别表示1和0，是一种绝对调相方式。  

>#### pro：采用QAM技术时码元的比特位数（2009、2023）  

4）正交幅度调制（QAM)。在频率相同的前提下，将AM与PM结合起来，形成叠加信号。设波特率为 $B$ ，采用 $m$ 个相位，每个相位有 $n$ 种振幅，则该QAM的数据传输速率 $R$ 为  

$R\!=\!B\mathrm{log}_{2}(m n)$ （单位为 ${\tt b}/{\tt s}$  

# 4.模拟数据调制为模拟信号  

为了实现传输的有效性，可能需要较高的频率。这种调制方式还可使用频分复用（FDM）技术，充分利用带宽资源。电话机和本地局交换机采用模拟信号传输模拟数据的编码方式。  

# 2.2 传输介质  

# 2.2.1 双绞线、同轴电缆、光纤与无线传输介质  

传输介质也称传输媒体，是数据传输系统中发送器和接收器之间的物理通路。传输介质可分为： $\textcircled{\scriptsize{1}}$ 导向传输介质，指铜线或光纤等，电磁波被导向为沿着固体介质传播： $\circledcirc$ 非导向传输介质，指自由空间（空气、真空或海水)，电磁波在非导向传输介质中的传输称为无线传输。  

# 1.双绞线  

双绞线是最常用的传输介质，在局域网和传统电话网中普遍使用。双绞线由两根采用一定规则并排绞合、相互绝缘的铜导线组成。绞合可减少对相邻导线的电磁干扰。为了进一步提高抗电 磁干扰的能力，还可在双绞线的外面加上一层金属丝编织成的屏蔽层，这就是屏蔽双绞线（STP）。无屏蔽层的双绞线称为非屏蔽双绞线（UTP）。双绞线的结构如图2.4所示。  

双绞线的价格便宜，模拟传输和数字传输都可使用双绞线，通信距离一般为几干米到数十干米。双绞线的带宽取决于铜线的粗细和传输的距离。距离太远时，对于模拟传输，要用放大器放大衰减的信号；对于数字传输，要用中继器来对失真的信号进行整形。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3a619194921245e780d0ffe50a3003bdc096f8ead04f90c663789508bfd94971.jpg)  
图2.4双绞线的结构  

# 2.同轴电缆  

同轴电缆由内导体、绝缘层、网状编织屏蔽层和塑料外层构成，如图2.5所示。同轴电缆一般分为两类： $\textcircled{\scriptsize{1}}$ 50Q同输电缆，主要用于传送基带数字信号，在早期局域网中应用广泛： $\circledcirc$ 75Q同轴电缆，主要用于传送宽带信号，在有线电视系统中应用广泛。因为外导体屏蔽层的作用，所以同轴电缆具有良好的抗干扰特性而被广泛用于传输较高速率的数据。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f83aba72a656e91cbd56efb07284b51198d458300a656b4cbf4727da4a90f39f.jpg)  
图2.5同轴电缆的结构  

随着技术的发展和集线器的出现，在局域网领域基本上都采用双绞线作为传输介质。  

# 3.光纤  

光纤通信是指利用光导纤维（简称光纤）传递光脉冲来进行通信。有光脉冲表示1，无光脉冲表示0。可见光的频率约为 $10^{8}\mathrm{MHz}$ ，因此光纤通信系统的带宽极大。  

光纤主要由纤芯和包层构成（见图2.6），纤芯很细，直径仅为 $8\!\sim\!100\upmu\mathrm{m}$ ，包层较纤芯有较低的折射率，光波通过纤芯进行传导。当光线从高折射率的介质射向低折射率的介质时，其折射角将大于入射角。因此，只要入射角大于某个临界角，就会出现全反射，即光线碰到包层时就会折射回纤芯，这个过程不断重复，光也就沿着光纤传输下去。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c31445185d6237de4247e897a7799344b5db3b959ae64e145a7362d9f491e11d.jpg)  
图2.6光波在纤芯中的传播  

利用光的全反射特性，可让从不同角度入射的多条光线在一根光纤中传输，这种光纤称为多模光纤（见图2.7），多模光纤的光源为发光二极管。光脉冲在多模光纤中传输时遂渐展宽，造成失真，因此多模光纤只适合近距离传输。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/080cf89791186e918919cd964321ccd192440fb467f8c03c0ee6e92df8ed3a93.jpg)  
图2.7多模光纤  
当光纤的直径减小到只有一个光的波长时，光纤就像一根波导那样，可使光线一直向前传播，而不产生多次反射，这样的光纤就是单模光纤（见图2.8）。单模光纤的纤芯很细，直径只有几微米，制造成本较高。同时，单模光纤的光源是定向性很好的半导体激光器，因此单模光纤的衰减较小，可传输数干米甚至数十干米而不必采用中继器，适合远距离传输。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/03c389f0abce206bef77a5089dfa39ac538e0ae63477808ab3557b5a1a9110bb.jpg)  
图2.8单模光纤  

光纤不仅具有通信容量非常大的优点，而且具有如下特点：  

1）传输损耗小，中继距离长，对远距离传输特别经济。2）抗雷电和电磁干扰性能好，在有大电流脉冲干扰的环境下这尤为重要。3）无串音干扰，保密性好，不易被窃听或截取数据。4）体积小，重量轻，在现有电缆管道已拥塞不堪的情况下这特别有利。  

# 4.无线传输介质  

无线通信已广泛用于蜂窝移动电话领域。随着便携式计算机的出现，以及军事、野外等特殊场合对移动联网的需要，促进了移动通信的发展，现在无线局域网的应用已非常普遍。  

# （1）无线电波  

无线电波具有较强的穿透能力，可以传输很长的距离，因此广泛用于通信领域，如无线手机通信、计算机网络中的无线局域网（WLAN）等。因为无线电波使信号向所有方向散播，所以有效距离范围内的接收设备无须对准某个方向，就可与无线电波发射者进行通信连接，大大简化了通信连接。这也是无线电波传输的最重要优点之一。  

（2）微波、红外线和激光  

目前高带宽的无线通信主要使用三种技术：微波、红外线和激光，它们都需要在发送方和接收方之间有一条视线通路，有很强的方向性，沿直线传播。不同的是，红外通信和激光通信将要传输的信号分别转换为各自的信号格式，即红外光信号和激光信号，再直接在空间中传播。  

微波通信的频率较高，频段范围也很宽，载波频率通常为 $2\!\sim\!40\mathrm{GHz}$ ，因此通信信道的容量大。例如，一个带宽为2MHz的频段可容纳500条语音线路，若用来传输数字信号，则数据率可达数兆比特/秒。与通常的无线电波不同，微波通信的信号是沿直线传播的，因此在地面上的传播距离有限，超过一定距离后就要使用中继站来接力。  

卫星通信利用地球同步卫星作为中继来转发微波信号，可以克服地面微波通信距离的限制3三颗相隔 $120^{\circ}$ 的同步卫星几乎就能覆盖整个地球表面，因此基本能实现全球通信。卫星通信的优点是通信容量大、距离远、覆盖广，缺点是保密性差、端到端传播时延长。  

# 2.2.2物理层接口的特性  

物理层考虑的是如何在连接各种计算机的传输介质上传输比特流，而不指具体的传输介质。网络中的硬件设备和传输介质的种类繁多，通信方式也各不相同。物理层应尽可能屏蔽这些差异，让数据链路层感觉不到这些差异，使数据链路层只需考虑如何完成本层的协议和服务。  
>#### pro：物理层接口的特性的内容（2018）  

物理层的主要任务是确定与传输介质的接口有关的一些特性：1）机械特性。指明接口所用接线器的形状和尺寸、引脚数目和排列、固定和锁定装置等。2）电气特性。指明在接口电缆的各条线上的电压范围、传输速率和距离限制等。3）功能特性。指明某条线上出现的某一电平的电压的意义，以及每条线的功能。  

>#### pro：物理层接口的过程特性的内容（2012）  

4）过程特性，也称规程特性。指明对不同功能的各种可能事件的出现顺序。  

# 2.2.3 本节习题精选  

# 单项选择题  

01.双绞线是用两根绝缘导线绞合而成的，绞合的目的是（）。A.减少干扰B.提高传输速度C.增大传输距离D.增大抗拉强度

02.在电缆中采用屏蔽技术带来的好处主要是（）  

A.减少信号衰减 B.减少电磁干扰辐射 C.减少物理损坏D.减少电缆的阻抗  

03.利用一根同轴电缆互连主机构成以太网，则主机间的通信方式为（）。A.全双工B.半双工C.单工D.不确定

04.同轴电缆比双绞线的传输速率更快，得益于（）  

A.同轴电缆的铜芯比双绞线粗，能通过更大的电流B.同轴电缆的阻抗比较标准，减少了信号的衰减 C.同轴电缆具有更高的屏蔽性，同时有更好的抗噪声性D.以上都正确  

05.不受电磁干扰和噪声影响的传输介质是（）  

A.屏蔽双绞线 B.非屏蔽双绞线 C.光纤 D.同轴电缆  

06.多模光纤传输光信号的原理是（）  

A.光的折射特性B.光的发射特性C.光的全反射特性D.光的绕射特性  

07.以下关于单模光纤的说法中，正确的是（）。  

A.光纤越粗，数据传输速率越高B.若光纤的直径减小到只有光的一个波长大小，则光沿直线传播C.光源是发光二极管或激光D.光纤是中空的  

08.下列关于卫星通信的说法中，错误的是（）  

A卫星通信的距离长，覆盖的范围广 B.使用卫星通信易于实现广播通信和多址通信C.卫星通信的好处在于不受气候的影响，误码率很低 D.通信费用高、延时较大是卫星通信的不足之处  

09.某网络在物理层规定，信号的电平用 $+10\mathrm{V}\sim+15\mathrm{V}$ 表示二进制0，用-10V\~-15V表示二进制1，电线长度限于 $15\mathrm{m}$ 以内，这体现了物理层接口的（）。A.机械特性B.功能特性C.电气特性D.规程特性  
10.当描述一个物理层接口引脚处于高电平时的含义时，该描述属于（）A.机械特性B.电气特性C.功能特性D.规程特性11.【2012统考真题】在物理层接口特性中，用于描述完成每种功能的事件发生顺序的是（）。A.机械特性B.功能特性C.过程特性D.电气特性12.【2018统考真题】下列选项中，不属于物理层接口规范定义范畴的是（）A.接口形状B.引脚功能C.物理地址D.信号电平  

# 2.2.4 答案与解析  

单项选择题  

01.A  

绞合可以减少两根导线相互的电磁干扰。  

02.B 屏蔽层的主要作用是提高电缆的抗干扰能力  

03.B  

传统以太网采用广播的方式发送信息，同一时间只充许一台主机发送信息，否则各主机之间就形成冲突，因此主机间的通信方式是半双工。全双工是指通信双方可同时发送和接收信息。单工是指只有一个方向的通信而没有反方向的交互。  

04.C  

同轴电缆以硬铜线为芯，外面包一层绝缘材料，绝缘材料的外面再包一层密织的网状导体，导体的外面又覆盖一层保护性的塑料列壳。这种结构使得它具有更高的屏蔽性，从而既有很高的带宽，又有很好的抗噪性。因此，同轴电缆的带宽更高得益于它的高屏蔽性。  

05.C 光纤抗雷电和电磁干扰性能好，无串音干扰，保密性好。  

06.C 多模光纤传输光信号的原理是光的全反射特性。  

07.B 光纤的直径减小到与光线的一个波长相同时，光纤就如同一个波导，光在其中没有反射，而沿直线传播，这就是单模光纤。  

08.C 卫星通信有成本高、传播时延长、受气候影响大、保密性差、误码率较高的特点。  

09.C  

本题易误选功能特性。规定各条线上的电压范围，以及电缆长度的限制，属于电气特性。而功能特性指明某条线上出现的某一电平的电压表示何种意义，以及每条线的功能（数据线、控制线、时钟线）。例如，数据线上的电压 $+11\mathrm{V}$ 表示二进制1，就属于功能特性。  

物理层的功能特性指明某条线上出现的某一电平的电压表示何种意义，以及每条线的功能。  

11.C 物理层的过程特性指明对于不同功能的各种可能事件的出现顺序。  
12.C  

物理层的接口规范主要分为4种：机械特性、电气特性、功能特性、过程特性。机械特性规定连接所用设备的规格，如A所说的接口形状。电气特性规定各条线上的电压范围、阻抗匹配等，如D所说的信号电平。功能特性规定线路上出现的电平表示何种意义及每条线的功能，如B所说的引脚功能。C中的物理地址是MAC地址，它属于数据链路层的范畴。  

# 2.3物理层设备  

# 2.3.1中继器  

中继器的主要功能是整形、放大并转发信号，以消除信号经过一长段电缆后产生的失真和衰减，使信号的波形和强度达到所需的要求，进而扩大网络传输的距离。其原理是信号再生（而非简单地放大衰减的信号）。中继器有两个端口，数据从一个端口输入，从另一个端口发出。端口仅作用于信号的电气部分，而不管是否有错误数据或不适于网段的数据。  

中继器是用来扩大网络规模的最简单的廉价互连设备。中继器两端的网络部分是网段，而不是子网，使用中继器连接的几个网段仍是一个局域网。中继器若出现敌障，则对相邻两个网段的工作都产生影响。因为中继器工作在物理层，所以不能连接两个具有不同速率的局域网。  

# 注意  

若某个网络设备有存储转发功能，则认为它能连接两个不同的协议；若该网络设备无存储转发功能，则认为它不能连接两个不同的协议。中继器没有存储转发功能，因此它不能连接两个速率不同的网段，中继器两端的网段一定要使用同一个协议。  

从理论上讲，中继器的使用数目是无限的，网络因而也可无限延长。但事实上这是不可能的，因为网络标准中对信号的延迟范围做了具体规定，中继器只能在该范围内进行有效的工作，否则会引起网络敌障。例如，在采用粗同轴电缆的10BASE5以太网规范中，互相串联的中继器的个数不能超过4个，而且用4个中继器事联的5段通信介质中，只有3段可以挂接计算机，其余2段只能用作扩展通信范围的链路段，不能挂接计算机。这就是所谓的“5-4-3规则”。  

# 注意  

放大器和中继器都起放大作用，只不过放大器放大的是模拟信号，其原理是放大衰减的信号，而中继器放大的是数字信号，其原理是整形再生衰减的信号。  

# 2.3.2集线器  

集线器（Hub）实质上是一个多端口的中继器。当Hub工作时，一个端口接收到数据信号后，因为信号在从端口到Hub的传输过程中已有衰减，所以Hub便对该信号进行整形放大，使之再生（恢复）到发送时的状态，紧接着转发到其他所有（除输人端口外）处于工作状态的端口。若同时有两个或多个端口输入，则输出时将发生冲突，致使这些数据都无效。从Hubb的工作方式可以看出，它在网络中只起信号放大和转发作用，自的是扩大网络的传输范围，而不具备信号的定向传送能力，即信息传输的方向是固定的，是标准的共享式设备。  
使用Hub组网灵活，它将所有结点的通信集中在以其为中心的结点上，由Hub组成的网络是共享式网络，但逻辑上仍是总线网。Hu品b的每个端口连接的是同一网络的不同网段，同时Hub也只能在半双工状态下工作，网络的吞吐率因而受到限制。  

>#### pro：中继器和集线器对冲突域/广播域的划分（2010、2020）  

# 注意  

集线器不能分割冲突域，集线器的所有端口都属于同一个冲突域。集线器在一个时钟周期内只能传输一组信息，当一台集线器连接的机器数目较多且多台机器经常需要同时通信时，将导致信息冲突，使得集线器的工作效率很差。例如，一个带宽为10MIb/s的集线器上连接了8台计算机，当这8台计算机同时工作时，每台计算机所真正拥有的带宽为 $10/8\mathrm{{M}\mathrm{{b}/\mathrm{{s}=1.25\mathrm{{M}\mathrm{{b}/\mathrm{{s}.}}}}}}$  


# 2.4本章小结及疑难点  

1.传输介质是物理层吗？传输介质和物理层的主要区别是什么？  

传输介质并不是物理层。因为传输介质在物理层的下面，而物理层是体系结构的第一层，所以有时称传输介质为0层。在传输介质中传输的是信号，但传输介质并不知道所传输的信号代表什么。也就是说，传输介质不知道所传输的信号什么时候是1、什么时候是0。但是，物理层因为规定了电气特性，所以能够识别所传送的比特流。图2.9描述了上述概念。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/2f1f5f2c0d7fe7203bffb23547955323749cf1e817aa2ce960cb455a03143dca.jpg)  
图2.9传输介质与物理层  
# 2.什么是基带传输、频带传输和宽带传输？三者的区别是什么？  

在计算机内部或在相邻设备之间近距离传输时，可不经过调制就在信道上直接进行的传输方式称为基带传输。它通常用于局域网。数字基带传输就是在信道中直接传输数字信号，且传输介质的整个带宽都被基带信号占用，双向地传输信息。最简单的方法是用两个高低电平来表示二进制数字，常用的编码方法有不归零编码和曼彻斯特编码。例如，要传输1010，低电平代表0，高电平代表1，那么在基带传输下，1010需要向通信线路传输（高、低、高、低电平）。  

用数字信号对特定频率的载波进行调制（数字调制），将其变成适合传送的信号后再进行传输，这种传输方式就是频带传输。当采用远距离传输或无线传输时，数字信号必须用频带传输技术进行传输。利用频带传输，不仅解决了电话系统传输数字信号的问题，而且可以实现多路复用，进而提高传输信道的利用率。同样传输1010，经过调制，一个码元对应4个二进制位，假设码元A代表1010，那么在模拟信道上传输码元A就相当于传输1010。  

借助频带传输，可将链路分解成两个或多个信道，每个信道可携带不同的信号，这就是宽带传输。宽带传输中所有的信道能同时互不干扰地发送信号。例如，对信道进行频分复用，划分为2个互不相关的子信道，分别在两个子信道上同时进行频带传输，链路容量就会大大增加。  

3.奈氏准则和香农定理的主要区别是什么？这两个定理对数据通信的意义是什么？  

奈氏准则指出，码元传输的速率是受限的，不能任意提高，否则接收端就不能正确判定码元所携带的比特数据（因为码元之间存在相互干扰）。奈氏准则是在理想条件下推导出来的。在实际条件下，最高码元传输速率要比理想条件下得出的数值小很多。  

值得注意的是，奈氏准则并未限制信息传输速率。要提高信息传输速率，就必须使每个码元能够携带许多比特的信息。但是，码元所载的比特数确定后，信道的极限数据率也就确定了。  

香农定理给出了信息传输速率的极限，即对于一定的传输带宽（单位为Hz）和一定的信噪比，信息传输速率的上限是确定的，这个极限不能突破。要想提高信息传输速率，要么设法提高传输线路的带宽，要么设法提高信道的信噪比，此外没有其他任何办法。  

香农定理告诉我们，要得到无限大的信息传输速率，只有两个办法：要么使用无限大的传输带宽（这显然不可能），要么使信号的信噪比无限大，即采用没有噪声的信道或使用无限大的发送功率（这显然也不可能）。注意，奈氏准则和香农定理中“带宽”的单位都是 $\mathrm{Hz}$  

4.信噪比为SIN，为什么还要取对数 $10\mathrm{log}_{10}(S/N)?$ 1）数字形式表示，如噪声功率为1，信号功率为100，信噪比为 $100/1\,{=}\,100$ 2）同样还是上面这些数字，以分贝形式表示的信噪比为 $10\mathrm{log}_{10}(S/N)\,{=}\,10\mathrm{log}_{10}100\,{=}\,20\mathrm{dB}\,.$  

二者在数值上等价。区别在于，前者没有单位，后者必须加dB（分贝）。采用分贝表示的原因：很多时候，信号要比噪声强得多，如信号比噪声强10亿倍，若用数值表示，则1后面有9个0，很容易丢失0；若用分贝表示，则仅为90dB，因此要简单得多，且不容易出错。分贝对于表示特别大或特别小的数值极为方使，在通信领域中用途很广。  
# 第3章数据链路层  

# 【考纲内容】  

（一）数据链路层的功能  

（二）组帧  

（三）差错控制  

检错编码：纠错编码  

（四）流量控制与可靠传输机制流量控制、可靠传输与滑动窗口机制：停止-等待协议：后退 $N$ 帧协议（GBN）：选择重传协议（SR）  

（五）介质访问控制  

1.信道划分：频分复用、时分复用、波分复用、码分复用2.随机访问：ALOHA协议：CSMA协议：CSMA/CD协议：CSMA/CA协议3.轮询访问：令牌传递协议  

（六）局域网局域网的基本概念与体系结构：以太网与IEEE802.3；IEEE802.11无线局域网：VLAN的基本概念与基本原理  

（七）广域网广域网的基本概念：PPP协议  

以太网交换机及其工作原理  

# 【复习提示】  

本章是历年考试中考查的重点。要求在了解数据链路层基本概念和功能的基础上，重点掌握滑动窗口机制、三种可靠传输协议、各种MAC协议，特别是CSMA/CD协议、CSMA/CA协议和以太网顿格式，以及局域网的争用期和最小帧长的概念、二进制指数退避算法。此外，中继器、网卡、集线器、网桥和局域网交换机的原理及区别也要重点掌握。  

# 3.1数据链路层的功能  

数据链路层的主要任务是实现帧在一段链路上或一个网络中进行传输。数据链路层协议有多种，但有三个基本问题则是共同的，即封装成顿、透明传输和差错检测。  

数据链路层使用的信道主要有两种：  
1）点对点信道，使用一对一的通信方式。PPP协议则是目前使用最广泛的点对点协议。2）广播信道，这种信道上连接的主机很多，使用一对多的广播通信方式。采用共享广播信道的有线局域网普遍使用CSMA/CD协议，而无线局域网则使用CSMA/CA协议。  

# 3.1.1数据链路层所处的地位  

下面使用两台主机通过互联网进行通信的例子来了解数据链路层所处的地位，如图3.1所示。局域网1中的主机H1经过路由器R1、广域网及路由器R2连接到局域网2中的主机H2。主机H1和H2都有完整的五层协议栈，而路由器在转发分组时仅使用协议栈的下三层。当主机H1向H2发送数据时，从协议的层次上看，数据的流动如图3.2所示。数据进入路由器后要先从物理层上到网络层，在转发表中我到下一跳的地址后，再下到物理层转发出去。因此，数据从主机H1送到主机H2需要在路径中的各结点的协议栈向上和向下流动多次。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/e7e297fbb0520613c7252ae1f3530980f5248c701458e45dd8079c49662f2683.jpg)  
图3.1主机H1向H2发送数据  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/25920ca739682fceb5264e70ee939f8d7abe7feee0fa034448b85f86ab86b5f8.jpg)  
图3.2从层次上看数据的流动  

当我们学习数据链路层时，通常可以只关心协议栈中水平方向的各数据链路层。于是，当主机H1向主机H2发送数据时，可以想象数据就是在各相关设备的数据链路层之间沿水平方向传送的。如图3.3所示，即通过以下这样的链路：H1的链路层 $\to\!\mathrm{R1}$ 的链路层 $\to\!\mathbb{R}2$ 的链路层一H2的链路层，其中三段不同的数据链路可能采用不同的数据链路层协议。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/ffb78b2e18190098f64fcc494beb631836f32110a4006eb8b1a6412e30626310.jpg)  
图3.3只考虑数据在数据链路层的流动  

下面介绍点对点信道的一些基本概念，某些概念对广播信道也是适用的。  

1）链路。指从一个结点到相邻结点的一段物理线路。当进行数据通信时，两台计算机之间的通信路径往往要经过许多段这样的链路。可见链路只是一条路径的组成部分。  

2）数据链路。当在一条链路上传送数据时，除了需要链路本身，还需要一些必要的通信协议来控制这些数据的传输，把实现这些协议的硬件和软件加到链路上，就构成了数据链  
路。有时也把上面所说的链路称为物理链路，而把数据链路称为逻辑链路。  

3）顿。数据链路层对等实体之间进行逻辑通信的协议数据单元。数据链路层把网络层下交的数据构成帧发送到链路上，并把接收到的帧中的数据取出并上交给网络层。  

# 3.1.2为网络层提供服务  

数据链路层通常可以为网络层提供如下三种服务：  

1）无确认的无连接服务。源主机发送帧时不需要先建立链路连接，目的主机收到帧时不需要发回确认。数据传输的可靠性由高层负责。适用于误码率较低的信道，如以太网。  

2）有确认的无连接服务。源主机发送帧时不需先建立链路连接，但目的主机收到帧时必须发回确认。源主机在所规定的时间内未收到确定信号时，就重传丢失的帧，以提高传输的可靠性。该服务适用于误码率较高的信道，如无线通信。  

3）有确认的面向连接服务。顿传输过程分为三个阶段：建立链路、传输顿、释放链路。目的主机对收到的每一个帧都要返回确认。该服务适用于可靠性要求较高的场合。  

# 注意  

有连接就一定要有确认，即不存在无确认的面向连接的服务。  

# 3.1.3链路管理  

数据链路层连接的建立、维持和释放过程称为链路管理，它主要用于面向连接的服务。链路两端的结点要进行通信，必须首先确认对方已处于就绪状态，并交换一些必要的信息以对顺序号初始化，然后才能建立连接，在传输过程中要能维持连接，而在传输完毕后要释放该连接。  

# 3.1.4 封装成帧与透明传输  

封装成顿是指在一段数据的前后分别添加首部和尾部，构成顿，顺是数据链路层的数据传送单元。顿长等于帧的数据部分长度加上首部和尾部的长度。首部和尾部中含有很多控制信息，它们的一个重要作用是确定帧的界限，即顿定界。接收方能从接收到的二进制比特流中区分出帧的起始与终止，即帧同步。如在HDLC协议中，用标识位F（01111110）来标识帧的开始和结束。在通信过程中，检测到帧标识位F即认为其是顿的开始，然后一旦检测到帧标识位F即表示顿的结束。HDLC标准帧格式如图3.4所示。为了提高帧的传输效率，应当使帧的数据部分的长度尽可能地大于首部和尾部的长度，但随着帧长的增加，传输差错发生的概率也随之提高，发生差错时重传的代价也越大，因此每种链路层协议都规定了帧的数据部分的长度上限，即最大传送单元。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/cf66d2f1d0b40f4535ac0e51bb07fdcdfe8a22a900b11a84e927a41c2f9190f7.jpg)  
图3.4HDLC标准帧格式  

若在数据中恰好出现与顺定界符相同的比特组合（会误认为“传输结束”而丢弃后面的数据），则要采取有效的措施来解决这个问题，即透明传输。更确切地说，透明传输是指不论所传的数据是什么样的比特组合，都能够按原样无差错地在这个数据链路上传输。  

# 3.1.5流量控制  

因为链路两端结点的工作速率和缓存空间存在差异，所以发送方的发送能力可能大于接收方的接收能力，此时若不适当限制发送方的发送速率，前面来不及接收的帧将被后面不断发送来的倾“淹没”，造成顿的丢失而出错。因此，流量控制实际上就是限制发送方的发送速率，使之不超过接收方的接收能力。这个过程需通过某种反馈机制，使发送方知道在什么情况下可以接着发送下一帧，而在什么情况下必须暂停发送，以等待收到某种反馈信息后继续发送。  
在OSI体系结构中，数据链路层具有流量控制的功能。而在TCP/IP体系结构中，流量控制功能被移到了传输层。它们控制的对象不同。对数据链路层来说，控制的是相邻结点之间的数据链路上的流量，而对传输层来说，控制的则是从源端到目的端之间的流量。  

# 3.1.6 差错检测  

因为信道噪声等原因，顿在传输过程中可能会出现错误，这些错误分为位错和顿错  

1）位错：帧中某些位出现差错，通常采用循环冗余检验（CRC）来发现位错。2）顿错：帧丢失、顿重复或帧失序等错误，它们都属于传输差错。  

过去OSI的观点是：必须让数据链路层向上提供可靠传输。因此在CRC检错的基础上，增加了帧编号、确认和重传机制。收到正确的帧就要向发送方发送确认。发送方在一定期限内若未收到对方的确认，就认为出现了差错，因此进行重传，直到收到确认为止。现在，在通信质量较差的无线传输中，数据链路层依然使用确认和重传机制，向上提供可靠的传输服务。  

对于通信质量良好的有线链路，数据链路层已不再使用确认和重传机制，即不要求向上提供可靠传输的服务，而仅需进行CRC检错，目的是将有差错的帧丢弃，保证上交的帧都是正确的，而对出错的顿的重传任务则由高层协议（如传输层TCP协议）完成。  
 

# 3.2 组帧  

发送方依据一定的规则将网络层递交的分组封装成帧（也称组帧）。数据链路层之所以要将比特组合成以帧为单位传输，是为了在出错时只重发出错的帧，而不必重发全部数据，从而提高效率。组帧主要解决帧定界、顿同步、透明传输等问题。实现组帧的方法通常有以下4种。  
# 注意  

组帧时既要加首部，又要加尾部。原因是，在网络中信息是以帧为最小单位进行传输的，所以接收方要正确地接收顿，就必须清楚该倾在一串比特流中从哪里开始到哪里结束（因为接 收方收到的是一串比特流，没有首部和尾部是不能正确区分帧的）。而分组（即IP数据报）仅是包含在顿中的数据部分（后面将详细讲解），所以不需要加尾部来定界。  

# 3.2.1字符计数法  

字符计数法是指在顺首部使用一个计数字段来记录该帧所含的字节数（包括计数字段自身所占用的1个字节），如图3.5所示。当接收方读出顿首部的字节计数值时，就知道后面跟随的字节数，从而确定帧结束位置。因为帧与帧之间是连续传输的，所以也能确定下一顺的开始位置。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/18cc49d5bb85480e0fc592ac0552950e0a6fde483285e113ce24cf11aa21335f.jpg)  
图3.5字符计数法  

这种方法最大的问题在于若计数字段出错，即失去帧边界划分的依据，则接收方就无法判断所传输帧的结束位和下一帧的开始位，收发双方将失去同步，造成灾难性后果。  

# 3.2.2字节填充法  

字节填充法使用特定字节来定界一帧的开始与结束，在图3.6的例子中，控制字符SOH放在倾的最前面，表示帧的开始，控制字符EOT表示顺的结束。为了使信息位中出现的特殊字符不被误判为帧的首尾定界符，可在特殊字符之前填充一个转义字符ESC来加以区分（注意，转义字符是ASCII码中的控制字符，是一个字符，而非“E”“S”“C”三个字符的组合），以实现数据的透明传输。接收方收到转义字符后，就知道其后面紧跟的是数据信息，而不是控制信息。  

在图3.6(a)所示的字符帧中，帧的数据段中出现EOT或SOH字符，发送方在每个EOT或SOH字符前再插入一个ESC字符［见图3.6(b)」，接收方收到数据后会自己册除这个插入的ESC字符，结果仍得到原来的数据[见图3.6（c)]。这也正是字符填充法名称的由来。若转义字符ESC也出现在数据中，则解决方法仍是在转义字符前插入一个转义字符。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/8bc622f7582e5fe4c3b6569bf04fcef4d549661a5ba94591071cdb9feec74e46.jpg)  
图3.6字节填充法  

# 3.2.3零比特填充法  

>#### pro：HDLC协议中的比特填充法（2013）  

零比特填充法允许数据帧包含任意个数的比特，它使用一个特定的比特串 $0111110$ 来标志一顿的开始和结束，如图3.7所示。为了不使数据字段中出现的比特流01111110被误判为帧的首尾标志，发送方先扫描整个数据字段，每遇到5个连续的“1”，就自动在其后插入一个“0”。经过这种比特填充后，就可保证数据字段中不会出现6个连续的“1”。接收方做该过程的逆操作，即每收到5个连续的“1”，就自动删除后面紧跟的“0”，以恢复原始数据。在数据链路层早期使用的HDLC协议中，便是采用这种比特填充的首尾标志法来实现透明传输的。  
（a）原始数据011011110010(b)线上数据011011111011111011111010010填充的位（c）接收方删除填0110111 1111110010 充位后的数据图3.7比特填充法  

零比特填充法很容易由硬件来实现，性能优于字节填充法  

# 3.2.4违规编码法  

在物理层进行比特编码时，常采用违规编码法。例如，曼彻斯特编码方法将数据比特“1”编码成“高-低”电平对，将数据比特“0”编码成“低-高”电平对，而“高一高”电平对和“低一低”电平对在数据比特中是违规的（即没有采用），因此可借用这些违规编码序列来定界顿的起始和终止。局域网IEEE802标准就采用了这种方法。违规编码法不采用任何填充技术便能实现数据的透明传输，但只适用于采用余编码的特殊编码环境。广  

因为字符计数法中计数字段的脆弱性和字节填充法实现上的复杂性与不兼容性，所以自前较常用的组帧方法是零比特填充法和违规编码法。  


# 3.3差错控制  

实际通信链路都不是理想的，比特在传输过程中可能产生差错，1可能变成0，0也可能变成1，这就是比特差错。比特差错是传输差错中的一种，本节仅讨论比特差错。  

通常利用编码技术进行差错控制，主要有两类：自动重传请求（AutomaticRepeatreQuest，ARQ）和前向纠错（Forward Error Correction，FEC）。在ARQ方式中，当接收方检测到差错时，就设法通知发送方重发，直到收到正确的数据为止。在FEC方式中，接收方不但能发现差错，而且能确定错误的位置并加以纠正。因此，差错控制又可分为检错编码和纠错编码。  

# 3.3.1 检错编码  

检错编码都采用冗余编码技术，核心思想是在有效数据（信息位）被发送前，按某种关系附加一定的余位，构成一个符合某一规则的码字后发送。当要发送的有效数据变化时，相应的冗余位也随之变化，使得码字遵从不变的规则。接收方根据收到的码字是否仍符合原规则来判断是否出错。常见的检错编码有奇偶检验码和循环见余码。  

# 1.奇偶检验码  

奇偶检验码是奇检验码和偶检验码的统称，是一种最基本的检错码。它由 $n-1$ 位数据和1位检验位组成，检验位的取值（0或1）将使整个检验码中“1”的个数为奇数或偶数。  

1）奇检验码：附加一个检验位后，码长为 $n$ 的码字中“1”的个数为奇数。2）偶检验码：附加一个检验位后，码长为 $n$ 的码字中“1”的个数为偶数。  

例如，7位数据1001101对应的奇检验码为10011011，对应的偶检验码为10011010。它只能检测奇数位的出错情况，但不知道哪些位错了，也不能发现偶数位的出错情况。  

2.循环冗余码  

（Cyclic Redundancy Code，CRC）检错技术。  

循环冗余码（CRC）检错的基本思想：1）收发双方约定生成多项式 $G(x)$ （最高位和最低位必须为1)。 $k$ 位位串可视为阶数为 $k\!-\!1$ 的  
多项式的系数序列。例如，可用多项式 $x^{3}+x^{2}+1$ 表示位串1101。2）发送方基于待发送的数据和 $G(x)$ ，计算出余码，将余码附加到数据后面一起发送。3）接收方收到数据和冗余码后，通过 $G(x)$ 来计算收到的数据和冗余码是否产生差错  

假设一个待传送 $m$ 位的数据，CRC运算产生一个 $r$ 位的冗余码，称为顿检验序列（FCS)。这样形成的帧将由 $m+r$ 位组成。在所要发送的数据后面增加 $r$ 位冗余码，虽然增大了传输开销，但是可以进行差错检测，这种代价往往是值得的。这个带检验码的帧刚好能被预先确定的多项式 $G(x)$ 整除。接收方用相同的多项式去除收到的帧，若无余数，则认为无差错。  

>#### pro：循环余码的计算（2023）  

假设一段 $m$ 位数据，则计算余码的步骤如下：1）加0。假设 $G(x)$ 的阶为 $r$ ，在数据后面加 $r$ 个 $0$ ，相当于乘以 $2^{r}$  

2）模2除。利用模2除法，用 $G(x)$ 对应的二进制串去除1）中计算得出的数据串，得到的余数即为冗余码（共 $r$ 位，前面的0不可省略）。  

按照模2运算规则，加法不进位，减法不借位，相当于对应位进行逻辑异或运算。  

冗余码的计算举例。假设数据 $M\!=\!101001$ （即 $m\!=\!6$ )，除数 $G(x)\!=\!1101$ （即 $r\!=\!3\,.$ ），经模2除法运算后的结果是：商 $Q\,{=}\,110101$ （这个商没什么用），余数 $R\!=\!001$ 。因此，发送出去的数据为 $101001\;001$ （即 $2^{r}M+\mathrm{FCS}$ )，共有 $m+r$ 位，运算过程如图3.8所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/7fe3ce6cca99d7917138341845afea8f15d743f93b7222c8dc023eca16fb4d69.jpg)  
图3.8循环冗余码的运算过程  

发送方的FCS生成和接收方的CRC检验都是由硬件实现的，处理非常迅速，不会影响数据的传输。若在传输过程中无差错，则经过CRC检验后得出的余数 $R$ 肯定为0。但是，若出现误码，则余数 $R$ 仍为0的概率极低。因此，通过CRC检错技术，可以近似地认为“凡是接收方数据链路层接受的顿均无差错”。也就是说，凡是接收方数据链路层接受的帧，我们都能以非常接近1的概率认为这些帧在传输过程中未产生差错；而接收方丢弃的顿虽然曾经收到，但最终因为有差错而被丢弃，即未被接受。  

# 注意  

循环冗余码（CRC）是具有纠错功能的，只是数据链路层仅使用了它的检错功能，检测到帧出错则直接丢弃，是为了方便协议的实现，因此本节将CRC放在检错编码中介绍。  

# 3.3.2纠错编码  

最常见的纠错编码是海明码，其实现原理是在有效信息位中加入几个检验位形成海明码，并把海明码的每个二进制位分配到几个奇偶检验组中。某一位出错后，就会引起有关的几个检验位的值发生变化，这不但可以发现错位，而且能指出错位的位置，为自动纠错提供依据。  
现以数据码1010为例讲述海明码的编码原理和过程  

（1）确定海明码的位数设 $n$ 为有效信息的位数， $k$ 为检验位的位数，则信息位 $n$ 和检验位 $k$ 应满足  

$$
n+k\leqslant2^{k}-1
$$  

海明码位数 $n+k=7\!\leqslant\!2^{3}\!-\!1$ 成立，则 $n,\;k$ 有效。设信息位为 $D_{4}D_{3}D_{2}D_{1}$ （1010)，共4位，检验位为 $P_{3}P_{2}P_{1}$ ，共3位，对应的海明码为 $H_{7}H_{6}H_{5}H_{4}H_{3}H_{2}H_{1}$  

（2）确定检验位的分布规定检验位 $P_{i}$ 在海明位号为 $2^{i-1}$ 的位置上，其余各位为信息位，因此有：  

$P_{1}$ 的海明码位号为 $2^{i-1}\!=\!2^{0}\!=\!1$ ，即 $H_{1}$ 为 $P_{1}$  $P_{2}$ 的海明码位号为 $2^{i-1}\!=\!2^{1}\!=\!2$ ，即 $H_{2}$ 为 $P_{2}$  $P_{3}$ 的海明码位号为 $2^{i-1}\!=\!2^{2}\!=\!4$ ，即 $H_{4}$ 为 $P_{3}$  

将信息位按原来的顺序插入，则海明码各位的分布如下：  

$$
\begin{array}{c c c c c c c c}{{H_{7}}}&{{H_{6}}}&{{H_{5}}}&{{H_{4}}}&{{H_{3}}}&{{H_{2}}}&{{H_{1}}}\\ {{D_{4}}}&{{D_{3}}}&{{D_{2}}}&{{P_{3}}}&{{D_{1}}}&{{P_{2}}}&{{P_{1}}}\end{array}
$$  

（3）分组以形成检验关系  

每个数据位用多个检验位进行检验，但要满足条件：被检验数据位的海明位号等于检验该数据位的各检验位海明位号之和。另外，检验位不需要再被检验。分组形成的检验关系如下。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f963b4fdaa3d709ead387b3b915ec9d6919e696e045e6a79d41c56bbe2ccb151.jpg)  

（4）检验位取值  

检验位 $P_{i}$ 的值为第 $i$ 组（由该检验位检验的数据位）所有位求异或。  

根据（3）中的分组有  

$P_{1}\!=\!D_{1}\oplus D_{2}\oplus D_{4}\!=\!0\oplus1\oplus1\!=\!0$   $P_{2}\!=\!D_{1}\oplus D_{3}\oplus D_{4}\!=\!0\oplus0\oplus1\!=\!1$   $P_{3}\!=\!D_{2}\oplus D_{3}\oplus D_{4}\!=\!1\oplus0\oplus1\!=\!0$  

所以，1010对应的海明码为1010010（下画线为检验位，其他为信息位）。  

（5）海明码的检验原理  

每个检验组分别利用检验位和参与形成该检验位的信息位进行奇偶检验检查，构成 $k$ 个检验方程：  

$$
\begin{array}{c}{S_{1}\!=\!P_{1}\oplus D_{1}\oplus D_{2}\oplus D_{4}}\\ {S_{2}\!=\!P_{2}\oplus D_{1}\oplus D_{3}\oplus D_{4}}\\ {S_{3}\!=\!P_{3}\oplus D_{2}\oplus D_{3}\oplus D_{4}}\end{array}
$$  

若 $S_{3}S_{2}S_{1}$ 的值为“000”，则说明无错：否则说明出错，且这个数就是错误位的位号，如 $S_{3}S_{2}S_{1}\!=\!001$ 说明第1位出错，即 $H_{1}$ 出错，直接将该位取反就达到了纠错的自的。  

# 3.4流量控制与可靠传输机制  

在数据链路层中，流量控制机制和可靠传输机制是交织在一起的。  

# 3.4.1流量控制与滑动窗口机制  

流量控制是指由接收方控制发送方的发送速率，使接收方有足够的缓冲空间来接收每个帧。常见的流量控制方法有两种：停止-等待协议和滑动窗口协议。数据链路层和传输层均有流量控制的功能，它们都用到了滑动窗口协议，但也有所区别，主要体现如下：  

1）数据链路层控制的是相邻结点之间的流量，而传输层控制的是端到端的流量。  

2）数据链路层的控制手段是接收方收不下就不返回确认。传输层的控制手段是接收方通过确认报文段中的窗口值来调整发送方的发送窗口。  

# 1.停止-等待流量控制基本原理  

停止-等待流量控制是一种最简单的流量控制方法。发送方每次只充许发送一个帧，接收方每接收一个顿都要反馈一个应答信号，表示可以接收下一帧，发送方收到应答信号后才能发送下一顿。若发送方没有收到接收方反馈的应答信号，则需要一直等待。发送方每发送完一个帧，就进入等待接收方确认信息的过程中，因而传输效率很低。  

# 2.滑动窗口流量控制基本原理  

滑动窗口流量控制是一种更高效的流量控制方法。在任意时刻，发送方都维持一组连续的允许发送帧的序号，称为发送窗口；同时接收方也维持一组连续的允许接收帧的序号，称为接收窗口。发送窗口表示在还未收到对方确认信息的情况下，发送方最多还能发送多少个顺和哪些顺。同理，在接收方设置接收窗口是为了控制可以接收哪些倾和不可以接收哪些顺。  

图3.9给出了发送窗口的工作原理，图3.10给出了接收窗口（ $W_{\mathrm{T}}{=}\,1$ ）的工作原理  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/248725a206d61268b973ecf8d7a386b827f85a708e4466f48aca92b0595310cb.jpg)  
图3.9发送窗口控制发送方的发送速率：（a)允许发送 $_{0\sim4}$ 号共5个帧：（b)允许发送 $1\!\sim\!4$  号共4个帧；(c)不允许发送任何帧；(d)允许发送  $5{\sim}7$  号共3个帧  
发送方每收到一个按序确认的确认帧，就将发送窗口向前滑动一个位置。这样，就有一个新的序号落入发送窗口，序号落入发送窗口内的数据帧可以继续发送。当窗口内没有可以发送的帧（即窗口内的帧全部是已发送但未收到确认的帧）时，发送方就停止发送。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/9d828f694c1132f7e08e7c2789e1420a756d8816e676452e1fb324f88be8ccd3.jpg)  
图3.10 $W_{\mathrm{R}}\!=\!1$ 的接收窗口的意义  

接收方每收到一个序号落入接收窗口的数据顿，就充许将该帧收下，然后将接收窗口向前滑动一个位置，并发回确认。这样，就有一个新的序号落入接收窗口，序号落入接收窗口内的数据倾即为准备接收的帧。若收到的帧落在接收窗口之外，则一律丢弃。  

滑动窗口具有以下重要特性：  

1）只有接收窗口向前滑动（同时接收方发送了确认）时，发送窗口才有可能（只有发送方收到确认后才一定）向前滑动。  

>#### pro：滑动窗口协议的窗口大小的关系（2019）  

2）从滑动窗口的概念看，停止-等待协议、后退  $N$  帧协议和选择重传协议只在发送窗口大小  

与接收窗口大小上有所差别：停止-等待协议：发送窗口  $W_{\mathrm{T}}\!=\!1$  ，接收窗口  $W_{\mathbb{R}}\!=\!1$  后退 $N$ 帧协议：发送窗口 $W_{\mathrm{T}}\!>\!1$ ，接收窗口 $W_{\mathbb{R}}\!=\!1$ 。选择重传协议：发送窗口  $W_{\mathrm{T}}\!>\!1$  ，接收窗口  $W_{\mathbb{R}}\!>\!1$  若采用  $n$  比特对帧编号，则后两种滑动窗口协议还需满足  $W_{\mathrm{{T}}}+W_{\mathrm{{R}}}\leqslant2^{n}$  

3）当接收窗口的大小为1时，可保证帧的有序接收。4）在数据链路层的滑动窗口协议中，窗口大小在传输过程中是固定的（与传输层不同）。  

# 3.4.2可靠传输机制  

可靠传输是指发送方发送的数据都能被接收方正确地接收，通常采用确认和超时重传两种机制来实现。确认是指接收方每收到发送方发来的数据顺，都要向发送方发回一个确认顺，表示已正确地收到该数据帧。超时重传是指发送方在发送一个数据顿后就启动一个计时器，若在规定时简内没有收到所发送数据顺的确认顿，则重发该数据顿，直到发送成功为止。  

使用这两种机制的可靠传输协议称为自动重传请求（ARQ），它意味着重传是自动进行的，接收方不需要对发送方发出重传请求。在ARQ协议中，数据帧和确认帧都必须编号，以区分确认帧是对哪个帧的确认，以及哪些帧还未确认。ARQ协议分为三种：停止-等待（Stop-and-Wait）协议、后退 $N$ 帧（Go-Back-N）协议和选择重传（SelectiveRepeat）协议。值得注意的是，这三种可靠传输协议的基本原理并不仅限于数据链路层，还可应用到其上各层。  
在有线网络中，链路的误码率较低，为了降低开销，并不要求数据链路层向其上层提供可靠传输服务，即使出现了误码，可靠传输的问题也由其上层处理。而无线网络的链路易受干扰，误码率较高，因此要求数据链路层必须向其上层提供可靠传输服务。  

# 1.单帧滑动窗口与停止-等待协议（S-W）  

在停止-等待协议中，发送方每次只能发送一个帧，当发送方收到接收方的确认帧之后，才可以发送下一个帧。从滑动窗口的角度看，停止-等待协议的发送窗口和接收窗口大小均为1。  

在停止-等待协议中，除数据帧丢失外，还可能出现以下两种差错： $\textcircled{\scriptsize{1}}$ 到达接收方的数据帧可能已遭破坏，接收方利用前面介绍的差错检测技术检出后，简单地将该帧丢弃。为了应付这种可能的情况，发送方装备了计时器。在一个帧发送后，发送方等待确认，当计时器超时的时候，若仍未收到确认，则重发该数据帧。如此重复，直到该数据顿正确到达为止。 $\textcircled{2}$ 数据顿正确而确认帧被破坏，此时接收方已收到正确的数据帧，但发送方收不到确认顿，因此发送方会重传已被接收的数据顿，接收方收到相同的数据顿时会丢弃该帧，并重传一个该帧对应的确认帧。  

对于停止-等待协议，因为每发送一个数据帧就停止并等待，所以用1比特来编号就已足够。发送的帧交替地用0和1来标识，确认顿分别用ACK0和ACK1来表示，当收到的确认顿有误时，就重传已发送的数据帧。若连续出现相同序号的数据帧，则表明发送方进行了超时重传。若连续出现相同序号的确认顿，则表明接收方收到了重复帧。  

此外，为了超时重传和判定重复帧的需要，发送方和接收方都要设置一个顿缓冲区。当发送方发送完数据帧时，必须在其发送缓存中保留该数据帧的副本，这样才能在出现差错时进行重传。只有在收到对方发来的确认顿ACK后，方可清除该副本。  

停止-等待协议的信道利用率很低。为了提高传输效率，产生了连续ARQ协议（后退  $N$  帧协 议和选择重传协议），发送方可连续发送多个帧，而不是每发完一个帧就停止等待确认。  

# 2.多帧滑动窗口与后退 $N$ 顿协议（GBN）  

>#### pro：GBN协议的工作原理（2009）  

在后退 $N$ 帧协议中，发送方可在未收到确认顿的情况下，将序号在发送窗口内的多个数据帧全部发送出去。后退 $N$ 倾的含义是：发送方发送 $N$ 个数据帧后，若发现这 $N$ 个帧的前一个数据顾在计时器超时的时候仍未收到其确认信息，则该顺被判为出错或去失，此时发送方不得不重传该出错帧及随后的 $N$ 个顿。这意味着，接收方只允许按顺序接收帧。  

>#### pro：GBN确认号的含义/捎带确认的应用（2017）  

如图3.11所示，发送方向接收方发送数据帧。发送方发完0号帧后，可以继续发送后续的1号帧、2号帧等。发送方每发送完一个数据帧，就要为该帧设置超时计时器。因为连续发送了许多顿，所以确认帧必须指明是对哪个帧的确认。为了降低开销，GBN协议充许接收方进行累积确 认，即充许接收方不需要每收到一个正确的数据帧就立即发回一个确认帧，而可在连续收到多个正确的数据顿后，对最后一个数据帧发回确认信息，也就是说，对某个数据帧的确认就代表该数据帧和之前所有的顿均已正确无误地收到。ACKn表示对 $n$ 号帧的确认，表示接收方已正确收到 $n$ 号帧及之前的所有顺，下次期望收到 $n+1$ 号帧（也可能是0号顿）。接收方只按序接收数据顺。图中，虽然在有差错的2号帧之后接着收到了正确的6个数据帧，但接收方必须将这些帧丢弃。  
接收方虽然丢弃了这些未按序出现的无差错帧，但应重发已发送的最后一个确认顿ACK1（这是为了防止已发送的确认帧ACK1去失）。  

>#### pro：GBN超时重传的分析（2017）  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f3d8ffa553e14eac7cd68cf2198b841bed3882b8f8397d4235957d13e95a1280.jpg)  
图3.11GBN协议的工作原理：对出错数据帧的处理  

>#### pro：GBN发送窗口的意义/最大尺寸（2017）  

若采用  $n$  比特对顿编号，则其发送窗口  $W_{\mathrm{T}}$  应满足  $1\!<\!W_{\mathrm{T}}\!\leqslant\!2^{n}\!-\!1$  。若  $W_{\mathrm{T}}$  大于  $2^{n}\!-\!1$  ，则会造 成接收方无法分辨新数据帧和旧数据帧（参考本章末的疑难点1）。  

后退 $N$ 顿协议的接收窗口 $W_{\mathrm{R}}\!=\!1$ ，可保证按序接收数据帧。  

不难看出，后退 $N$ 帧协议一方面因连续发送数据帧而提高了信道利用率，另一方面在重传时又必须重传原来已正确到达的顺（仅因这些倾的前面有一顺出错），因此这种做法会降低传送效率。当信道误码率较大时，后退 $N$ 帧协议不一定优于停止-等待协议。  

# 3.多帧滑动窗口与选择重传协议（SR）  

为了进一步提高信道的利用率，可以设法只重传出现差错和计时器超时的数据帧，但此时必须加大接收窗口，以便先收下失序但正确到达且序号仍落在接收窗口内的那些数据顿，等到所缺序号的数据帧收齐后，再一并送交上层。这就是选择重传协议。  

>#### pro：选择重传协议的工作原理（2011）  

为了使发送方仅重传出错的帧，接收方不能再采用累积确认，而要对每个正确接收的数据帧逐一进行确认。显然，选择重传协议比后退 $N$ 帧协议更复杂，且接收方需要设置足够的帧缓冲区（帧缓冲区的数目等于接收窗口的大小而非序号数目，因为接收方不能接收序号在窗口下界以下或窗口上界以上的帧）来暂存那些失序但正确到达且序号落在接收窗口内的数据帧。每个发送缓冲区对应一个计时器，当计时器超时的时候，缓冲区的帧就重传。另外，选择重传协议还采用了比上述其他协议更有效的差错处理策略，即一旦接收方检测到某个数据帧出错，就向发送方发送一个否定顿NAK，要求发送方立即重传NAK指定的数据顿。在图3.12中，2号顿丢失后，接收方仍可正常接收并缓存之后收到的数据顺，待发送方超时重传2号顺并被接收方成功接收后，接 收窗口就可向前移动，而当发送方收到2号顿的确认后，发送窗口就可向前移动。在某个时刻，接收方检测到10号帧出错，向发送方发出否定帧NAK10，在此期间接收方仍可正常接收并缓存之后收到的顿，发送方收到否定帧NAK10后立即重传10号帧。  

选择重传协议的接收窗口 $W_{\mathrm{R}}$ 和发送窗口 $W_{\mathrm{T}}$ 都大于1，一次可以发送或接收多个帧。若采用 $n$ 比特对顿编号，需满足条件 $\textcircled{\scriptsize{1}}$ ： $W_{\mathrm{{R}}}+W_{\mathrm{{T}}}\!\leqslant\!2^{n}$ （否则，在接收方的接收窗口向前移动后，若有一个或多个确认帧丢失，则发送方就会超时重传之前的旧数据顿，接收窗口内的新序号与之前的旧序号出现重叠，接收方就无法分辨是新数据帧还是重传的旧数据帧）。此外，还应满足条件 $\circledcirc$  $W_{\mathrm{{R}}}\leqslant W_{\mathrm{{T}}}$ （否则，若接收窗口大于发送窗口，则接收窗口永远不可能填满，接收窗口多出的空间就毫无意义)。由 $\textcircled{\scriptsize{1}}$ 和 $\circledcirc$ 不难得出 $W_{\mathbb{R}}\!\leqslant\!2^{n-1}$ 。一般情况下， $W_{\mathbb{R}}$ 和 $W_{\mathrm{T}}$ 的大小是相同的。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/de59299ec42c47f7749328137b7d85d10deaadf593f80970a3170cc75da885a2.jpg)  
图3.12SR协议的工作原理：对超时和出错数据帧的处理  

# 4.信道利用率的分析  

信道利用率是指信道的效率。从时间角度看，信道效率是对发送方而言的，是指发送方在一个发送周期（从发送方开始发送分组到收到第一个确认分组所需的时间）内，有效发送数据的时间与整个发送周期之比。本节之所以使用分组的PDU名称而不使用帧，是为了更具通用性。  

（1）停止-等待协议的信道利用率  

>#### pro：停止-等待协议下信道利用率的计算（2018、2020）  

停止-等待协议的优点是简单，缺点是信道利用率太低。下面用图3.13来分析这个问题。假定在发送方和接收方之间有一个直通的信道来传送分组。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/32c2e5a6d87213d9c91d0cbc5b5ea99f663b7a7cf0a460c11b9a131bd28a37f8.jpg)  
图3.13停止-等待协议中数据帧和确认帧的发送时间关系  

发送方发送分组的发送时延为 $T_{\mathrm{{D}}}$ 。显然， $T_{\mathrm{{D}}}$ 等于分组长度除以数据传输速率。假定分组正确到达接收方后，接收方处理分组的时间可以忽略不计，同时立即发回确认。接收方发送确认分组的发送时延为 $T_{\mathrm{A}}$ （通常可以忽略不计）。再假设发送方处理确认分组的时间也可以忽略不计，那么发送方经过时间 ${T_{\mathrm{{D}}}}\ +{\mathrm{{RTT}}}+{T_{\mathrm{{A}}}}$ 后就可再发送下一个分组，其中RTT是往返时延。因为仅在 $T_{\mathrm{{D}}}$ 内才用来发送数据分组，因此停止-等待协议的信道利用率 $U$ 为  

$$
U\,{=}\,\frac{T_{\mathrm{D}}}{T_{\mathrm{D}}+\mathrm{RT}+T_{\mathrm{A}}}
$$  

假定某个信道的 $\mathrm{RTT}=20\mathrm{ms}$ 。分组长度是1200比特，数据传输速率是 $1\mathrm{{Mb/s}}$ 。若忽略处理时间和 $T_{\mathrm{A}}$ ，则可算出信道利用率 $U\!=\!5.66\%$ 。若把数据传输速率提高到 $10\mathrm{Mb/s}$ ，则 $U\!=\!0.0596\%$ 由此可知，当往返时延RTT大于分组发送时延 $\mathit{T}_{\mathrm{{D}}}$ 时，信道利用率就非常低。  
（2）连续ARQ协议的信道利用率  

命题追踪三种滑动窗口协议的信道利用率比较（2023）  

连续ARQ协议采用流水线传输（见图3.14），即发送方可连续发送多个分组。这样，只要发送窗口足够大，就可使信道上有数据持续流动。显然，这种方式能获得很高的信道利用率。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/8e812ae1175819652438ba38e40f983c2fad2ab762a531a9c6ad028e526082e0.jpg)  
图3.14连续ARQ协议的流水线传输可提高信道利用率  

命题追踪GBN协议下信道利用率与发送窗口大小的关系（2012、2015、2017）  

假设连续ARQ协议的发送窗口为 $n$ ，即发送方可连续发送 $n$ 个分组，分为两种情况1D $n T_{\mathrm{D}}\,{<}\,T_{\mathrm{D}}\,{+}\,{\mathrm{RTT}}\,{+}\,T_{\mathrm{A}}$ ：即在一个发送周期内可以发送完 $n$ 个分组，信道利用率为  

$$
U={\frac{n T_{\mathrm{{D}}}}{T_{\mathrm{{D}}}+\mathrm{{RTT}}+T_{\mathrm{{A}}}}}
$$  

2) $n T_{\mathrm{D}}\,{\geqslant}\,T_{\mathrm{D}}\,{+}\,\mathrm{RTT}+T_{\mathrm{A}}$ ：即在一个发送周期内发不完（或刚好发完） $n$ 个分组，对于这种情况，只要不发生差错，发送方就可不间断地发送分组，信道利用率为1。  

命题追踪滑动窗口协议的数据传输速率的计算（2009、2010、2014）  

此外，“信道平均（实际）数据传输速率 $=$ 信道利用率 $.\times$ 信道带宽（最大数据传输速率）”，或者“信道平均（实际）数据传输速率 $=$ 发送周期内发送的数据量/发送周期”。  

本节习题中有不少关于信道利用率和数据传输速率的计算，读者可以结合习题学习。  


# 3.5介质访问控制  

介质访问控制所要完成的主要任务是，为使用介质的每个结点隔离来自同一信道上其他结点所传送的信号，以协调活动结点的传输。图3.15是广播信道的通信方式，结点A、B、C、D、E共享广播信道，假设A要与C通信，B要与D通信，因为它们共用一条信道，若不加控制，则两对结点之间的通信可能会因互相干扰而失败。用来决定广播信道中信道分配的协议属于数据链路层的一个子层，称为介质访问控制（Medium Access Control，MAC）子层。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/9ca053d64d3e0454a486ca2d0596abec10117566cb04d939d349516482e06b37.jpg)  
图3.15广播信道的通信方式  

常见的介质访问控制方法有信道划分介质访问控制、随机访问介质访问控制和轮询访问介质访问控制。其中前者是静态划分信道的方法，而后两者是动态分配信道的方法。  

# 3.5.1信道划分介质访问控制  

信道划分介质访问控制将使用同一传输介质的多个设备的通信隔离开来，把时域和频域资源合理地分配给这些设备。信道划分介质访问控制通过复用技术实现。所谓复用，是指在发送端把多个发送方的信号组合在一条物理信道上进行传输，在接收端把收到的复用信号分离出来，并发送给对应的接收方，如图3.16所示。当传输介质的带宽超过传输单个信号所需的带宽时，通过在一条介质上传输多个信号，还能提高传输系统的利用率。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/db2b663112711b7fbd103f843c6340fe46b6a5abd6a2b395f3b85c66372e3d9a.jpg)  
图3.16复用原理示意图  
信道划分的实质是通过分时、分频、分码等方法，将原来的一个广播信道，逻辑上分为几个用于在两个结点之间进行通信的互不干扰的子信道，即将广播信道转变为若干个点对点信道。  

信道划分介质访问控制分为以下4种。  

# 1.频分复用（FDM）  

频分复用（Frequency Division Multiplexing，FDM），每个子频带作为一个子信道，每对用户使用一个子信道进行通信，如图3.17所示。所有用户在同一时间占用不同的频带资源。每个子信道分配的频带可不相同，但它们的总和不能超过信道的总频带。在实际应用中，为了防止子信道之间互相干扰，相邻信道间还要加入“隔离频带”。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/97ee383c310e7a88c1fad36132c6e33425721806fd85d6e745c3a2f5bee9b126.jpg)  
图3.17频分复用的原理示意图  

分复用的优点在于充分利用了传输介质的带宽，系统效率较高，实现也较容易。  

# 2.时分复用（TDM）  

时分复用（Time Division Multiplexing，TDM）时间片，称为TDM顿，每个用户在每个TDM帧中占用固定序号的时隙，每个用户所占用的时隙周期性地出现（其周期就是TDM的长度），所有用户在不同的时间占用同样的信道资源，如图3.18所示。TDM帧实际上是一段固定长度的时间，它与数据链路层的顿不是同一个概念。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/eeb2deb249d0dcde4ed543762681f37459cd83d3337b43692dc71503e9e57355.jpg)  
图3.18时分复用的原理示意图  

从某个时刻来看，时分复用信道上传送的仅是某对用户之间的信号：从某段时间来看，传送的是按时间分割的复用信号。因为时分复用是按固定次序给用户分配时隙的，当用户在某段时间暂无数据传输时，其他用户也无法使用这个暂时空闲的线路资源，所以时分复用后的信道利用率不高。统计时分复用（StatisticTDM，STDM）又称异步时分复用，它是对TDM的一种改进。STDM倾与TDM帧不同，它并不固定分配时隙，而按需动态分配时隙，当用户有数据要传送时，才会分配到STDM帧中的时隙，因此可以提高线路的利用率。例如，假设线路的数据传输速率为 $6000\mathrm{b/s}$ ，3个用户的平均速率都为 $2000{\mathrm{b/s}}$ ，当采用TDM方式时，每个用户的最高速率为 $2000\mathrm{b/s}$ 而在STDM方式下，每个用户的最高速率可达 $6000\mathrm{b/s}$  

# 3.波分复用（WDM)  

波分复用（Wavelength Division Multiplexing，WDM）即光的频分复用，它在一根光纤中传输多种不同波长（频率）的光信号，因为波长不同，各路光信号互不干扰，最后用光分用器将各路波长分解出来。因为光波处于频谱的高频段，有很大的带宽，所以可以实现多路的波分复用。  
# 4.码分复用（CDM)  

码分复用（Code Division Multiplexing，CDM）复用方式。与FDM和TDM不同，它既共享信道的频率，又共享时间。  

实际上，（Code Division Multiple Access，CDMA），其原理是将每个比特时间再划分成 $m$ 个短的时间槽，称为码片（Chip），通常 $m$ 的值是64或128，下例中为简单起见，设 $m$ 为8。每个站点被指派一个唯一的 $m$ 位码片序列。发送1时，站点发送它的码片序列；发送0时，站点发送该码片序列的反码。当两个或多个站点同时发送时，各路数据在信道中线性相加。为了从信道中分离出各路信号，要求各个站点的码片序列相互正交。  

简单理解就是，A站向C站发出的信号用一个向量来表示，B站向C站发出的信号用另一个向量来表示，两个向量要求相互正交。向量中的分量，就是所谓的码片。  

下面举例说明CDMA的原理。  

令向量 $s$ 表示A站的码片向量， $\pmb{T}$ 表示B站的码片向量。假设A站的码片序列被指派为00011011，则A站发送00011011就表示发送比特1，发送11100100就表示发送比特0。为了方便计算，将码片中的0写为-1，将1写为 $+1$ ，因此A站的码片序列是 $(-1\,{-}1\,{-}1\,{+}1\,{+}1\,{-}1\,{+}1\,{+}1\,)$  

不同站的码片序列相互正交，即向量 $s$ 和 $\pmb{T}$ 的规格化内积为0：  

$$
S\mathbf{\cdot}T\equiv\frac{1}{m}\sum_{i=1}^{m}S_{i}T_{i}=0
$$  

任何站的码片向量和该码片向量自身的规格化内积都是1：  

$$
S\bullet S={\frac{1}{m}}\sum_{i=1}^{m}S_{i}S_{i}={\frac{1}{m}}\sum_{i=1}^{m}S_{i}^{2}={\frac{1}{m}}\sum_{i=1}^{m}(\pm1)^{2}=1
$$  

任何站的码片向量和该码片反码的向量的规格化内积都是-1：  

$$
S\bullet\overline{{S}}=\frac{1}{m}\sum_{i=1}^{m}S_{i}\,\overline{{S_{i}}}=-\frac{1}{m}\sum_{i=1}^{m}S_{i}^{2}=-1
$$  

令向量  $\pmb{T}$  为  $\left(-1-\!\!1+\!\!1-\!\!1+\!\!1+\!\!1+\!\!1-\!\!1\,\right)$  8  

当A站向C站发送数据1时，就发送了向量 $\left(-1-\!1-\!1+\!1+\!1-\!1+\!1+\!1\,\right)$  

当B站向C站发送数据0时，就发送了向量 $(+1+1-1+1-1-1-1+1)$  

两个向量在公共信道上叠加，实际上是线性相加，得到  

$$
S+\overline{{{T}}}=\left(\begin{array}{c c c c c c c}{{0}}&{{0}}&{{-2}}&{{2}}&{{0}}&{{-2}}&{{0}}&{{2}}\end{array}\right)
$$  

>#### pro：码分复用中数据分离的计算（2014）  

到达C站后，进行数据分离，若要得到来自A站的数据，则C站就必须知道A站的码片序列，让 $s$ 与 $s+\bar{T}$ 进行规格化内积。根据叠加原理，其他站点的信号都在内积的结果中被过滤掉，内积的相关项都是0，而只剩下A站发送的信号，得到  

$$
S\bullet(S+\overline{{{T}}})=1
$$  

所以A站发出的数据是1。同理，若要得到来自B站的数据，则  

$$
T\bullet(S+{\overline{{T}}})=-1
$$  

因此从B站发送过来的信号向量是一个反码向量，代表0。  

规格化内积是线性代数中的内容，它在得到两个向量的内积后，再除以向量的分量的个数。下面举一个直观的例子来理解频分复用、时分复用和码分复用。  
假设A站要向C站运输黄豆，B站要向C站运输绿豆，A站和B站与C站之间有一条公共 的道路，可类比为广播信道。在频分复用方式下，公共道路被划分为两个车道，分别提供给A站到C站的车和B站到C站的车通行，两类车可同时通行，但都只分到了公共车道的一半，因此频分复用（波分复用也一样）共享时间而不共享空间。在时分复用方式下，先让A站到C站的车走一趟，再让B站到C站的车走一趟，两类车交替地使用公共车道，因此时分复用共享空间，但不共享时间。码分复用与另外两种信道划分方式极为不同，在这种方式下，黄豆与绿豆放在同一辆车上运送，到达C站后，由C站负责把车上的黄豆和绿豆分开，因此码分复用既共享空间，又共享时间。  

码分复用技术具有频谱利用率高、抗干扰能力强、保密性强、语音质量好等优点，还可以减少投资及降低运行成本，主要用于无线通信系统，特别是移动通信系统。  

# 3.5.2随机访问介质访问控制  

>#### pro：信道划分与随机访问介质访问控制的特点（2014）  

在随机访问协议中，不采用集中控制方式解决发送信息的次序问题，所有用户都能根据自己的意愿随机地发送信息，占用信道的全部速率。在总线形网络中，当有两个或多个用户同时发送信息时，就会产生帧冲突（也称碰撞），导致所有冲突用户的发送均以失败告终。为了解决随机访问发生的冲突，每个用户需要按照一定的规则反复地重传它的帧，直到该帧无冲突地通过，这些规则就是随机访问介质访问控制协议，其核心思想是：胜利者通过争用获得信道，进而获得信息的发送权。因此，随机访问介质访问控制协议又称争用型协议。  

可见，若采用信道划分机制，则结点之间的通信要么共享空间，要么共享时间，要么共享空间和时间：而若采用随机访向控制机制，则结点之间的通信既不共享时间，又不共享空间。因此，随机介质访向控制实质上是一种将厂播信道转换为点到点信道的机制。  

# 1.ALOHA协议  

ALOHA ALOHA ALOHA。  

（1）纯ALOHA协议  

纯ALOHA协议的基本思想是，当总线形网络中的任何站点需要发送数据时，可以不进行任何检测就发送数据。若在一段时间内未收到确认，则该站点就认为传输过程中发生了冲突。发送站点需要等待一段时间后再发送数据，直至发送成功。  

图3.19表示一个纯ALOHA协议的工作原理。每个站均可自由地发送数据帧，假定所有帧都是定长的，帧长不用比特而用发送这个帧所需的时间来表示，图中用 $T_{0}$ 表示这段时间。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/ae9a115a7e4fbb1e8ae3ec162449673ea9bdc2251aced1d68bb09e49b721c595.jpg)  
图3.19纯ALOHA协议的工作原理  
在图3.19的例子中，当站1发送帧1时，其他站都未发送数据，所以站1的发送必定是成功的。但随后站2和站 $N\!-\!1$ 发送的顺2和顺3在时间上重叠了一部分（即发生了冲突）。发生冲突的各站都必须进行重传，但并不能马上进行重传，因为这样做必然导致继续发生冲突。因此，让各站等待一段随机的时间，然后进行重传。若再次发生冲突，则需要再等待一段随机的时间，直到重传成功为止。图中其余一些顿的发送情况是，帧4发送成功，而帧5和帧6发生冲突。  

纯ALOHA网络的吞吐量很低，为了克服这个缺点，便产生了时隙ALOHA协议。  

（2）时隙ALOHA协议  

时隙ALOHA协议同步各站点的时间，将时间划分为一段段等长的时隙（Slot），规定站点只能在每个时隙开始时才能发送帧，发送一帧的时间必须小于或等于时隙的长度。这样做避免了用户发送数据的随意性，降低了产生冲突的可能性，提高了信道的利用率。  

图3.20表示两个站的时隙ALOHA协议的工作原理。每个帧到达后，一般都要在缓存中等待一段小于时隙 $T_{0}$ 的时间，才能发送出去。当在一个时隙内有两个或两个以上的帧到达时，在下一个时隙将产生冲突。冲突后重传的策略与纯ALOHA协议的情况相似。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/eab8d419e4bb0d1523f4496ef9b820a30d21ab1ae79b7a85d33598e667eac4dc.jpg)  
图3.20时隙ALOHA协议的工作原理  

# 2.CSMA协议  

ALOHA网络发生冲突的概率很大。若每个站点在发送前都先监听公用信道，发现信道空闲后再发送，则会大大降低冲突的可能性，从而提高信道的利用率，载波监听多路访问（CarrierSenseMultiple AccesS，CSMA）。CSMA ALOHA一种改进协议，它与ALOHA协议的主要区别是多了一个载波监听装置。  

根据监听方式和监听到信道忙后的处理方式的不同，CSMA协议分为三种。  

# （1）1-坚持CSMA  

1-坚持CSMA的基本思想是：当站点要发送数据时，首先监听信道：若信道空闲，则立即发送数据；若信道忙，则继续监听直至信道空闲。“坚持”的含义是监听到信道忙时，继续坚持监听信道；“1”的含义是监听到信道空闲时，立即发送帧的概率为1。  

# （2）非坚持CSMA  

非坚持CSMA的基本思想是：当站点要发送数据时，首先监听信道；若信道空闲，则立即发送数据；若信道忙，则放弃监听，等待一个随机的时间后，再重新监听。  

非坚持CSMA协议在监听到信道忙时就放弃监听，因此降低了多个站点等待信道空闲后同时发送数据导致冲突的概率，但也增加了数据在网络中的平均时延。  

# (3)  $p$  -坚持CSMA  

$p$ -坚持CSMA只适用于时分信道，其基本思想是：当站点要发送数据时，首先监听信道；若信道忙，则持续监听（即等到下一个时隙再监听），直至信道空闲；若信道空闲，则以概率 $p$ 发送数据，以概率 $1\!-\!p$ 推迟到下一个时隙再继续监听；直到数据发送成功。  

$p$ -坚持CSMA检测到信道空闲后，以概率 $p$ 发送数据，以概率 $1\!-\!p$ 推迟到下一个时隙继续监听，目的是降低1-坚持CSMA中多个站点检测到信道空闲时同时发送帧的冲突概率；采用坚 持“监听”的目的是，克服非坚持CSMA中因随机等待造成的延迟时间较长的缺点。因此， $p-$ 坚持CSMA协议是非坚持CSMA协议和1-坚持CSMA协议的折中。  
三种不同类型的CSMA协议比较如表3.1所示。  

表3.1三种不同类型的CSMA协议比较
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/ab84e37ae6367358ae2338fa8eca6764402a28f7d79e8aa56a3fff0a09f8d685.jpg)  

# 3.CSMA/CD协议  

>#### pro：CSMA/CD协议的特点（2015）  

载波监听多路访问/冲突检测（CSMA/CD）协议是CSMA协议的改进方案，适用于总线形网络或半双工网络环境。对于全双工网络，因为全双工采用两条信道，分别用来发送和接收，在任何时候，发收双方都可以发送或接收数据，不可能产生冲突，所以不需要CSMA/CD协议。  

载波监听是指每个站点在发送前和发送过程中都必须不停地检测信道，在发送前检测信道是为了获得发送权，在发送过程中检测信道是为了及时发现发送的数据是否发生冲突。站点要在发送数据前先监听信道，只有信道空闲时才能发送。冲突检测（CollisionDetection）就是边发送边监听的，若监听到了冲突，则立即停止数据发送，等待一段随机时间后，重新开始尝试发送数据。  

CSMA/CD的工作流程可简单地概括为“先听后发，边听边发，冲突停发，随机重发”。  

>#### pro：信道发生冲突的最短、最长时间的分析（2010）  

电磁波在总线上的传播速率总是有限的。因此，当某时刻发送站检测到信道空闲时，信道不一定空闲。如图3.21所示，设 $\tau$ 为单程传播时延。当 $t=0$ 时，A站发送数据。当 $t=\tau-\delta$ 时，A站发送的数据还未到达B站，因为B站检测到信道空闲而发送数据。经过时间 $\delta/2$ 后，即当 $t=\tau-\delta/2$ 时，A站发送的数据和B站发送的数据发生冲突，但这时A站和B站都不知道。当 $t=\tau$ 时，B站检测到冲突，于是停止发送数据。当 $t=2\tau-\delta$ 时，A站检测到冲突，也停止发送数据。显然，CSMA/CD中的站不可能同时进行发送和接收，因此采用CSMA/CD协议的以太网只能进行半双工通信。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/ae240d111343b3cca19a39fb51a2804acf5f10feb02fe6219bbbe3043615b345.jpg)  
图3.21传播时延对载波监听的影响  
从图3.21不难看出，A站在开始发送数据后最多经过时间 $2\,\tau$ （端到端传播时延的2倍）就能知道有没有发生冲突（当 $\delta\!\to\!0$ 时）。因此，把以太网的端到端往返时间 $2\tau$ 称为争用期（又称冲突窗口）。每个站在自己发送数据后的一小段时间内，存在发生冲突的可能性，只有经过争用期这段时间还未检测到冲突时，才能确定这次发送不会发生冲突。  

>#### pro：CSMA/CD最短帧长的理解和相关计算（2009、2016、2019、2022）  

现在考虑一种情况：某站发送一个很短的顿，但在发送完之前并未检测出冲突。假定这个帧在继续向前传播到达目的站之前和别的站发送的帧发生了冲突，因此目的站将收到有差错的帧（当然会把它丢弃）。然而，发送站却不知道发生了冲突，因此不会重传这个顿。为了避免发生这种情况，以太网规定了一个最短顿长（争用期内可发送的数据长度）。在争用期内若检测到冲突，则站就停止发送，此时已发送出去的数据一定小于最短帧长，因此凡长度小于这个最短帧长的帧，就都是因为冲突而异常中止的无效顿。最短帧长的计算公式为  

# 最短帧长 $=$ 总线传播时延 $\times$ 数据传输速率 $^{\times2}$  

例如，以太网规定 $51.2\upmu\mathrm{s}$ 为争用期的长度。对于10Mb/s的以太网，在争用期内可发送512bit，即64B。当以太网发送数据时，若前64B未发生冲突，则后续数据也不会发生冲突（表示已成功抢占信道）。换句话说，若发生冲突，则一定在前64B。因为一旦检测到冲突就立即停止发送，所以这时发送出去的数据一定小于64B。于是，以太网规定最短帧长为64B，凡长度小于64B的帧，就都是因为冲突而异常中止的无效顿，收到这种无效帧时应立即丢弃。  

若只发送小于64B的帧，如40B的帧，则需要在MAC子层中于数据字段的后面加一个整数字节的填充字段，以保证以太网的MAC帧的长度不小于64B。  

>#### pro：二进制指数退避算法的应用（2023）  

一旦发生冲突，参与冲突的两个站点紧接着再次发送就没有意义，若坚持这样做，则将导致无休止的冲突。CSMA/CD采用截断二进制指数退避算法来确定冲突后重传的时机，它让发生冲突的站点在停止发送后，推迟一个随机的时间再重新发送。算法精髓如下：  

1）确定基本退避时间，一般取2倍的总线端到端的传播时延 $2\,\tau$ （即争用期）。  

2）从离散的整数集合 $[0,1,\cdots,(2^{k}\!-\!1)]$ 中随机取出一个数，记为 $r$ ，重传所需推迟的时间就是 $r$ 倍的争用期，即 $2r\tau_{\circ}$ 参数 $k\!=$ min[重传次数，10]，可见当重传次数不超过10时，参数 $k$ 等于重传次数：但当重传次数超过10时， $k$ 就不再增大，而一直等于10。3）当重传达16次仍不成功时，说明网络太拥挤，认为该帧永远无法正确发出，抛弃该帧并向高层报告出错（这个条件也容易忽略，请读者注意）。  

假设适配器首次试图传送一帧，且在传送过程中检测到冲突。第1次重传时， $k\!=\!1$ ，随机数 $r$ 从整数集合{0，1中选择，可选的重传推迟时间是0或 $2\,\tau_{c}$ 。若再次发生冲突，则第二次重传时，随机数 $r$ 从整数集合 $\{0,1,2,3\}$ 中选择，因此重传推迟时间是在 $0,2\tau,4\tau,6\tau$ 这四个时间中随机选取的一个，以此类推。使用截断二进制指数退避算法可使重传需要推迟的平均时间随重传次数的增大而增大（也称动态退避），因此能降低发生冲突的概率，有利于整个系统的稳定。  

CSMA/CD算法的归纳如下：  

$\textcircled{\scriptsize{1}}$ 准备发送：适配器从网络层获得一个分组，封装成帧，放入适配器的缓存。 $\circledcirc$ 检测信道：若信道空闲，则开始发送该帧：若信道忙，则持续检测直至信道空闲。 $\textcircled{3}$ 在发送过程中，适配器仍然持续检测信道。这里只有如下两种可能。）发送成功：在争用期内一直未检测到冲突，该顿肯定能发送成功。  
·发送失败：在争用期内检测到冲突，此时立即停止发送，适配器执行指数退避算法等待一段随机时间后返回到步骤 $\textcircled{2}$ 。若重传16次仍不能成功，则停止重传并向上报错。  

# 4.CSMA/CA协议  

CSMA/CD协议已成功用于使用有线连接的局域网，但在无线局域网环境下不能简单地搬用CSMA/CD协议，特别是冲突检测部分，主要有两个原因：  

1）接收信号的强度往往远小于发送信号的强度，且在无线介质上信号强度的动态变化范围 很大，因此若要实现冲突检测，则硬件上的花费会过大。  

2）在无线通信中，并非所有站点都能够听见对方，即存在“隐蔽站”问题，  

为此，802.11标准定义了广泛用于无线局域网的CSMA/CA协议，它对CSMA/CD协议进行修改，将冲突检测改为冲突避免（CollisionAvoidance，CA）。“冲突避免”并不是指协议可以完全避免冲突，而是指协议的设计要尽量降低冲突发生的概率。因为802.11无线局域网不使用冲突检测，一旦站点开始发送一个帧，就会完全发送该帧，但冲突存在时仍发送整个帧（尤其是长数据帧）会严重降低网络的效率，所以要采用冲突避免技术来降低冲突的概率。  

>#### pro：需要使用确认方案的MAC协议（2011）  

因为无线信道的通信质量远不如有线信道，所以802.11标准使用链路层确认/重传（ARQ）方案，即站点每通过无线局域网发送完一顺，就要在收到对方的确认顺后才能继续发送下一顺。可见，802.11标准无线局域网采用的停止-等待协议是一种可靠传输协议。  

为了尽量避免冲突，802.11标准规定，所有站完成发送后，必须等待一段很短的时间（继续监听）才能发送下一帧。这段时间称为帧间间隔（InterFrameSpace，IFS）。帧间间隔的长短取决于该站要发送的帧的类型。802.11标准使用了下列三种IFS。  

>#### pro： CSMA/CA协议的IFS的特点（2020)  

1）SIFS（短IFS）：最短的IFS，用来分隔属于一次对话的各帧，使用SIFS的帧类型有ACK倾、CTS帧、分片后的数据帧，以及所有回答AP探询的顿等。  

2）PIFS（点协调IFS）：中等长度的IFS，在PCF操作中使用。3）DIFS（分布式协调IFS）：最长的IFS，用于异步帧竞争访问的时延。  

802.11标准还采用了虚拟载波监听机制，即让源站将它要占用信道的持续时间（包括目的站发回ACK顺所需的时间）及时通知给所有其他站，以便使所有其他站在这段时间内都停正发送，这样就大大减少了冲突的机会。“虚拟载波监听”表示其他站并未监听信道，而是因收到了源站的通知才不发送数据，这种效果就像是其他站都监听了信道。  

当信道从忙态变为空闲时，任何一个站要发送数据顿，不仅要等待一个DIFS的间隔，而且要进入争用窗口，计算随机退避时间以便再次试图访问信道，因此降低了冲突发生的概率。当且仅当检测到信道空闲且这个数据顺是要发送的第一个数据帧时，才不使用退避算法，其他所有情况都必须使用退避算法，具体为： $\textcircled{\scriptsize{1}}$ 在发送第一个顺之前检测到信道忙； $\circledcirc$ 每次重传： $\textcircled{3}$ 每次成功发送后要发送下一帧。CSMA/CA的退避算法与CSMA/CD的稍有不同（详见相关的教材）。  

CSMA/CA算法的归纳如下：  

1）若站点最初有数据要发送（而非发送不成功再进行重传），且检测到信道空闲，那么在等待时间DIFS后，就发送整个数据帧。  

2）否则，站点执行CSMA/CA退避算法，选取一个随机退避值。一旦检测到信道忙，退避计时器就保持不变。只要信道空闲，退避计时器就进行倒计时。  
3）当退避计时器减至0时（这时信道只可能是空闲的），站点就发送整个帧并等待确认。4）发送站若收到确认，就知道已发送的帧被目的站正确接收。这时要发送第二帧，就要从步骤2）开始，执行CSMA/CA退避算法，随机选定一段退避时间。若发送站在规定时间（由重传计时器控制）内未收到确认帧ACK，就必须重传该帧，再次使用CSMA/CA协议争用该信道，直到收到确认，或经过若干次重传失败后放弃发送。  

# 处理隐蔽站问题：RTS和CTS  

在图3.22中，站A和站B都在AP的覆盖范围内，但站A和站B相距较远，彼此都听不见对方。当站A和站B检测到信道空闲时，都向AP发送数据，导致冲突发生，这就是隐蔽站问题，  

>#### pro：CSMA/CA协议进行信道预约的方法（2018）  

为了避免该问题，802.11标准允许发送站对信道进行预约，如图3.23所示。源站要发送数据帧之前，先监听信道，若信道空闲，则等待时间DIFS后，广播一个请求发送RTS（RequestToSend)控制帧，它包括源地址、目的地址和这次通信所需的持续时间。若AP正确收到RTS顿，且信道空闲，则等待时间SIFS后，向源站发送一个充许发送CTS（ClearToSend）控制帧，它也包括这次通信所需的持续时间，源站收到CTS帧后，再等待时间SIFS，就可发送数据帧。若AP正确收到了源站发来的数据，则等待时间SIFS后就向源站发送确认帧ACK。AP覆盖范围内的其他站听到CTS顿后，将在CTS帧中指明的时间内抑制发送。CTS帧有两个目的： $\textcircled{\scriptsize{1}}$ 给源站明确的发送许可； $\circledcirc$ 指示其他站在预约期内不要发送。  

需要说明的是，源站在RTS帧中填写的所需占用信道的持续时间，是从RTS帧发送完毕后，到目的站最后发送完ACK帧为止的时间，即“ $\mathrm{SIFS+CTS+S I F S+}$ 数据帧 $+\;{\mathrm{SIFS}}+$ ACK"而AP在CTS顿中填写的所需占用信道的持续时间，是从CTS顿发送完毕，到目的站最后发送完ACK帧为止的时间，即“ $\mathrm{SIFS+}$ 数据帧 $\mathrm{+\;SIFS+ACK}$ ”。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c3ab7d2f814295e28c23f9b8d7d6e27883b83fde9116c67df227adcbfb64b071.jpg)  
图3.22A站和B站同时向AP发送信号，发生冲突  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/2674c2b5b366aab47d9a818ebdb238e29926b42fa0b01c12631f7f41d08ac0bc.jpg)  
图3.23使用RTS和CTS帧的冲突避免  

使用RTS帧和CTS帧会使网络的通信效率有所下降，但这两种顿都很短，与数据顿相比开销不算大。相反，若不使用这种控制顿，则一旦发生冲突而导致数据帧重发，浪费的时间会更多。信道预约不是强制性规定，各站可自行决定使用或不使用。只有当数据帧长超过某个数值时，使用RTS帧和CTS帧才比较划算。  

CSMA/CD与CSMA/CA主要有如下区别：  

1）CSMA/CD可以检测冲突，但无法避免；CSMA/CA发送数据的同时不能检测信道上有无  
冲突，本结点处没有冲突并不意味着在接收结点处就没有冲突，只能尽量避免。2）传输介质不同。CSMA/CD用于总线形以太网，CSMA/CA用于无线局域网802.11a/b/g/n等。3）检测方式不同。CSMA/CD通过电缆中的电压变化来检测；而CSMA/CA采用能量检测、载波检测和能量载波混合检测三种检测信道空闲的方式。  

总结：CSMA/CA在发送数据帧之前先广播告知其他站点，让其他站点在某段时间内不要发送数据顿，以免发生冲突。CSMA/CD在发送数据顺之前监听，边发送边监听，一旦发生冲突，就立即停止发送。  

# 3.5.3轮询访问：令牌传递协议  

在轮询访问中，用户不能随机地发送信息，而要通过一个集中控制的监控站，以循环方式轮询每个结点，再决定信道的分配。典型的轮询访问控制协议是令牌传递协议。  

在令牌传递协议中，一个令牌（Token）沿着环形总线在各站之间依次传递。令牌是一个特殊的控制帧，它本身并不包含信息，仅控制信道的使用，确保同一时刻只有一个站独占信道。当环上的一个站希望发送帧时，必须等待令牌。站点只有取得令牌后才能发送帧，因此令牌环网络不会发生冲突（因为令牌只有一个）。站点发送完一帧后，应释放令牌，以便让其他站使用。因为令牌在网环上是按顺序依次传递的，所以对所有入网计算机而言，访问权是公平的。  

令牌环网络中令牌和数据的传递过程如下：  

1）当网络空闲时，环路中只有令牌帧在循环传递。2）当令牌传递到有数据要发送的站点时，该站点就修改令牌中的一个标志位，并在令牌中附加自己需要传输的数据，将令牌变成一个数据帧，然后将这个数据帧发送出去。3）数据帧沿着环路传输，接收到的站点一边转发数据，一边查看帧的目的地址。若目的地址和自己的地址相同，则接收站就复制该数据帧，以便进一步处理。4）数据帧沿着环路传输，直到到达该帧的源站点，源站点收到自己发出去的帧后便不再转发。同时，通过检验返回的帧来查看数据传输过程中是否出错，若出错则重传。5）源站点传送完数据后，重新产生一个令牌，并传递给下一站点，交出信道控制权。  

令牌传递协议非常适合负载很高的广播信道，即多个结点在同一时刻发送数据概率很大的信道。若这样的信道采用随机介质访问控制，则发生冲突的概率很大，而采用令牌传递协议则可以很好地满足各站点间的通信需求。令牌传递协议既不共享时间，又不共享空间；它实际上在随机访问介质访问控制的基础上，限定了有权发送数据的结点只能有一个。  

即使是广播信道也可通过介质访问控制机制，使广播信道变为逻辑上的点对点信道，所以说数据链路层研究的是“点到点”之间的通信。  


# 3.6局域网  

# 3.6.1局域网的基本概念和体系结构  

局域网（LocalAreaNetwork，LAN）是指在一个较小的地理范围（如一所学校）内，将各种计算机、外部设备和数据库系统等通过双绞线、同轴电缆等连接介质互相连接起来，组成资源和信息共享的计算机互连网络。主要特点如下：  
1）为一个单位所拥有，且地理范围和站点数目均有限。2）所有站点共享较高的总带宽（即较高的数据传输速率）。3）较低的时延和较低的误码率。4）各站为平等关系而非主从关系。5）能进行广播和多播。  

局域网的特性主要由三个要素决定：拓扑结构、传输介质、介质访问控制方式，其中最重要的是介质访问控制方式，它决定着局域网的技术特性。  

常见的局域网拓扑结构主要有以下4大类： $\textcircled{\scriptsize{1}}$ 星形结构； $\circledcirc$ 环形结构； $\textcircled{3}$ 总线形结构； $\textcircled{4}$ 星形和总线形结合的复合型结构。  

局域网可以使用铜缆、双绞线和光纤等多种传输介质，其中双绞线为主流传输介质。  

局域网的介质访问控制方法主要有CSMA/CD协议、令牌总线协议和令牌环协议，其中前两种协议主要用于总线形局域网，令牌环协议主要用于环形局域网。  

三种特殊的局域网拓扑实现如下：  

以太网（目前使用范围最广）。逻辑拓扑是总线形结构，物理拓扑是星形结构。令牌环（TokenRing，IEEE802.5）。逻辑拓扑是环形结构，物理拓扑是星形结构。FDDI（光纤分布数字接口，IEEE802.8）。逻辑拓扑是环形结构，物理拓扑是双环结构。  

IEEE802标准定义的局域网参考模型只对应于OSI参考模型的数据链路层和物理层，并将数据链路层拆分为两个子层：逻辑链路控制（LLC）子层和介质访问控制（MAC）子层。与接入传输介质有关的内容都放在MAC子层，它向上层屏蔽对物理层访问的各种差异，主要功能包括：组帧和拆卸帧、比特传输差错检测、透明传输。LLC子层与传输介质无关，它向网络层提供无确认无连接、面向连接、带确认无连接、高速传送四种不同的连接服务类型。  

因为在局域网市场中的垄断地位，以太网几乎成为局域网的代名词，而802委员会制定的LLC子层作用已经不大，所以现在许多网卡仅装MAC协议而不装LLC协议。IEEE802协议层与0SI参考模型的比较如图3.24所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/16c71a620ddded21f3ab9edcb32be26696a427239d32f2fc4cc82b8d8ddad874.jpg)  
图3.24IEEE802协议层与OSI参考模型的比较  

# 3.6.2 以太网与1EEE802.3  

以太网规约的第一个版本是DIXV1，它由DEC、Intel和Xerox联合提出。之后，它被修改为第二版规约DIXEthermnetV2，是世界上第一个局域网产品的规约。在此基础上，IEEE802委员会的IEEE802.3工作组制定了第一个IEEE的以太网标准IEEE802.3。  

以太网是目前最流行的有线局域网技术。以太网逻辑上采用总线形拓扑结构，所有计算机共享同一条总线，信息以广播方式发送，以太网使用CSMA/CD方式对总线进行访问控制。  
严格来说，DIX Ether mnet V 2，DIX Ethernet V 2 IEEE802.3标准的差别很小，因此通常将802.3局域网简称为以太网。  

>#### pro：以太网MAC协议提供的服务类型（2012）  

以太网采用两项措施来简化通信： $\textcircled{\scriptsize{1}}$ 采用无连接的工作方式，既不对发送的数据帧编号，又不要求接收方发送确认，即以太网尽最大努力交付数据，提供的是不可靠服务，对差错的纠正则由高层完成： $\circledcirc$ 发送的数据都使用曼彻斯特编码的信号，每个码元的中间出现一次电压转换，接收方利用这种电压转换方便地将位同步信号提取出来。  

# 1.以太网的传输介质与网卡  

以太网常用的传输介质有4种：粗缆、细缆、双绞线和光纤，它们的适用情况见表3.2。  

表3.2各种传输介质的适用情况
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3dea384933fe4b050f28d3dbd4a48eedd11df3f4fd270e10c83edbb8a2448575.jpg)  

# 注意  

在上述标准中，10指标准的速率为 $10\mathrm{Mb/s}$ ；Base指基带以太网；早期标准Base之后的5或2指单段最大传输距离不超过 $500\mathrm{m}$ 或 $185\mathrm{m}$ ，Base之后的T指双绞线，F指光纤。  

计算机与外界局域网的连接是通过主板上嵌入的一块网络适配器（Adapter）［又称网络接口卡（NetworkInterfaceCard，NIC）」实现的。适配器上装有处理器和存储器，工作在数据链路层。适配器和局域网的通信是通过电缆或双绞线以事行方式进行的，而适配器和计算机的通信则是通过 计算机的TO总线以并行方式进行的。因此，适配器的重要功能就是进行数据的事并转换。  

适配器不仅能实现与局域网传输介质之间的物理连接和电信号匹配，还涉及顺的发送与接收、顺的封装与拆封、介质访问控制、数据的编码与解码及数据缓存等功能。当适配器收到正确的帧时，就使用中断来通知该计算机，并交付协议栈中的网络层。当计算机要发送1IP数据报时，就由协议栈把IP数据报向下交给适配器，组顿后发送到局域网。  

# 2.以太网的MAC地址  

IEEE802标准为局域网规定了一种48位的全球地址，是指局域网上的每台计算机中固化在适配器的ROM中的地址，称为物理地址或MAC地址（因为这种地址用在MAC顿中），这个地址用于控制主机在网络上的数据通信。全世界所有的局域网适配器都具有不同的地址，一台计算机只要没有更换适配器，不管其地理位置如何变化，其MAC地址都不会变化。  

>#### pro：以太网MAC地址的长度（2013）  

MAC地址长6字节，一般用由连字符（或冒号)分隔的12个十六进制数表示，如02-60-8c-e4-b1-21。高24位为厂商代码，低24位为厂商自行分配的适配器序列号。  

当路由器通过适配器连接到局域网时，适配器上的MAC地址就用来标志路由器的某个接口。路由器若同时连接到两个网络上，则它需要两个适配器和两个MAC地址。  
适配器从网络上每收到一个MAC帧，首先都要用硬件检查MAC帧中的目的地址。若是发往本站的帧，则收下，否则丢弃该帧。这里“发往本站的帧”包括以下三种帧：  

1）单播帧（一对一），即收到的帧的目的地址与本站的MAC地址相同。2）广播顿（一对全体），即发送给本局域网上所有站点的（全1地址）。3）多播帧（一对多），即发送给本局域网上一部分站点的帧。  

# 3.以太网的MAC帧  

以太网MAC帧格式有两种标准：DIXEthernetV2标准（即以太网V2标准）和IEEE802.3标准。这里只介绍最常用的以太网V2的MAC帧格式，如图3.25所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/335c6fdb9bafd3bdfa0928452310b671659a80125d05ada1c9a171de77cb363b.jpg)  
图3.25以太网V2标准的MAC帧格式  

命题追踪以太网帧首部的内容、首部和尾部的长度（2010、2011）  

在帧前面插入的8字节前导码分为两个字段：第一个字段是7字节的前同步码，用来实现MAC帧的比特同步；第二个字段是1字节的帧开始定界符，表示后面的信息就是MAC帧。  

# 注意  

以太网帧不需要顿结束定界符，因为当以太网传送顿时，各帧之间必须有一定的间隙。因此，接收方只要找到顿开始定界符，其后面连续到达的比特流就都属于同一个顿。实际上，以太网采用了违规编码法的思想，因为以太网使用曼彻斯特编码，所以每个码元中间都有一次电压的跳变。发送方发完一个帧后，发送方网络接口上的电压不再变化，这样接收方就能很容易地找到倾的结束位置，这个位置往前数4字节就是FCS字段，于是就能确定数据字段的结束位置。  

>#### pro：以太网帧中目的地址和源地址的含义（2018）  

目的地址：6字节，帧在局域网上的目的适配器的MAC地址。源地址：6字节，传输帧到局域网上的源适配器的MAC地址。类型：2字节，指出数据字段中的数据应交给哪个上层协议处理，如网络层的IP协议。命题追踪分析IP首部并判断其以太帧是否需要填充（2012）  

数据： $46\!\sim\!1500$ 字节，承载上层的协议数据单元（如IP数据报）。以太网的最大传输单元是1500字节，若IP数据报超过1500字节，则必须将该IP数据报分片。此外，由于CSMA/CD算法的限制，以太网顿必须满足最小长度是64字节，当数据字段的长度小于46字节时，MAC子层就在数据字段的后面加一个整数字节的填充字段，以确保帧长不小于64字节。  
# 注意  

46是怎么来的？由CSMA/CD可知以太网帧的最短帧长为64B，而MAC帧的首部和尾部的长度为18字节，所以数据字段最短为 $64-18=46$ 字节。  

检验码（FCS）：4字节，检验范围从目的地址段到数据字段，算法采用32位CRC码，不但要检验MAC顿的数据部分，而且要检验目的地址、源地址和类型字段，但不检验前导码。  

802.3顿格式与以太网V2帧格式的不同之处是，用长度域替代了V2帧中的类型域，指出了数据域的长度。在实践中，前述长度/类型两种机制可以并存，因为IEEE802.3数据段的最大字节数是1500，所以长度段的最大值是1500，于是从1501到65535的值可用于类型段标识符。  

# 4.高速以太网  

速率达到或超过 $100\,\mathrm{{Mb/s}}$ 的以太网称为高速以太网，表33列出了几种高速以太网技术。  

表3.3几种高速以太网技术
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c6d6e330faf79cc8e82e7e93152cc261305eb48d81b2a32610c15a7ec1713421.jpg)  

（1）100BASE-T以太网  

命题追踪100BaseT以太网使用的传输介质（2019）  

100BASE-T是在双绞线上传送 $100\mathrm{Mb/s}$ 基带信号的星形拓扑以太网，它仍然使用CSMA/CD协议，又称快速以太网。100BASE-T既支持全双工方式，又支持半双工方式，可在全双工方式下工作而无冲突发生，因此在全双工方式下不使用CSMA/CD协议。  

100BASE-T的MAC帧格式仍然是802.3标准规定的帧格式。保持最短帧长不变，但将一个网段的最大长度减小到 $100\mathrm{m}$ 。帧间最小间隔从原来的 $9.6\upmu\mathrm{s}$ 改为 $0.96\upmu\mathrm{s}$  

（2）吉比特以太网  

吉比特以太网又称千兆以太网，允许在1Gb/s速率下以全双工和半双工两种方式工作。使用802.3协议规定的帧格式。使用双绞线或光纤作为传输介质。在半双工方式下使用CSMA/CD协议，而在全双工方式不使用CSMA/CD协议。与10BASE-T和100BASE-T技术向后兼容。  

（3）10吉比特以太网  

10吉比特以太网的帧格式与10Mb/s、100Mb/s和1Gb/s以太网的顿格式完全相同，还保留了802.3标准规定的以太网最小帧长和最大帧长，以便升级和向后兼容。10吉比特以太网只工作在全双工方式，不存在争用问题，当然也不使用CSMA/CD协议。  

以太网从10Mb/s到10Gb/s的演进证明了以太网是可扩展的（从10Mb/s到10Gb/s）、灵活的（多种传输介质、全/半双工、共享/交换），且易于安装，稳健性好。  

# 3.6.3IEEE802.11无线局域网  

# 1.无线局域网的组成  

无线局域网可分为两大类：有固定基础设施的无线局域网和无固定基础设施的移动自组织网络。所谓“固定基础设施”，是指预先建立的、能覆盖一定地理范围的固定基站。  
# （1）有固定基础设施无线局域网  

对于有固定基础设施的无线局域网，IEEE制定了无线局域网的802.11系列协议标准，包括 $802.11\mathrm{a/b/g/n}$ 等。802.11标准使用星形拓扑，其中心称为接入点（AccessPoint，AP），在MAC层使用CSMA/CA协议。使用802.11系列协议的局域网又称Wi-Fi。  

802.11标准规定无线局域网的最小构件是基本服务集（BasicServiceSet，BSS）。一个基本服务集包括一个接入点和若干移动站。各站在本BSS内的通信，或与本BSS外部站的通信，都必须通过本BSS的AP。上面提到的AP就是基本服务集中的基站（basestation）。安装AP时，必须为其分配一个不超过32字节的服务集标识符（ServiceSetIDentifier，SSID）和一个信道。SSID是指使用该AP的无线局域网的名称。基本服务集覆盖的地理范围称为基本服务区（BasicServiceArea，BSA)，无线局域网的基本服务区的直径一般不超过 $100\mathrm{m}$  

基本服务集可以是孤立的，也可通过AP连接到一个分配系统（DistributionSystem，DS），然后连接到另一个基本服务集，构成一个扩展的服务集（ExtendedServiceSet，ESS）。分配系统的作用是使扩展的服务集对上层的表现就像一个基本服务集。ESS还可通过一种称为Portal（门户）的设备为无线用户提供到有线连接的以太网接入。门户的作用相当于网桥。在图3.26中，移动站A若要和另一个基本服务集中的移动站B通信，则必须经过两个接入点 $\mathrm{AP_{1}}$ 和 $\mathrm{AP}_{2}$ ，即 $\mathrm{A{\rightarrow}A P_{1}{\rightarrow}A P_{2}{\rightarrow}B}$ ，注意 $\mathrm{AP_{1}}$ 到AP2的通信是使用有线传输的。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/9eb5ed824fc2a3b0a59ba485fd71622971ce829bb5fd78ba76982d77f4d615a1.jpg)  
图3.26基本服务集和扩展服务集  

当移动站A从某个基本服务集漫游到另一个基本服务集时（图3.26中的A'），仍可保持与另一个移动站B的通信。但A在不同的基本服务集中使用的AP改变了。  

# （2）无固定基础设施移动自组织网络  

另一种无线局域网是无固定基础设施的无线局域网，又称自组网络（adhocnetwork）。自组网络没有上述基本服务集中的AP，而有由一些平等状态的移动站相互通信组成的临时网络（见图3.27）。各结点之间地位平等，中间结点都为转发结点，因此都具有路由器的功能。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/5e9beabbfb4f9fccf1dcc1a93424962aa72ecf19782692558da976e534935427.jpg)  
图3.27由一些处于平等状态的便携机构成的自组网络  
自组网络通常是这样构成的：一些可移动设备发现在它们附近还有其他的可移动设备，且要求和其他移动设备进行通信。自组网络中的每个移动站都要参与网络中其他移动站的路由发现和维护，同时由移动站构成的网络拓扑可能随时间变化很快，因此在固定网络中行之有效的一些路由选择协议对移动自组网络已不适用，需引起特别的关注。  

自组网络和移动IP并不相同。移动ⅡP技术使漫游的主机可用多种方法连接到因特网，其核心网络功能仍然基于固定网络中一直使用的各种路由选择协议。而自组网络是将移动性扩展到无线领域中的自治系统，具有自己特定的路由选择协议，且可以不和因特网相连。  

# 2.802.11局域网的MAC帧  

802.11帧共有三种类型，即数据帧、控制帧和管理帧。数据帧的格式如图3.28所示。  

802.11数据顺由以下三部分组成：  

1）MAC首部，共30字节。帧的复杂性都在MAC首部。  

2）顿主体，即顿的数据部分，不超过2312字节。它比以太网的最大长度长很多。  

3）顿检验序列FCS是MAC尾部，共4字节。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3f40c912ceedd23f85edb5439bf521f26f450fa378bb77273726767fa923d3b9.jpg)  

>#### pro：802.11数据帧前三个地址的含义（2017、2022）  

802.11帧的MAC首部中最重要的是4个地址字段（都是MAC地址）。这里仅讨论前三个地址（地址4用于自组网络）。这三个地址的内容取决于帧控制字段中的“去往AP”和“来自AP”这两个字段的数值。表3.4中给出了802.11帧的地址字段最常用的两种情况。  

表3.4802.11帧的地址字段最常用的两种情况
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f3eaebbc5f5d12579fab4e4c209783bca0171b7a4b8180336806e93b3506e840.jpg)  

地址1是直接接收数据帧的结点地址，地址2是实际发送数据帧的结点地址。1）现在假定从一个BSS中的A站向B站发送数据帧。在A站发往AP的数据帧的帧控制字  

段中，“去往 $\mathrm{AP}\!=\!1$ ”而“来自 $\scriptstyle\mathrm{AP}\,=\,0^{\,\ast}$ ；地址1是AP的MAC地址，地址2是A站的MAC地址，地址3是B站的MAC地址。注意，“接收地址”与“目的地址”并不等同。2）AP接收到数据帧后，转发给B站，此时在数据帧的帧控制字段中，“去往 $\scriptstyle\mathrm{AP}\,=\,0$ ”而“来自 $\mathrm{AP}\!=\!1^{\mathrm{~\prime}}$ "；地址1是B站的MAC地址，地址2是AP的MAC地址，地址3是A站的MAC地址。注意，“发送地址”与“源地址”也不等同。  

对这三个地址的理解方法如下：地址1和地址2分别是无线通信中信道两端的接收地址和发送地址。当主机发往AP时，接收地址不是实际的目的地址，因此用地址3来存放实际的目的地址；当AP发往主机时，发送地址不是实际的源地址，因此用地址3来存放实际的源地址。  
下面讨论一种更复杂的情况。在图3.29中，两个AP有线连接到路由器，现在路由器要向A站发送数据。路由器是网络层设备，它看不见链路层的AP，只认识A站的IP地址。而AP是链路层设备，它只认识MAC地址，而不认识IP地址。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/e7f833269a3e7b7cb8b5ed61e42cde3731f90a609e1648ec60c7c6c56d6e5f14.jpg)  
图3.29链路上的802.11帧和802.3帧  

1）路由器从IP数据报获知A站的IP地址，并用ARP获取A站的MAC地址。获取A站的MAC地址后，路由器接口R1将该IP数据报封装成802.3帧（802.3帧只有两个地址），该帧的源地址字段是R1的MAC地址，目的地址字段是A站的MAC地址。2）AP收到该802.3帧后，将该802.3帧转换为802.11帧，在顿控制字段中，“去往 $\scriptstyle\mathrm{AP}\,=\,0$ 而“来自  $\mathrm{AP}\!=\!1$  "；地址1是A站的MAC地址，地址2是AP的MAC地址，地址3是 R1的MAC地址。这样，A站就可以确定（从地址3）将数据报发送到子网中的路由器接口的MAC地址。  

现在考虑从A站向路由器接口R1发送数据的情况。  

1）A站生成一个802.11帧，在帧控制字段中，“去往 $\mathrm{AP}\!=\!1$ ”而“来自 $\scriptstyle\mathrm{AP}\,=\,0$ "；地址1是AP的MAC地址，地址2是A站的MAC地址，地址3是R1的MAC地址。2）AP收到该802.11帧后，将其转换为802.3帧。该帧的源地址字段是A站的MAC地址，目的地址字段是R1的MAC地址。  

由此可见，地址3在BSS和有线局域网互连中起关键作用，它充许AP在构建以太网帧时确定目的MAC地址。  

802.11帧的MAC首部的其他字段不是考查重点，感兴趣的同学可以翻阅教材。  

# 3.6.4VLAN基本概念与基本原理  

一个以太网是一个广播域，当一个以太网中包含的计算机太多时，往往会导致：  

以太网中出现大量的广播帧，特别是经常使用的ARP和DHCP协议（第4章）。一个单位的不同部门共享一个局域网，对信息保密和安全不利。通过虚拟局域网（VirtualLAN，VLAN)，可将一个较大的局域网分割成一些较小的与地理位置无关的逻辑上的VLAN，而每个VLAN是一个较小的广播域。  

有以下三种划分VLAN的方式：  

1）基于接口。将交换机的若干接口划为一个逻辑组，这种方法最简单、最有效，若主机离开了原来的接口，则可能进入一个新的子网。2）基于MAC地址。按MAC地址将一些主机划分为一个逻辑子网，当主机的物理位置从一个交换机移动到另一个交换机时，它仍属于原来的子网。3）基于IP地址。根据网络层地址或协议划分VLAN，这样的VLAN可以跨越路由器进行扩展，将多个局域网的主机连接在一起。  
802.3ac标准定义了支持VLAN的以太网帧格式的扩展。它在以太网帧中插入一个4字节的标识符（插在源地址字段和类型字段之间），称为VLAN标签，用来指明发送该顿的计算机属于哪个虚拟局域网。插入VLAN标签的帧称为802.1Q顿，如图3.30所示。因为VLAN帧的首部增 加了4字节，所以以太网的最大帧长从原来的1518字节变为1522字节。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/1fa3727e65c66ef56fbed43250bdacfe8219a92ec3a163fb8a0fb3a860dc6465.jpg)  
图3.30插入VLAN标签后变成了802.1Q帧  

VLAN标签的前两个字节总是置为 $0x8100$ ，表示这是一个802.1Q帧。在VLAN标签的后两个字节中，前4位实际上并没什么作用，这里不讨论，后12位是该VLAN的标识符VID，它唯一地标识该802.1Q顺属于哪个VLAN。12位的VID可识别4096个不同的VLAN。插入VLAN标签后，802.1Q帧最后的FCS必须重新计算。  

如图3.31所示，交换机1连接7台计算机，该局域网划分为两个虚拟局域网VLAN-10和VLAN-20，这里的10和20就是802.1Q帧中的VID字段的值，由交换机管理员设定。各主机并不知道自己的VID值（但交换机必须知道），主机与交换机之间交互的都是标准以太网帧。一个VLAN的范围可以跨越不同的交换机，前提是所用的交换机能够识别和处理VLAN。交换机2连接5台计算机，并与交换机1相连。交换机2中的2台计算机加入VLAN-10，另外3台计算机加入VLAN-20。这两个VLAN虽然都跨越了两个交换机，但各自都是一个广播域。  

连接两个交换机接口之间的链路称为汇聚链路或干线链路。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/dd404bb6f4326a5aaef9831d2ab0187e38a5a00c9a33d5c1bef9ca4561b86ddf.jpg)  
图3.31利用以太网交换机构成虚拟局域网  

假定A站向B站发送帧，交换机1根据帧首部的目的MAC地址，识别B站属于本交换机管理的VLAN-10，因此就像在普通以太网中那样直接转发顿。假定A站向E站发送帧，交换机1必须把帧转发到交换机2，但在转发前，要插入VLAN标签，否则交换机2就不知道应把帧转发给哪个VLAN。因此，在于线链路上传送的帧是802.1Q帧。交换机2在向E站转发帧之前，要拿走已插入的VLAN标签，因此E站收到的顿是A站发送的标准以太网帧，而不是802.1Q帧。若A站向C站发送帧，则情况就复杂了，因为这是在不同网络之间的通信，虽然A站和C站都连接到同一个交换机，但是它们已处在不同的网络中（VLAN-10和VLAN-20），需要通过上层的路由器来解决，也可在交换机中嵌入专用芯片进行转发，以便在交换机中实现第3层的转发功能。  

虚拟局域网只是局域网为用户提供的一种服务，并不是一种新型局域网。  

# 3.7广域网  

# 3.7.1广域网的基本概念  

广域网（WideAreaNetwork，WAN）通常是指覆盖范围很广（远超一个城市的范围）的长距离网络，任务是长距离运送主机所发送的数据。连接厂域网各结点交换机的链路都是高速链路广域网首要考虑的问题是通信容量必须足够大，以便支持日益增长的通信量。  

广域网不等于互联网。互联网可以连接不同类型的网络，通常使用路由器来连接。图3.32显示了由相距较远的局域网通过路由器与广域网相连而成的一个覆盖范围很广的互联网。因此，局域网可以通过广域网与另一个相隔很远的局域网通信。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/fa20b8aff01d6411522b5859a6d1ef29ac82c032e885c56b3830863eac73e4c8.jpg)  
图3.32由局域网和广域网形成的互联网  

广域网由一些结点交换机（注意不是路由器，结点交换机和路由器都用来转发分组，它们的工作原理也类似。结点交换机在单个网络中转发分组，而路由器在多个网络构成的互联网中转发分组）及连接这些交换机的链路组成。结点交换机的功能是存储并转发分组。结点之间都是点到点连接，但为了提高网络的可靠性，通常一个结点交换机往往与多个结点交换机相连。  

从层次上考虑，广域网和局域网的区别很大，因为局域网使用的协议主要在数据链路层（还有少量在物理层），而广域网使用的协议主要在网络层。怎么理解“局域网使用的协议主要在数据链路层，而厂域网使用的协议主要在网络层”这句话呢？若网络中的两个结点要进行数据交换，则结点除了要给出数据，还要给数据“包装”上一层控制信息，用于实现传输控制等功能。若这层控制信息是数据链路层协议的控制信息，则称使用了数据链路层协议：若这层控制信息是网络层的控制信息，则称使用了网络层协议。  

广域网和局域网的区别与联系见表3.5。  
表3.5广域网和局域网的区别与联系
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/5405276467369b2d85907054b6143b147698e5110094dc13809916dce8e72eac.jpg)  

在通信线路质量较差的年代，能实现可靠传输的高级数据链路控制（HDLC）成为当时比较流行的数据链路层协议。但对现在误码率很低的点对点有线链路，更简单的点对点协议（PPP）则是目前使用最广泛的数据链路层协议。HDLC已从最新大纲中删除，所以本书不再介绍。  

# 3.7.2PPP协议  

点对点协议（Point-to-PointProtocol，PPP）是现在最流行的点对点链路控制协议。主要有两种应用： $\textcircled{\scriptsize{1}}$ 用户通常都要连接到某个ISP才能接入互联网，PPP协议就是用户计算机与ISP通信时所用的数据链路层协议： $\circledcirc$ 广泛用于广域网路由器之间的专用线路。  

PPP协议有三个组成部分：  

1）一个链路控制协议（LCP）。用来建立、配置、测试数据链路连接，以及协商一些选项。  

2）一套网络控制协议（NCP）。PPP协议充许采用多种网络层协议，每个不同的网络层协议要用一个相应的NCP来配置，为网络层协议建立和配置逻辑连接。  

3）一种将IP数据报封装到串行链路的方法。IP数据报在PPP帧中就是其信息部分，这个信息部分的长度受最大传送单元（MTU）限制。  

PPP帧的格式如图3.33所示，首部和尾部分别为4个字段和2个字段。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/1e8d91d9da44885d266b032830b73b1f319582eddaad40c563b504eeddffc9ef.jpg)  
图3.33PPP帧的格式  

首部和尾部各有一个标志字段（F），规定为0x7E（01111110），它表示一个帧的开始和结束，即PPP顿的定界符。当标志字段出现在信息段中时，就必须采取一些措施使这种形式上和标志字段一样的比特组合不出现在信息段中。当PPPP使用异步传输时，采用字节填充法，使用的转义字符是0x7D（01111101）。当PPP使用同步传输时，采用零比特填充法来实现透明传输。  

地址字段（A）占1字节，规定为0xFF，控制字段（C）占1字节，规定为0x03，这两个字段的意义暂未定义。PPP是面向字节的，因此所有PPP帧的长度都是整数个字节。  

第四个字段是协议段，占2字节，它表示信息段运载的是什么种类的分组。若为0x0021，则信息字段是IP数据报。若为 $\mathrm{0xC021}$ ，则信息字段是PPP链路控制协议（LCP）的数据。  

第五段信息段的长度是可变的，长度为 $\mathord{0}\mathord{\sim}\!1500$ 字节。  
# 注意  

因为PPP是点对点的，并不是总线形，所以无须使用CSMA/CD协议，自然就不会有最短帧长的限制，所以信息段占 $0\sim1500$ 字节，而不是46\~1500学节。  

第六个字段是顿检验序列（FCS），占2字节，是使用CRC检验的几余码。图3.34给出了PPP协议的状态图。具体解释如下：  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/d94ee3aeefa6ea19b8d920eb532cdff20689de0539f58617c2802450a1044797.jpg)  
图3.34PPP协议的状态图  

1）当处于链路静止状态时，通信双方不存在物理层的连接2）当链路一方检测到载波信号并建立物理连接时，进入链路建立状态。  

3）在链路建立状态下，链路控制协议（LCP）开始协商一些配置选项（包括最大顿长、鉴别协议等）。若协商成功，则进入鉴别状态。若协商失败，则退回到链路静止状态。  

4）协商成功后，双方就建立了LCP链路，接着进入“鉴别”状态。若双方无须鉴别或鉴别身份成功，则进入网络层协议状态。若鉴别失败，则进入链路终正状态。  

5）处于网络层协议状态后，双方采用NCP配置网络层，配置协商成功后，进入链路打开状态。6）只要链路处于打开状态，双方就可进行数据通信。  

7）数据传输结束后，链路一方发出终正请求且在收到对方发来的终止确认后，或者链路出现故障时，进入链路终止状态。载波停止后，回到链路静止状态。  

PPP协议的特点如下：  

1）PPP不使用序号和确认机制，只保证无差错接收（CRC检验），因此是不可靠服务。2）PPP只支持全双工的点对点链路，不支持多点线路。3）PPP的两端可以运行不同的网络层协议，但仍可使用同一个PPP进行通信。4）PPP是面向字节的，所有PPP帧的长度都是整数个字节。  
 

# 3.8数据链路层设备  

#  ${\bf\Psi}^{*}3.8.1$ 网桥的基本概念  

使用集线器在物理层扩展以太网会形成更大的冲突域。为了避免这个问题，可以使用网桥在数据链路层扩展以太网，而原来的每个以太网称为一个网段。使用网桥进行扩展时，不会将原本独立的两个冲突域合并成一个更大的冲突域，这是因为网桥具有识别顿和转发顿的能力，根据顺首部中的目的MAC地址和网桥的帧转发表来转发或丢弃所收到的顿，起到了过滤通信量的功能。因为各个网段是相对独立的，所以一个网段的故障不影响另一个网段的运行。  
网络1和网络2通过网桥连接后，网桥接收网络1发送的数据顿，检查数据帧中的地址，若是网络2的地址，则转发给网络2；若是网络1的地址，则将其丢弃，因为源站和目的站处在同一个网段，目的站能够直接收到这个帧，而不需要借助网桥转发。  

网桥是早期的数据链路层设备，现已被以太网交换机取代，最新大纲中已将其删除。  

# 3.8.2以太网交换机  

# 1.交换机的原理和特点  

以太网交换机也称二层交换机，二层是指以太网交换机工作在数据链路层。以太网交换机实质上是一个多接口的网桥，它能将网络分成小的冲突域，为每个用户提供更大的带宽。对于传统使用集线器的共享式10Mb/s以太网，若共有 $N$ 个用户，则每个用户的平均带宽为总带宽（ $10\,\mathrm{{Mb/s}}\,\mathrm{{)}}$ 的1/N。使用以太网交换机（全双工方式）连接这些主机时，虽然从每个接口到主机的带宽还是 $10\mathrm{Mb/s}$ ，但是因为一个用户通信时是独占带宽的（而不是和其他网络用户共享传输介质带宽的），所以拥有 $N$ 个接口的交换机的总容量为 $N{\times}10\mathrm{M}\mathrm{b}/\mathrm{s}$ 。这正是交换机的最大优点。  

>#### pro：以太网交换机的特点（2015）  

以太网交换机的特点：  

1）当交换机的接口直接与主机或其他交换机连接时，可工作在全双工方式，并能同时连通多对接口，使每对相互通信的主机都能像独占通信介质那样，无冲突地传输数据，这样就不需要使用CSMA/CD协议。2）当交换机的接口连接集线器时，只能使用CSMA/CD协议且只能工作在半双工方式。当前的交换机和计算机中的网卡都能自动识别上述两种情况。3）交换机是一种即插即用设备，其内部的帧转发表是通过自学习算法，基于网络中各主机间的通信，自动地逐渐建立的。4）交换机因为使用专用交换结构芯片，交换速率较高。  

5）交换机独占传输介质的带宽。  

>#### pro：直通交换方式的转发时延的分析（2013）  

以太网交换机主要采用两种交换模式：  

1）直通交换方式。只检查帧的目的MAC地址，以决定该帧的转发接口。这种方式的交换时延非常小，缺点是它不检查差错就直接转发，因此可能将一些无效顺转发给其他站。直通交换方式不适用于需要速率匹配、协议转换或差错检测的线路。  

2）存储转发交换方式。先将接收到的帧缓存到高速缓存器中，并检查数据是否正确，确认无误后通过查找表转换为输出接口，以便将该帧发送出去。若发现帧有错，则将其丢弃。优点是可靠性高，且能支持不同速率接口间的转换，缺点是时延较大。  

交换机一般都具有多种速率的接口，如10Mb/s、100Mb/s的接口，以及多速率自适应接口。  

# 2.交换机的自学习功能  

>#### pro：以太网交换机转发决策时使用的PDU地址（2009）  

决定一个顿是转发到某个接口还是丢弃它称为过滤。决定一个帧应被移至哪个接口称为转发。交换机的过滤和转发借助交换表（switchtable）完成。交换表中的一个表项至少包含： $\textcircled{\scriptsize{1}}$ 一个MAC地址； $\textcircled{2}$ 连通该MAC地址的接口。例如，在图3.35中，以太网交换机有4个接口，各连接一台计算机，MAC地址分别为A、B、C和D，交换机的交换表最初为空。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/53ad90e0fe9307244331a3e9fee9dbea78bb5927bafa54f29fc77ee3e117e528.jpg)  
图3.35以太网交换机中的交换表  

>#### pro：交换机自学习的过程（2014、2016、2021）  

A先向B发送一帧，从接口1进入交换机。交换机收到帧后，查找交换表，找不到MAC地址为B的表项。然后，交换机将该帧的源地址A和接口1写入交换表，并向除接口1外的所有接口广播这个顺（该帧就是从接口1进入的，因此不应将它再从接口1转发出去）。C和D丢弃该顿，因为目的地址不对。只有B才收下这个目的地址正确的帧。交换表中写入（A，1）后，从任何接口收到目的地址为A的帧都应从接口1转发出去。这是因为，既然A发出的顿从接口1进入交换机，那么从接口1转发出去的帧也应能到达A。  

接下来，假定B通过接口3向A发送一帧，交换机查找交换表后，发现有表项（A，1），将该帧从接口1转发给A。显然，此时已没有必要再广播收到的帧。将该帧的源地址B和接口3写入交换表，表明以后若有发送给B的帧，则应从接口3转发出去。  

经过一段时间后，只要C和D也向其他主机发送帧，交换机就把C和D及对应的接口号写入交换表。这样，转发给任何主机的帧，就都能很快地在交换表中找到相应的转发接口。  

因为交换机所连的主机会随时变化，所以需要更新交换表中的表项。为此，交换表中的每个表项都设有一定的有效时间，过期表项将被自动删除。这就保证了交换表中的数据符合当前网络的实际状况。这种自学习算法使得交换机能即插即用，而不必手工配置，因此非常方便。  

# 3.共享式以太网和交换式以太网的对比  

>#### pro：集线器与交换机连接的网段的区别（2016）  

假设交换机已通过自学习算法遂步建立了完整的转发表，下面举例说明使用集线器的共享式以太网与全部使用交换机的交换式以太网的区别。  

1）主机发送普通顿。对于共享式以太网，集线器将帧转发到其他所有接口，其他各主机中的网卡根据帧的目的MAC地址决定接收或丢弃该帧。对于交换式以太网，交换机收到帧后，根据帧的目的MAC地址和自身的交换表将帧明确地转发给目的主机。  

2）主机发送广播帧。对于共享式以太网，集线器将顿转发到其他所有接口，其他各主机中的网卡检测到帧的目的MAC地址是广播地址时，就接收该顿。对于交换式以太网，  
交换机检测到帧的目的MAC地址是广播地址，于是从其他所有接口转发该顿，其他各主机收到该广播顿后，就接收该帧。两种情况从效果上看是相同的，但它们的原理并不相同。  

3）多对主机同时通信。对于共享式以太网，当多对主机同时通信时，必然产生冲突。对于交换式以太网，交换机能实现多对接口的高速并行交换，因此不会产生冲突。  

>#### pro：集线器和交换机对冲突域/广播域的隔离（2020、2022）  

可见，集线器既不隔离广播域，又不隔离冲突域，而交换机不隔离广播域，但隔离冲突域。  


# 3.9本章小结及疑难点  

1.说明用 $n$ 比特进行编号时，若接收窗口的大小为1，则仅在发送窗口的大小 $W_{\mathrm{T}}\leqslant2^{n}\!-\!1$ 时，连续ARQ协议才能正确运行。  

假设用3比特进行编号，可表示8个不同的序号，发送窗口的最大值似乎可以为8。但是，实际上，发送窗口的大小设为8将使协议在某些情况下无法工作。下面来证明这一点。  

设发送窗口为8，发送方发送完 $_{0\sim7}$ 号共8个数据帧后，暂停发送。假定这8个数据顿均已正确到达接收方，且接收方对每个数据帧都发回了确认顿。下面考虑两种不同的情况。  

第一种情况：所有确认顿都正确地到达发送方，因此发送方接着又发送8个新的数据顿，其编号应是 $_{0\sim7}$ 。注意，序号是循环使用的。因此序号虽然相同，但8个顿都是新的顿。  

第二种情况：所有确认帧都丢失。经过一段超时计时器控制的时间后，发送方重传这8个旧数据帧，其编号仍为 $_{0\sim7}$  
于是，当接收方第二次收到编号为 $_{0\sim7}$ 的8个数据帧时，就无法判定这是8个新数据顿还是8个重传的旧数据顿。因此，将发送窗口设为8显然是不行的。  

2.为什么PPP协议不使用帧的编号和确认机制来实现可靠传输？PPP不使用序号和确认机制是出于以下考虑：  

若使用能够实现可靠传输的数据链路层协议（如HDLC），开销就会增大。当数据链路层出现差错的概率不大时，使用比较简单的PPP较为合理。  

在因特网环境下，PPP的信息字段放入的数据是IP数据报。假定我们采用了能实现可靠传输但十分复杂的数据链路层协议，当数据帧在路由器中从数据链路层上升到网络层时，仍有可能因网络拥塞而被去弃。因此，数据链路层的可靠传输并不能保证网络层的传输也是可靠的。  

PPP在帧格式中有顿检验序列FCS字段。对于每个收到的帧，PPP都要使用硬件进行CRC检验。若发现差错，则丢弃该帧（一定不能把有差错的顿交给上一层）。端到端的差错控制最后由高层协议负责。因此，PPP可以保证无差错接收。  

3.在标准以太网中，为什么说若有冲突，则冲突一定发生在冲突窗口内？或者说一个帧若在冲突窗口内没有发生冲突，则该帧不会再发生冲突？  

结点在发送数据之前，先监听信道是否有载波，若有，表示信道忙，则继续监听，直至检测到信道空闲为止。一个数据帧在从结点A向最远结点的传输过程中，若有其他结点也在发送数据，则会发生冲突，冲突后的信号经过冲突窗口时间后传回结点A，结点A会检测到冲突，所以说若有冲突，则一定发生在冲突窗口内，若在冲突窗口内没有发生冲突，之后若其他结点再要发送数据，则会监听到信道忙，而不会发送数据，从而不会再发生冲突。  

4.一个以太网的速率从10Mb/s升级到100Mb/s，满足CSMA/CD冲突条件。为使其正常工作，需做哪些调整？为什么？  

100BaseT以太网与 $10\,\mathrm{{Mb}/\mathrm{{s}}}$ 以太网的帧格式相同，唯一不同的参数是帧间最小间隔时间，10Mb/s以太网的顿间最小间隔时间是 $9.6\upmu\mathrm{s}$ ，100BaseT以太网的帧间最小间隔时间是 $0.96\upmu\mathrm{s}$ 。此外，为了保持最短帧长不变，将一个网段的最大长度减小到 $100\mathrm{m}$ 。所有这些调整的原因是速率提高到了原速度的10倍。  

5.关于物理层、数据链路层、网络层设备对于隔离冲突域和广播域的总结。
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/fc3ddde383674d06764c118a9de7de3dffbcff35e7317effddf57d889c61eb8c.jpg)  
# 第4章网络层  

# 【考纲内容】  

（一）网络层的功能  

异构网络互连：路由与转发：SDN基本概念：拥塞控制  

（二）路由算法静态路由与动态路由；距离-向量路由算法；链路状态路由算法；层次路由  

（三）IPv4  

IPv4分组；IPv4地址与NAT；子网划分与子网掩码、CIDR、路由聚合、ARP、DHCP 与ICMP  

（四）IPv6  

IPv6的主要特点：IPv6地址  

（五）路由协议  

自治系统：域内路由与域间路由：RIP路由协议：OSPF路由协议：BGP路由协议  

（六）IP多播  

多播的概念：IP多播地址  

（七）移动IP 移动IP的概念；移动IP通信过程  

（八）网络层设备路由器的组成和功能；路由表与路由转发  

# 【复习提示】  

本章是历年考查的重中之重，尤其是结合第3章、第5章、第6章出综合题的概率很大。其中IPv4和路由的相关知识点是核心，历年真题都有涉及，因此必须牢固掌握其原理，还要多做题，以便灵活应用。本章的其他知识点，如IP多播、移动IP、IPv6也要有所了解。  

# 4.1网络层的功能  

网络层提供主机到主机的通信服务，主要任务是将分组从源主机经过多个网络和多段链路传输到自的主机。该任务可划分为分组转发和路由选择两种重要功能。  

OSI参考模型曾主张在网络层使用面向连接的虚电路服务，认为应由网络自身来保证通信的可靠性。而TCP/IP体系的网络层提供的是无连接的数据报服务，其核心思想是应由用户主机来保证通信的可靠性。虚电路和数据报服务已在2.1节中介绍。  
在互联网采用的TCP/IP体系结构中，网络层向上只提供简单灵活的、无连接的、尽最大努力交付的数据报服务。也就是说，所传送的分组可能出错、丢失、重复、失序或超时，这就使得网络中的路由器可以做得比较简单，而且价格低廉。通信的可靠性可以由更高层的传输层来负责。采用这种设计思路的好处是：网络的造价大大降低，运行方式灵活，能够适应多种应用。互联网能够发展到今日的规模，充分证明了当初采用这种设计思想的正确性。  

# 4.1.1异构网络互连  

互联网是由全球范围内数以百万计的异构网络互连起来的。这些网络的拓扑结构、寻址方案、差错处理方法、路由选择机制等都不尽相同。网络层所要完成的任务之一就是使这些异构的网络实现互连。网络互连是指将两个以上的计算机网络，通过一定的方法，用一些中继系统相互连接起来，以构成更大的网络系统。根据所在的层次，中继系统分为以下4种：  

1）物理层中继系统：转发器，集线器。2）数据链路层中继系统：网桥或交换机。3）网络层中继系统：路由器。4）网络层以上的中继系统：网关。  

当使用物理层或数据链路层的中继系统时，只是把一个网络扩大了，而从网络层的角度看，它仍然是同一个网络，一般并不称为网络互连。因此，网络互连通常是指用路由器进行网络连接和路由选择。路由器是一台专用计算机，用于在互联网中进行路由选择。  

# 注意  

由于历史原因，许多有关TCP/IP的文献也将网络层的路由器称为网关。  

TCP/IP在网络互连上采用的做法是在网络层采用标准化协议，但相互连接的网络可以是异构的。图4.1(a)表示用许多计算机网络通过一些路由器进行互连。因为参与互连的计算机网络都使用相同的IP协议，所以可把互连后的网络视为如图4.1(b)所示的一个虚拟IP网络。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/621a3f2136975b86286096e310e22fa48507532f731983586cccced6c926f71f.jpg)  
图4.1IP网络的概念  

虚拟互连网络也就是逻辑互连网络，意思是互连起来的各种物理网络的异构性本来是客观存在的，但是通过IP协议就可使这些性能各异的网络在网络层上看起来像是一个统一的网络。这种使用IP协议的虚拟互连网络可简称为IP网络。  

使用IP网络的好处是：当IP网上的主机进行通信时，就好像在单个网络上通信一样，而看不见互连的各个网络的具体异构细节（如具体的编址方案、路由选择协议等）。  
# 4.1.2 路由与转发  

路由器主要完成两个功能：一是路由选择（确定哪一条路径），二是分组转发（当一个分组到达时所采取的动作）。前者根据路由选择协议构造并维护路由表。后者处理通过路由器的数据流，关键操作是转发表查询、转发及相关的队列管理和任务调度等。  

1）路由选择。根据路由协议构造路由表，同时经常或定期地与相邻路由器交换信息，获取网络最新拓扑，动态更新维护路由表，以决定分组到达目的地结点的最优路径。  

2）分组转发。指路由器根据转发表将分组从合适的端口转发出去。  

路由表是根据路由选择算法得出的，而转发表是从路由表得出的。转发表的结构应当使查找过程最优化，路由表则需要最优化网络拓扑变化的计算。在讨论路由选择的原理时，往往不区分转发表和路由表，而笼统地使用路由表一词。  

# 4.1.3网络层提供的两种服务  

分组交换网根据其通信子网向端点系统提供的服务，还可进一步分为面向连接的虚电路服务和无连接的数据报服务。这两种服务方式都是由网络层提供的。  

# 1.虚电路  

>#### pro：虚电路网络的特性（2020）  

在虚电路方式中，当两台计算机进行通信时，应当先建立网络层的连接，也就是建立一条逻辑上的虚电路（VirtualCircuit，VC），连接一旦建立，就固定了虚电路对应的物理路径。与电路交换类似，整个通信过程分为三个阶段：虚电路建立、数据传输与虚电路释放。  

每次建立虚电路时，将一个未用过的虚电路号（VCID）分配给该虚电路，以区别于本系统中的其他虚电路，然后双方就沿着已建立的虚电路传送分组。分组的首部仅在连接建立时使用完整的目的地址，之后每个分组的首部只需携带这条虚电路的编号即可。在虚电路网络中的每个结点上都维持一张虚电路表，表中每项记录一个打开的虚电路的信息，包括在接收链路和发送链路上的虚电路号、前一结点和下一结点的标识，它是在虚电路建立过程中确定的。  

虚电路方式的工作原理如图4.2所示。  

1）数据传输前，主机A与主机B先建立连接，主机A发出“呼叫请求”分组，该分组通过中间结点送往主机B，若主机B同意连接，则发送“呼叫应答”分组予以确认。2）虚电路建立后，主机A和主机B就可相互传送数据分组。3）传送结束后，主机A通过发送“释放请求”分组来拆除虚电路，逐段断开整个连接。通过上面的例子，可总结出虚电路服务具有如下特点：1）虚电路通信链路的建立和拆除需要时间开销，对交互式应用和少量的短分组情况显得很浪费，但对长时间、频繁的数据交换效率较高。2）虚电路的路由选择体现在连接建立阶段，连接建立后，就确定了传输路径。3）虚电路提供了可靠的通信功能，能保证每个分组正确且有序到达。此外，还可对两个端点的流量进行控制，当接收方来不及接收数据时，可以通知发送方暂缓发送。4）虚电路有一个致命的弱点，即当网络中的某个结点或某条链路出现故障而彻底失效时，所有经过该结点或该链路的虚电路将遭到破坏。5）分组首部不包含目的地址，包含的是虚电路号，相对于数据报方式，其开销小。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/9233181e79b8ebc96077008ff22adf1f54d99334985fab79c6c81d56c6d3f9fd.jpg)  
图4.2虚电路方式的工作原理  

虚电路之所以是虚，是因为这条电路不是专用的，每个结点到其他结点之间的链路可能同时有若干条虚电路通过，也可能同时在多个结点之间建立虚电路。  

注意，图4.2所示的数据传输过程是有确认的传输（由高层实现），B收到分组后要发回相应分组的确认。网络中的传输是否有确认与网络层提供的两种服务没有任何关系。  

# 2.数据报  

网络在发送分组前不需要先建立连接。源主机的高层协议将报文拆成若干较小的数据段，并加上地址等控制信息后构成分组。中间结点存储分组很短一段时间，找到最佳的路由后，尽快转发每个分组。网络层不提供服务质量的承诺。因为网络不提供端到端的可靠传输服务，所以这就使得网络中的路由器比较简单，且造价低廉（与电话网络相比）。  

下面用图4.3中的例子来说明数据报服务的原理。假定主机A向主机B发送分组。  

1）主机A先将分组逐个发往与它直接相连的交换结点A，交换结点A缓存收到的分组。 2）然后查找自己的转发表。因为不同时刻的网络状态不同，所以转发表的内容可能不完全相同，所以有的分组转发给交换结点C，有的分组转发给交换结点D。3）网络中的其他结点收到分组后，类似地转发分组，直到分组最终到达主机B。当分组正在某一链路上传送时，分组并不占用网络其他部分的资源。因为采用存储转发技术资源是共享的，所以主机A在发送分组时，主机B也可同时向其他主机发送分组。  

通过上面的例子，我们可以总结出数据报服务具有如下特点：  

1）发送分组前不需要建立连接。发送方可随时发送分组，网络中的结点可随时接收分组。2）网络尽最大努力交付，传输不保证可靠性，所以分组可能出错或丢失：网络为每个分组独立地选择路由，转发的路径可能不同，因此分组不一定按序到达自的结点。  
3）发送的分组中要包括发送方和接收方的完整地址，以便可以独立传输。  

4）当分组在交换结点存储转发时，需要排队等候处理，这会带来一定的时延。当网络发生拥塞时，这种时延会大大增加，交换结点还可根据情况丢弃部分分组。5）网络具有冗余路径，当某个交换结点或一条链路出现故障时，可相应地更新转发表，寻找另一条路径转发分组，对故障的适应能力强。  

6）收发双方不独占某条链路，资源利用率较高。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/12567fcdff5ade6c268261075cfc133a5380945b6f92cd8795694b59b3b807a6.jpg)  
图4.3数据报方式转发分组  

采用这种设计思想的好处是：网络的造价大大降低、运行方式灵活、能够适应多种应用。互联网能够发展到今大的规模，充分证明了当初采用这种设计思想的正确性。  

数据报服务和虚电路服务的比较见表4.1。  

表4.1数据报服务和虚电路服务的比较
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f324c7ccd6e10a702d7ac84398e33b642c254c1efe5182a43c73d0e91c714684.jpg)  

# 4.1.4SDN的基本概念  

网络层的主要任务是转发和路由选择。可以将网络层抽象地划分为数据平面（也称转发层面）和控制平面，转发是数据平面实现的功能，而路由选择是控制平面实现的功能。  

软件定义网络（SoftwareDefinedNetwork，SDN）是近年流行的一种创新网络架构，它采用集中式的控制平面和分布式的数据平面，两个平面相互分离，控制平面利用控制-数据接口对数据平面上的路由器进行集中式控制，方便软件来控制网络。传统网络中的路由器既有转发表又有路由选择软件，即既有数据平面又有控制平面。但是在图4.4所示的SDN结构中，路由器都变得简单了，它的路由选择软件都不需要了，因此路由器之间不再相互交换路由信息。在网络的控制平面有一个逻辑上的远程控制器（可由多个服务器组成）。远程控制器掌握各主机和整个网络的状态，为每个分组计算出最佳路由，通过Openflow协议（或其他途径）将转发表（在SDN中称为流表）下发给路由器。路由器的工作很单纯，即收到分组、查找转发表、转发分组。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/8980411f3a345b80986b7d3b5cb90dfa7fc85d40d5af689d3f0e6480ae45beba.jpg)  
图4.4远程控制器确定并分发转发表中的值  

这样，网络又变成集中控制的，而本来互联网是分布式的。SDN并非要把整个互联网都改造成如图4.4所示的集中控制模式，这是不现实的。然而，在某些具体条件下，特别是像一些大型的数据中心之间的广域网，使用SDN模式来建造，就可使网络的运行效率更高。  

>#### pro：SDN的南向接口的定义（2022）  

SDN的可编程性通过为开发者提供强大的编程接口，使得网络具有很好的编程性。对上层应用的开发者，SDN提供的编程接口称为北向接口，北向接口提供了一系列丰富的API，开发者可以在此基础上设计自己的应用，而不必关心底层的硬件细节。SDN控制器和转发设备建立双向会话的接口称为南向接口，通过不同的南向接口协议（如Openflow），SDN控制器就可兼容不同的硬件设备，同时可在设备中实现上层应用的逻辑。SDN控制器集群内部控制器之间的通信接口称为东西向接口，用于增强整个控制平面的可靠性和可拓展性。  

SDN的优点： $\textcircled{\scriptsize{1}}$ 全局集中式控制和分布式高速转发，既利于控制平面的全局优化，又利于高性能的网络转发。 $\circledcirc$ 灵活可编程与性能的平衡，控制和转发功能分离后，使得网络可以由专有的自动化工具以编程方式配置。 $\textcircled{3}$ 降低成本，控制和数据平面分离后，尤其是在使用开放的接口协议后，就实现了网络设备的制造与功能软件的并发相分离，从而有效降低了成本。  

SDN的问题： $\textcircled{\scriptsize{1}}$ 安全风险，集中管理容易受攻击，若崩溃，则整个网络会受到影响。 $\circledcirc$ 瓶颈问题，原本分布式的控制平面集中化后，随着网络规模扩大，控制器可能成为网络性能的瓶颈。  

# 4.1.5拥塞控制  

因出现过量的分组而引起网络性能下降的现象称为拥塞。判断网络是否进入拥塞状态的方法是，观察网络的吞吐量与网络负载的关系：若随着网络负载的增加，网络的吞吐量明显小于正常的吞吐量，则网络就可能已进入轻度拥塞状态；若网络的吞吐量随着网络负载的增大而下降，则网络就可能已进入拥塞状态。拥塞控制主要解决的问题是如何获取网络中发生拥塞的信息，从而利用这些信息进行控制，以避免因拥塞而出现分组的丢失。  
拥塞控制的作用是确保网络能够承载所达到的流量，这是一个全局性的过程，涉及网络中所有的主机、路由器及导致网络传输能力下降的所有因素。单一地增加资源并不能解决拥塞。  

与流量控制的区别：流量控制往往是指在发送方和接收方之间的点对点通信量的控制。流量控制所要做的是抑制发送方发送数据的速率，以便使接收方来得及接收。  

拥塞控制的方法有两种：  

1）开环控制。在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。这是一种静态的预防方法。一旦整个系统启动并运行，中途就不再需要修改。开环控制手段包括确定何时可接收新流量、何时可丢弃分组及丢弃哪些分组，确定何利调度策略等。所有这些手段的共性是，在做决定时不考虑当前网络的状态。  

2）闭环控制。事先不考虑有关发生拥塞的各种因素，采用监测网络系统去监视，及时检测哪里发生了拥塞，然后将拥塞信息传到合适的地方，以便调整网络系统的运行，并解决出现的问题。闭环控制是基于反馈环路的概念，是一种动态的方法。  
 

# 4.2 IPv4  

4.2.1IPv4分组  

IPv4（版本4）即现在普遍使用的网际协议（IntemetProtocol，IP）。IP定义数据传送的基本单元一一IP分组及其确切的数据格式。IP也包括一套规则，指明分组如何处理、错误怎样控制。特别是IP还包含非可靠投递的思想，以及与此关联的路由选择的思想。  

# 1.IPv4分组的格式  

>#### pro：IP首部的分析/各字段的含义（2011、2012）  

一个IP分组（或称IP数据报）由首部和数据部分组成。首部前一部分的长度固定，共20B，是所有IP分组必须具有的。在首部固定部分的后面是一些可选字段，其长度可变，用来提供错误检测及安全等机制。IP数据报的格式如图4.5所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/83f7bc75378b06ceb46c21f71b64717714580f6ea9f486f61f4aca59abefe7d7.jpg)  
图4.5IP数据报的格式  

IPv4首部的部分重要字段含义如下：  

1）版本。占4位。指IP的版本，IPv4数据报中该字段值是4。  

2）首部长度。占4位。以4B为单位，最大可表示的首部长度为60B（ $15\!\times\!4\mathrm{B}$ ）。最常用的首部长度是20B（ $5{\times}4\mathrm{B}$ ），该字段值是5，此时不使用任何可选字段。  

# 注意  

IP首部前两个字节往往以0x45开头，解题时可用于定位IP数据报的开始位置。  

3）总长度。占16位。指首部和数据之和的长度，单位为字节，因此数据报的最大长度为 $2^{16}\!-\!1\!=\!65535\mathrm{B}$ 。以太网帧的最大传送单元（MTU）为1500B，因此当一个IP数据报封装成  
硕时，数据报的总长度（首部加数据）一定不能超过下面的数据链路层的MTU值  

4）标识。占16位。它是一个计数器，每产生一个数据报就加1，并赋值给标识字段。但它并不是“序号”（因为IP是无连接服务）。当一个数据报的长度超过网络的MTU时，必须分片，此时每个数据报片都复制一次标识号，以便能正确地重装成原来的数据报。  

5）标志（Flag）。占3位。标志字段的最低位为MF， ${\mathrm{MF}}\!=\!1$ 表示后面还有分片， ${\mathrm{MF}}\!=\!0$ 表示最后一个分片。标志字段中间的一位是DF，只有当 $\ensuremath{\mathrm{DF}}\!=\!0$ 时才允许分片。  

6）片偏移。占13位。它指出较长的数据报在分片后，某片在原数据报中的相对位置，片偏移以8B为偏移单位。除最后一个分片外，每个分片的长度一定是8B的整数倍。  

>#### pro：TTL的计算（2014）  

7）生存时间（TTL）。占8位。数据报在网络中可通过的路由器数的最大值，标识数据报在网络中的寿命，以确保数据报不会永远在网络中循环。路由器在转发数据报前，先将TTL减1。若TTL被减为0，则该数据报必须去弃。  

8）协议。占8位。指出此数据报携带的数据使用何种协议，即数据报的数据部分应上交给哪个协议进行处理，如TCP、UDP等。其中值为6表示TCP，值为17表示UDP。  

9）首部检验和。占16位。它只检验数据报的首部，但不包括数据部分。这是因为数据报每经过一个路由器，都要重新计算首部检验和（有些字段，如生存时间、总长度、标志、片偏移、源/目的地址都可能发生变化）。不检验数据部分可减少计算的工作量。  

10）源地址字段。占4B，标识发送方的IP地址。11）目的地址字段。占4B，标识接收方的IP地址。  

# 注意  

$\textcircled{\scriptsize{1}}$ 在IP数据报首部中有三个关于长度的标记，即首部长度、总长度、片偏移，它们的基本单位分别为4B、1B、8B（需要记住）。题中常出现这几个长度之间的加减运算。另外，读者要熟悉IP数据报首部中的各个字段的意义和功能，但不需要记忆IP数据报的首部，正常情况下若需要参考首部，则题目会直接给出。第5章学习的TCP、UDP的首部也是一样的。 $\textcircled{2}$ 在分析IP首部时，IP地址通常是用十六进制表示的，要注意其与十进制之间的转换。  

# 2.IP数据报分片  

一个链路层数据帧能承载的最大数据量称为最大传送单元（MTU)。因为IP数据报被封装在链路层的顿中，因此链路层的MTU严格地限制了IP数据报的长度，而且在IP数据报的源与目的地路径上的各段链路可能使用不同的链路层协议，有不同的MTU。例如，以太网的MTU为1500B，而许多广域网的MTU不超过576B。当IP数据报的总长度大于链路MTU时，就需要将IP数据报中的数据分装在多个较小的IP数据报中，这些较小的数据报称为片。  

>#### pro：分片时会影响首部中的哪些字段（2011）  

片在目的地的网络层被重新组装。目的主机使用IP首部中的标识、标志和片偏移字段来完成对片的重组。创建一个IP数据报时，源主机为该数据报加上一个标识号。当一个路由器需要将一个数据报分片时，形成的每个数据报（即片）都具有原始数据报的标识号。当目的主机收到来自同一发送主机的一批数据报时，它可通过检查数据报的标识号来确定哪些数据报属于同一个原始数据报的片。IP首部中的标志位占3位，但只有后2位有意义，分别是DF（Don'tFragment)位和MF（More Fragment）位。只有当 $\ensuremath{\mathrm{DF}}\!=\!0$ 时，该IP数据报才可被分片。MF则用来告知目的主机该IP数据报是否为原始数据报的最后一个片。当 ${\mathrm{MF}}=1$ 时，表示相应的原始数据报还有后续的片；当 ${\mathrm{MF}}\!=\!0$ 时，表示该数据报是相应原始数据报的最后一个片。自的主机在对片进行重组时，使用片偏移字段来确定片应放在原始IP数据报的哪个位置。  
>#### pro：IP分片的原理及相关字段的分析（2021）  

IP分片涉及一定的计算。例如，一个长4000B的IP数据报（首部20B，数据部分3980B）到达一个路由器，需要转发到一条MTU为1500B的链路上。这意味着原始数据报中的3980B数据必须分配到3个独立的片中（每片也是一个IP数据报），每片的数据部分依次为1480B、1480B和1020B。假定原始数据报的标识号为777，则分成的3片如图4.6所示。可见，因为偏移值的单位是8B，所以除最后一个片外，其他所有片中的数据部分都为8B的倍数。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/626e7ffc8ed5ca7c1f4c45679e7d234b783838316cdd440725a7b9512cb99c27.jpg)  
图4.6IP分片的例子  

# 4.2.2 IPv4地址与NAT  

1.IPv4地址  

IP地址是给互联网上的每台主机（或路由器）的每个接口分配的一个在全球范围内唯一的32位标识符。IP地址由互联网名字和数字分配机构ICANN进行分配。  

互联网早期采用的是分类的IP地址，如图4.7所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f2e278ae9a152d96978ffc45243b7b127a36a1cce3578e4c25be1b688bd910d2.jpg)  
图4.7分类的IP地址  

无论哪类IP地址，都由网络号和主机号两部分组成。即IP地址：： $=$ {<网络号>，<主机号>}。其中网络号标志主机（或路由器）所连接到的网络。一个网络号在整个互联网范围内必须是唯一的。主机号标志该主机（或路由器）。一台主机号在它前面的网络号所指明的网络范围内必须是唯一的。由此可见，一个IP地址在整个互联网范围内是唯一的。  

>#### pro：特殊IP地址0.0.0.0的用途（2017）  

在各类IP地址中，有些IP地址具有特殊用途，不用作主机的IP地址：  
主机号全为0表示本网络本身，如202.98.174.0。主机号全为1表示本网络的广播地址，又称直接广播地址，如202.98.174.255。 $127.\times.\times.\times$ 保留为环回自检（LoopbackTest）地址，此地址表示任意主机本身，目的地址为环回地址的IP数据报永远不会出现在任何网络上。32位全为0，即0.0.0.0表示本网络上的本主机。32位全为1，即255.255.255.255表示整个TCP/P网络的广播地址，又称受限广播地址。实际使用时，因为路由器对广播域的隔离，255.255.255.255等效为本网络的广播地址。常用的三种类别IP地址的使用范围见表4.2。  

表4.2常用的三种类别IP地址的使用范围
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/8e5f99e160787c8b792c1180313a4d2d4e023d0e54160b7414f055ff18773b94.jpg)  

在表4.2中，A类地址可用的网络数为 $2^{7}\!-\!2$ ，减2的原因是：第一，网络号字段全为0的IP地址是保留地址，意思是“本网络"；第二，网络号为127的IP地址是环回自检地址。  

IP地址有以下重要特点：  

1）每个IP地址都由网络号和主机号两部分组成，因此IP地址是一种分等级的地址结构。分等级的好处是： $\textcircled{\scriptsize{1}}$ 地址管理机构在分配ITP地址时只分配网络号，而主机号则由得到该网络的单位自行分配，方便了IP地址的管理： $\textcircled{2}$ 路由器仅根据目的主机所连接的网络号来转发分组（而不考虑目标主机号），从而减小了路由表所占的存储空间。  

2）IP地址是标志一台主机（或路由器）和一条链路的接口。当一台主机同时连接到两个网络时，该主机就必须同时具有两个相应的IP地址，其网络号必须是不同的。因此路由器至少应具有两个或两个以上的IP地址，每个端口都有一个不同网络号的IP地址。  

3）用转发器或桥接器（网桥等）连接的若干LAN仍然是同一个网络（同一个广播域），因此该LAN中所有主机的IP地址的网络号必须相同，但主机号必须不同。  

4）在IP地址中，所有分配到网络号的网络（无论是LAN还是WAN）都是平等的。5）在同一个局域网上的主机或路由器接口的IP地址中的网络号必须是相同的。近年来，因为广泛使用无分类IP地址进行路由选择，这种传统分类的IP地址已成为历史。  

# 2.网络地址转换（NAT）  

网络地址转换（Network Address Translation，NAT）（如Intranet）转换为公用地址（如Intermet），从而对外隐藏内部管理的IP地址。它使得整个专用网只需要一个全球IP地址就可与互联网连通，因为专用网本地IP地址是可重用的，所以NAT大大节省了IP地址的消耗。同时，它隐藏了内部网络结构，从而降低了内部网络受到攻击的风险。  

>#### pro：私有IP地址访问Internet的处理（2011）  

此外，为了网络安全，划出了部分IP地址为私有IP地址。私有IP地址只用于LAN，不用于WAN连接（因此私有IP地址不能直接用于Intermet，必须通过网关利用NAT把私有IP地址转换为Intermet中合法的全球IP地址后才能出现在Internet上），并且允许私有IP地址被LAN重复使用。这有效地解决了IP地址不足的问题。私有IP地址网段如下：  
A类：1个A类网段，即 $\mathbf{10.0.0.0{\sim}10.255.255.255.}$ B类：16个B类网段，即172.16.0.0\~172.31.255.255。C类：256个C类网段，即192.168.0.0\~192.168.255.255。  

在互联网中的所有路由器，对目的地址是私有地址的数据报一律不进行转发。这种采用私有IP地址的互联网络称为专用互联网或本地互联网。私有IP地址也称可重用地址。  

使用NAT时需要在专用网连接到互联网的路由器上安装NAT软件，NAT路由器至少有一个有效的外部全球IP地址。当使用本地地址的主机和外界通信时，NAT路由器使用NAT转换表进行本地IP地址和全球IP地址的转换。NAT转换表中存放着{本地IP地址：端口}到{全球IP地址：端口}的映射。通过这种映射方式，可让多个私有IP地址映射到一个全球IP地址。  

>#### pro：NAT的原理和应用（2016、2019、2020、2023）  

如图4.8所示，假设某家庭办理了10Mb/s的电信宽带，那么该家庭就获得一个全球IP地址（如138.76.29.7），而家庭网络内3台主机使用私有地址（如10.0.0.0网段），家庭网关路由器应开启NAT功能。NAT路由器的工作原理： $\textcircled{\scriptsize{1}}$ 假设用户主机10.0.0.1（随机端口3345）向Web服务器128.119.40.186（端口80）发送请求。 $\circledcirc$ NAT路由器收到IP分组后，为该IP分组生成一个新端口号5001，将IP分组的源地址改为138.76.29.7（即NAT路由器的全球IP地址），将源端口号改为5001。NAT路由器在NAT转换表中增加一个表项。 $\textcircled{3}$ Web服务器并不知道刚抵达的IP分组已被NAT路由器改装，更不知道用户的专用地址，它响应的IP分组的自的地址是NAT路由器的全球IP地址138.76.29.7，目的端口号是5001。 $\textcircled{4}$ 响应分组到达NAT路由器后，通过NAT转换表将IP分组的目的IP地址改为10.0.0.1，将目的端口号改为3345。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/e02ffb33271e0f0ef1690c1d80df4b45778e6944f11d8a56baafaeed794a29f0.jpg)  
图4.8NAT路由器的工作原理  

这样，只需要一个全球IP地址，就可让多台主机同时访问互联网。  

# 注意  

普通路由器在转发IP分组时，其源IP地址和目的IP地址都不会改变。而NAT路由器在转发IP分组时，一定要更换其IP地址（转换源IP地址或目的IP地址）。普通路由器仅工作在网络层，而NAT路由器转发数据报时需要查看和转换传输层的端口号。  
# 4.2.3划分子网与路由聚合  

# 1.划分子网  

两级IP地址的缺点：IP地址空间的利用率有时很低：给每个物理网络分配一个网络号会使路由表变得太大，进而使网络性能变坏；两级IP地址不够灵活。  

从1985年起，在IP地址中又增加了一个“子网号字段”，使两级IP地址变成了三级IP地址。这种做法称为划分子网。划分子网已成为互联网的正式标准协议。  

划分子网的基本思路如下：  

划分子网纯属一个单位内部的事情。单位对外仍然表现为没有划分子网的一个网络，划分子网的方法是从网络的主机号借用若干位作为子网号，当然主机号也相应减少了相同的位数。三级IP地址的结构：IP地址： $=$ {<网络号>，<子网号>，<主机号>}。路由器转发分组根据的仍然是IP数据报的目的网络号，本单位的路由器收到TP数据报后，再按目的网络号和子网号找到目的子网。最后把IP数据报交付给目的主机。  

例如，将一个C类网络208.115.21.0划分为4个子网，子网号占用2位，因此主机号就只有6位，各子网的网络地址分别为208.115.21.0、208.115.21.64、208.115.21.128、208.115.21.192。每个子网可分配的IP地址数为 $2^{6}{-}2{=}62$  

# 注意  

$\textcircled{\scriptsize{1}}$ 划分子网只是把IP地址的主机号部分进行再划分，而不改变IP地址原来的网络号。因此，从一个ⅡP地址本身无法判断该主机所连接的网络是否进行了子网划分。 $\textcircled{2}$ 子网中的主机号全0或全1的地址不能被指派，其中主机号全0的地址为子网的网络地址，主机号全1的地址为子网的广播地址。 $\textcircled{3}$ 划分子网增加了灵活性，但减少了能够连接在网络上的主机总数。  

# 2.子网掩码和默认网关  

子网掩码可用来指明分类IP地址的主机号部分被借用了多少位作为子网号。命题追踪根据IP地址和子网掩码求网络地址（2022）  

子网掩码是一个与IP地址相对应的、长32位的二进制串，它由一串1和跟随的一串0组成。其中，1对应于IP地址中的网络号及子网号，而0对应于主机号。主机或路由器只需将IP地址和其对应的子网掩码逐位“与”（AND运算），就可得出相应子网的网络地址。  

>#### pro：默认网关配置错误对访问局域网和跨网访问的影响（2015）  

>#### pro：默认网关和子网掩码的配置分析（2016、2019、2022）  

默认网关是子网与外部网络连接的设备，也就是连接本机或子网的路由器接口的IP地址。当主机发送数据时，根据所发送数据的目的IP地址，通过子网掩码来判定目的主机是否在子网中，若自的主机在子网中，则直接发送。若目的主机不在子网中，则将该数据发送到默认网关，由网关（路由器）将其转发到其他网络，进一步寻找目的主机。  

现在的互联网标准规定：所有网络都必须使用子网掩码。若一个网络未划分子网，则该网络的子网掩码就使用默认子网掩码。A、B、C类地址的默认子网掩码分别为255.0.0.0、255.255.0.0、255.255.255.0。例如，某主机的1P地址为192.168.5.56，子网掩码为255.255.255.0，进行逐位“与”运算后，得出该主机所在子网的网络号为192.168.5.0。  

子网掩码是一个网络的重要属性，路由器相互之间交换路由信息时，必须将自己所在网络的子网掩码告诉对方。分组转发时，路由器将分组的自标地址和某网络的子网掩码按位相与，若结果与该网络地址一致，则路面匹配成功，路由器将分组转发至该网络。  
在使用子网掩码的情况下：  

$\textcircled{\scriptsize{1}}$ 一台主机在设置IP地址信息的同时，必须设置子网掩码。 $\circledcirc$ 同属于一个子网的所有主机及路由器的相应端口，必须设置相同的子网掩码。 $\textcircled{3}$ 路由器的路由表中所包含的信息主要内容有目的网络地址、子网掩码、下一跳地址。  

# 3.无分类编址CIDR  

无分类域间路由选择（Classless Inter-Domain Routing，CIDR），提出的一种消除传统A、B、C类地址及划分子网的概念。例如，若一个单位需要2000个地址，则给它分配一个2048地址的块，而不分配一个完全的B类地址，因此可更有效地分配IPv4的地址空间。CIDR使用网络前缀的概念代替网络的概念，与传统分类IP地址最大的区别就是，网络前缀的位数不是固定的，可以任意选取。CIDR的记法是  

IP地址： $=$ {<网络前缀>，<主机号>}。  

>#### pro：CIDR地址块的分析（2011、2015、2016、2019、2023）  

CIDR还使用斜线记法（或称CIDR记法），即记为“TP地址/网络前缀所占的位数”。其中，网络前缀所占的位数对应网络号的部分，等效于子网掩码中连续1的部分。例如，对于128.14.32.5/20这个地址，它的掩码是20个连续的1和后续12个连续的0，通过逐位“与”的方法可得该地址的网络前缀（或直接截取前20位）：  

IP=10000000.00001110.00100000.00000101 逐位与 掩码  $=$  11111111.11111111.11110000.00000000 网络前缀 $=$ 10000000.00001110.00100000.00000000(128.14.32.0)  

斜线记法不仅能表示其IP地址，而且能表示这个地址块的网络前缀有多少位。  

>#### pro：地址块的最小地址和最大地址分析（2023）  

CIDR将网络前缀都相同的连续IP地址组成一个CIDR地址块。只要知道CIDR地址块中的任何一个地址，就能知道这个地址块的最小地址和最大地址，以及地址块中的地址数。上例的地址128.14.32.5/20所在CIDR地址块中的最小地址和最大地址为  

最小地址：10000000.00001110.00100000.00000000（128.14.32.0）最大地址：10000000.00001110.00101111.11111111（128.14.47.255）  

主机号全0或全1的地址一般不使用，通常只使用在这两个特殊地址之间的地址。  

CIDR虽然不使用子网，但仍然使用“掩码”一词。“CIDR不使用子网”是指CIDR并没有在32位地址中指明若干位作为子网字段。但分配到一个CIDR地址块的单位，仍可在本单位内根据需要划分出一些子网。例如，某单位分配到地址块/20，就可继续划分为8个子网（从主机号中借用3位来划分子网），这时每个子网的网络前缀就变成了23位。  

>#### pro：子网广播地址/网络地址的分析（2011、2012、2018、2019）  

CIDR地址块中的地址数一定是2的整数次幂，实际可指派的地址数通常为 $2^{N}\!-\!2$  $N$ 表示主机号的位数，主机号全0代表网络号，主机号全1为广播地址。网络前缀越短，其地址块包含的地址数就越多。而在三级结构的IP地址中，划分子网使网络前缀变长。  
# 4.路由聚合  

因为一个CIDR地址块中有很多地址，所以在路由表中就可利用CIDR地址块来查找目的网络。这种地址的聚合称为路由聚合，也称构成超网，它使得路由表中的一个项自可以表示多个原来传统分类地址的路由，有利于减少路由器之间的信息交换，进而提高网络性能。  

>#### pro：路由聚合的分析（2009、2011、2013、2014、2018）  

例如，在如图4.9所示的网络中，若不使用路由聚合，则R1的路由表中需要分别有到网络1和网络2的路由表项。不难发现，网络1和网络2的网络前缀在二进制表示的情况下，前16位都是相同的，第17位分别是0和1，并且从R1到网络1和网络2的路由的下一跳皆为R2。若使用路由聚合，则在R1看来，网络1和网络2可以构成一个更大的地址块206.1.0.0/16，到网络1和网络2的两条路由就可聚合成一条到206.1.0.0/16的路由。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/3c327d3febd0959034937d5135371eb34698ee1d81aeb0c0a097b58a53585744.jpg)  
图4.9路由聚合的例子  

>#### pro：路由器分组转发的最长前缀匹配（2013、2015）  

最长前缀匹配（又称最佳匹配）：使用CIDR时，路由表中的个项由“网络前缀”和“下一跳地址”组成。在查找路由表时可能会得到不止一个匹配结果。此时，应当从匹配结果中选择具有最长网络前缀的路由，因为网络前缀越长，其地址块就越小，因此路由就越具体。  

CIDR查找路由表的方法：为了更有效地查找最长前缀匹配，通常将无分类编址的路由表存放在一种层次式数据结构（通常采用二叉线索）中，然后自上而下地按层次进行查找。  

CIDR的优点在于网络前缀长度的灵活性。因为上层网络的前缀长度较短，所以相应的路由表的项目较少。而内部又可采用延长网络前缀的方法来灵活地划分子网。  

# 5.子网划分的应用举例  

通常有两类划分子网的方法：采用定长的子网掩码，采用变长的子网掩码。  

（1）采用定长的子网掩码划分子网  

当采用定长的子网掩码划分子网时，所划分的每个子网使用相同的子网掩码，并且每个子网所分配的IP地址数量也相同，因此容易造成地址资源的浪费。  

>#### pro：采用定长子网掩码划分子网的应用（2009、2010、2017、2018）  

假设某单位拥有一个CIDR地址块为208.115.21.0/24，该单位有三个部门，各部门的主机台数分别为50、20、5，采用定长的子网掩码给各部门分配IP地址。  

部门1需要51个IP地址（含一个路由器接口地址）；部门2需要21个IP地址；部门3需要6个IP地址。接下来，从给定地址块208.115.21.0/24的主机号部分借用2位作为子网号，这样可以划分为 $2^{2}{=}4$ 个子网，每个子网可分配的IP地址数为 $2^{8-2}{-}2\!=\!62$ ，可满足各部门的需求。各子网的划分如下（为书写方便，只把IP地址的后8位用二进制展开）：  

208.115.21.00000000～208.115.21.00111111，地址块“208.115.21.0/26”，分配给部门1。208.115.21.01000000\~208.115.21.01111111，地址块“208.115.21.64/26”，分配给部门2。208.115.21.10000000\~208.115.21.10111111，地址块“208.115.21.128/26”，分配给部门3。  
208.115.21.11000000\~208.115.21.11111111，地址块“208.115.21.192/26”，留作以后用。子网掩码：255.255.255.1100000，即255.255.255.192。（2）采用变长的子网掩码划分子网  

命题追踪采用变长子网掩码划分子网的应用（2019、2021）  

采用变长的子网掩码划分子网时，所划分的每个子网可以使用不同的子网掩码，并且每个子网所分配的IP地址数量可以不同，这样就尽可能地减少了对地址资源的浪费。  

假设各种条件与上一节的相同，下面采用变长的子网掩码给该单位分配DP地址。  

部门1的主机号需6位，剩余26（ $(32-6=26\$ ）位作为网络前缀；部门2的主机号需5位，剩余27（ $32-5=27)$ ）位作为网络前缀；部门3的主机号需3位，剩余29 $(32-3=29\$ ）位作为网络前缀。接下来，从地址块 $208.115.21.0/24$ 中划分出3个子网（1个“/26”地址块，1个“727”地址块，1个“/29”地址块），并按需分配给三个部门。每个子网的最小地址只能选取主机号全0的地址。划分方案不唯一，建议从大的子网开始划分。以下是一种划分方案：  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/ac44667c05deef529ea237a5beaa962fc08414413a27f237c11d6473ec294d88.jpg)  

再次提醒，子网主机号全0或全1的地址不能分配。对于一段连接两个路由器的链路，可以分配一个“730”地址块，这样可分配地址为2个，恰好可分配给链路两端的路由器接口。  

# 4.2.4网络层转发分组的过程  

分组转发都是基于目的主机所在网络的，这是因为互联网上的网络数远小于主机数，这样可以极大地压缩转发表的大小。当分组到达路由器后，路由器根据目的IP地址的网络前缀来查找转发表，确定下一跳应当到哪个路由器。因此，在转发表中，每条路由必须有下面两条信息：  

（目的网络地址，下一跳地址）  

这样，IP数据报最终一定可以找到目的主机所在目的网络上的路由器（可能要通过多次间接交付），当到达最后一个路由器时，才试图向目的主机进行直接交付。  

采用CIDR编址时，若一个分组在转发表中可以找到多个匹配的前缀，则应当使用最长前缀匹配。为了更快地查找转发表，可以按照前缀的长短，将前缀最长的排在第1行，按前缀长度的降序排列。这样，从第1行最长的开始查找，只要检索到匹配的，就不必再继续查找。  

此外，在路由表中还可以增加两种特殊的路由：  

>#### pro：特定主机路由的应用（2009）  

1）特定主机路由：对特定目的主机的IP地址专门指明一个路由，以方便网络管理员控制和  
测试网络。若特定主机的IP地址是a.b.c.d，则转发表中对应项的目的网络是a.b.c.d/32。/32表示的子网掩码没有意义，但这个特殊的前缀可以用在转发表中。  

>#### pro：默认路由的应用（2009、2014）  

2）默认路由：用特殊前缀0.0.0.0/0表示默认路由，全0掩码和任何目的地址进行按位与运算，结果必然为全0，即必然和前缀 $0.0.0.0/0$ 相匹配。只要目的网络是其他网络（不在转发表中），就一律选择默认路由。默认路由通常用于路由器到互联网的路由，互联网包括无数的网络集合，不可能在路由表项中一一列出，因此只能采用默认路由的方式。  

综上所述，归纳出路由器执行的分组转发算法如下：1）从收到的IP分组的首部提取目的主机的IP地址 $D$ （即目的地址）。  

2）若查找到特定主机路由（目的地址为 $D$ ），则按照这条路由的下一跳转发分组；否则从转发表中的下一条（即按前缀长度的顺序）开始检查，执行步骤3）。  

3）将这一行的子网掩码与目的地址 $D$ 逐位“与”（AND操作）。若运算结果与本行的前缀匹配，则查找结束，按照“下一跳”指出的进行处理（或者直接交付本网络上的目的主机，或通过指定接口发送到下一跳路由器）。否则，若转发表还有下一行，则对下一行进行检查，重新执行步骤3）。否则，执行步骤4）。  

4）若转发表中有一个默认路由，则把分组传送给默认路由；否则，报告转发分组出错。  

值得注意的是，转发表（或路由表）并没有给分组指明到某个网络的完整路径（即先经过哪个路由器，然后经过哪个路由器等）。转发表指出，到某个网络应当先到某个路由器（即下一跳路由器），到达下一跳路由器后，再继续查找其转发表，知道再下一步应当到哪个路由器。这样一步一步地查找下去，直到最后到达目的网络。  

# 注意  

得到下一跳路由器的IP地址后，并不是直接将该地址填入待发送的数据报，而是将该IP地址转换成MAC地址（通过ARP），将此MAC地址填入MAC帧首部，然后根据这个MAC地址找到下一跳路由器。在不同网络中传送时，MAC帧的源地址和目的地址要发生变化。  

# 4.2.5地址解析协议 （ARP)  

# 1.IP地址与硬件地址  

IP地址是网络层及网络层之上使用的地址，它是分层式的。硬件地址（MAC地址）是数据链路层使用的地址，它是平面式的。IP地址放在IP数据报的首部，而MAC地址放在MAC帧的首部。把IP数据报封装为MAC帧后，数据链路层看不见IP数据报中的IP地址。  

因为路由器的隔离，IP网络中无法通过广播MAC地址来完成跨网络的寻址，所以在网络层只使用IP地址来完成寻址。寻址时，每个路由器依据其路由表（依靠路由协议生成）选择到目标网络（即主机号全为0的网络地址）需要转发到的下一跳（路由器的物理端口号或下一网络地址），而IP数据报通过多次路由转发到达自标网络后，改为在自标局域网中通过数据链路层的MAC地址以广播方式寻址。这样可以提高路由选择的效率。  

下列几个性质是计算机网络的精髓，有必要特别强调：  

1）在IP层抽象的互联网上只能看到IP数据报。2）虽然在IP数据报首部中有源IP地址，但路由器只根据目的IP地址进行转发。3）在局域网的链路层，只能看见MAC帧。IP数据报被封装在MAC帧中。通过路由器转发  
时，IP数据报在每个网络中都被路由器解封装和重新封装，其MAC帧首部中的源地址和自的地址会不断改变。这也决定了无法使用MAC地址跨网络通信。  

4）尽管互连在一起的网络的硬件地址体系各不相同，但IP层抽象的互联网却屏蔽了下层这些复杂的细节。只要我们在网络层上讨论问题，就能够使用统一的、抽象的IP地址研究主机与主机或路由器之间的通信。  

# 注意  

路由器因为互连多个网络，所以它不仅有多个IP地址，而且有多个硬件地址。  

# 2.地址解析协议  

>#### pro：  

ARP的功能和应用（2011、2012、2021）  

无论网络层使用什么协议，在实际网络的链路上传送数据顺时，最终必须使用硬件地址。所以需要一种方法来完成IP地址到MAC地址的映射，这就是地址解析协议（AddressResolutionProtocol，ARP）。每台主机都设有一个ARP高速缓存，用来存放本局域网上各主机和路由器的IP地址到MAC地址的映射表，称ARP表。使用ARP来动态维护ARP表。  

>#### pro：ARP请求帧的目的MAC地址（2011、2015）  

ARP工作在网络层，其工作原理如下：主机A欲向本局域网上的某台主机B发送IP数据报时，先在其ARP高速缓存中查看有无主机B的IP地址。若有，则可以查出其对应的硬件地址，再将此硬件地址写入MAC帧，然后通过局域网将该MAC帧发往此硬件地址。若没有，则通过使用目的MAC地址为FF-FF-FF-FF-FF-FF的帧来封装并广播ARP请求分组（广播发送），使同一个局域网里的所有主机都收到此ARP请求。主机B收到该ARP请求后，向主机A发出ARP响应分组（单播发送），分组中包含主机B的IP地址与MAC地址的映射关系，主机A收到ARP响应分组后就将此映射写入ARP缓存，然后按查询到的硬件地址发送MAC帧。ARP因为“看到了”IP地址，所以它工作在网络层，而NAT路由器因为“看到了”端口，所以它工作在传输层。对于某个协议工作在哪个层次，读者应该能通过协议的工作原理进行推测。  

# 注意  

ARP用于解决同一局域网上的主机或路由器的IP地址和硬件地址的映射问题。若目的主机和源主机不在同一个局域网上，则要通过ARP找到本局域网上的某个路由器的硬件地址，然后把分组发送给这个路由器，让这个路由器把分组转发给下一个网络，剩下的工作就由下一个网络来做。尽管ARP请求分组是广播发送的，但ARP响应分组是普通的单播。  

使用ARP的4种典型情况总结如下（见图4.10）。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/9a0240a6e9ad5e98a9ca150689311067f19352ad0f9a539c54df2672c931882b.jpg)  
图4.10使用ARP的4种典型情况  

1）发送方是主机（如 $\mathrm{H}_{1}$ )，要把IP分组发送到本网络上的另一台主机（如 $\mathrm{H}_{2}$ )。这时 $\mathrm{H}_{1}$ 在  
网1用ARP找到目的主机 $\mathrm{H}_{2}$ 的硬件地址。  

2）发送方是主机（如 $\mathrm{H}_{1}$ )，要把IP分组发送到其他网络上的一台主机（如 $\mathrm{H}_{4}.$ ）。这时 $\mathrm{H}_{1}$ 用ARP找到与网1连接的路由器 $\mathsf{R}_{1}$ 的硬件地址（默认网关），剩下的工作由 $\mathsf{R}_{1}$ 来完成。  

命题追踪跨局域网的帧的目的MAC地址（2015）  

# 注意  

开始在 $\mathrm{H}_{1}$ 和 $\mathsf{R}_{1}$ 之间传送时，MAC帧首部中的源地址是 $\mathrm{H}_{1}$ 的MAC地址，目的地址是 $\mathrm{L}_{1}$ 的硬件地址，路由器 $\mathsf{R}_{1}$ 收到此MAC帧后，在数据链路层，要丢弃原MAC的首部和尾部。这时首部中的源地址和目的地址分别为 $\mathrm{L}_{2}$ 和 $\mathrm{L}_{3}$ 的MAC地址。路由器 $\mathrm{R}_{2}$ 收到此帧后，再次更换MAC帧的首部和尾部，首部中的源地址和目的地址分别变为 $\mathrm{L}_{4}$ 和 $\mathrm{H}_{4}$ 的MAC地址。MAC顿首部的这种变化，在上面的IP层中是看不见的。  

3）发送方是路由器（如 $\mathsf{R}_{1}$ )，要把IP分组转发到与 $\mathsf{R}_{1}$ 连接的网络（网2）上的一台主机（如 $\mathrm{H}_{3}$ )。这时 $\mathrm{R_{1}}$ 在网2用ARP找到目的主机 $\mathrm{H}_{3}$ 的硬件地址。4）发送方是路由器（如 $\mathsf{R}_{1}$ ），要把IP分组转发到网3上的一台主机（如 $\mathrm{H}_{4}\mathrm{.}$ 。这时 $\mathrm{R_{1}}$ 在网2用ARP找到与网2连接的路由器 $\mathbb{R}_{2}$ 的硬件地址，剩下的工作由 $\mathbb{R}_{2}$ 来完成。从IP地址到硬件地址的解析是自动进行的，主机的用户并不知道这种地址解析过程。只要主机或路由器和本网络上的另一个已知IP地址的主机或路由器进行通信，ARP就自动地将这个IP地址解析为数据链路层所需要的硬件地址。  

# 4.2.6 动态主机配置协议 (DHCP)  

动态主机配置协议（Dynamic Host Configuration Protocol，DHCP） IP地址，它提供了即插即用的连网机制，这种机制允许一台计算机加入新的网络和自动获取IP地址而不用手工参与。DHCP是应用层协议，它是基于UDP的。  

>#### pro：DHCP发现报文的作用（2022）  

DHCP的工作原理如下：使用客户/服务器模型。需要IP地址的主机在启动时就向DHCP服务器广播发送发现报文，这时该主机就成为DHCP客户。本地网络上的所有主机都能收到这个广播报文，但只有DHCP服务器才能回答此广播报文。DHCP服务器先在其数据库中查找该计算机的配置信息。若找到，则返回找到的信息；若找不到，则从服务器的IP地址池中取一个地址分配给该计算机。DHCP服务器的回答报文称为提供报文。  

>#### pro：DHCP发现报文的源地址和目的地址（2015、2022）  

DHCP服务器和DHCP客户的交换过程如下：  

1）DHCP客户广播“DHCP发现”消息，试图找到网络中的DHCP服务器，以便从DHCP服务器获得一个IP地址。源地址为0.0.0.0，目的地址为255.255.255.255。2）DHCP服务器收到“DHCP发现”消息后，广播“DHCP提供”消息，其中包括提供给DHCP客户机的IP地址。源地址为DHCP服务器地址，目的地址为255.255.255.255。3）DHCP客户收到“DHCP提供”消息，若接受该IP地址，则广播“DHCP请求”消息向DHCP服务器请求提供IP地址。源地址为0.0.0.0，目的地址为255.255.255.255。4）DHCP服务器广播“DHCP确认”消息，将IP地址分配给DHCP客户。源地址为DHCP 服务器地址，目的地址为255.255.255.255。  
DHCP允许网络上配置多台DHCP服务器，当DHCP客户发出“DHCP发现”消息时，有可能收到多个应答消息。这时，DHCP客户只会挑选其中的一个，通常挑选最先到达的。  

DHCP服务器分配给DHCP客户的IP地址是临时的，因此DHCP客户只能在一段有限的时间内使用这个分配到的IP地址。DHCP称这段时间为租用期。租用期的数值应由DHCP服务器自己决定，DHCP客户也可在自己发送的报文中提出对租用期的要求。  

DHCP客户和服务器端需要通过广播方式来进行交互，原因是在DHCP执行初期，客户机不知道服务器端的IP地址，而在执行中间，客户机并未被分配IP地址，从而导致两者之间的通信必须采用广播的方式。采用UDP而不采用TCP的原因也很明显：TCP需要建立连接，若连对方的IP地址都不知道，则更不可能通过双方的套接字建立连接。  

DHCP是应用层协议，因为它是通过客户/服务器模式工作的，DHCP客户向DHCP服务器请求服务，而其他层次的协议是没有这两种工作方式的。  

# 4.2.7网际控制报文协议（ICMIP）  

>#### pro：直接为ICMP提供服务的协议（2012）  

为了有效地转发IP数据报和提高交付成功的机会，在网络层使用了网际控制报文协议（Internet Control Message Protocol，ICMP），。ICMP报文被封装在IP数据报中发送，但ICMIP不是高层协议，而是网络层的协议。  

ICMP报文有两种，即ICMP差错报告报文和ICMP询问报文。  

>#### pro：ICMP差错报文的类型及含义（2022）  

ICMIP差错报告报文用于目标主机或到目标主机路径上的路由器，向源主机报告差错和异常情况。共有以下5种常用的类型：  

1）终点不可达。当路由器或主机不能交付数据报时，就向源点发送终点不可达报文。2）源点抑制。当路由器或主机因为拥塞而丢弃数据报时，就向源点发送源点抑制报文，使源点知道应当把数据报的发送速率放慢。3）时间超过。当路由器收到生存时间（TTL）为零的数据报时，除丢弃该数据报外，还要向源点发送时间超过报文。当终点在预先规定的时间内不能收到一个数据报的全部数据报片时，就把已收到的数据报片都丢弃，并向源点发送时间超过报文。4）参数问题。当路由器或目的主机收到的数据报的首部中有的字段的值不正确时，就丢弃该数据报，并向源点发送参数问题报文。5）改变路由（重定向）。路由器把改变路由报文发送给主机，让主机知道下次应将数据报发送给另外的路由器（可通过更好的路由）。  

对于以下几种情况，不应发送ICMIP差错报告报文：1）对ICMP差错报告报文，不再发送ICMP差错报告报文。 2）对第一个分片的数据报片的所有后续数据报片，都不发送ICMIP差错报告报文。  

3）对具有多播地址的数据报，都不发送ICMP差错报告报文。4）对具有特殊地址（如127.0.0.0或0.0.0.0）的数据报，不发送ICMP差错报告报文。  

ICMP询问报文有4种类型：回送请求和回答报文、时间戳请求和回答报文、地址掩码请求和回答报文、路由器询问和通告报文，最常用的是前两类。  
ICMP的两个常见应用是分组网间探测PING（用来测试两台主机之间的连通性）和Traceroute （UNIX中的名字，在Windows中是Tracert，可以用来跟踪分组经过的路由）。其中PING使用了ICMP回送请求和回答报文，Traceroute（Tracert）使用了ICMP时间超过报文。  

# 注意  

PING工作在应用层，I CMP；Traceroute/Tracer t。  

   

# 4.3 IPv6  

4.3.1IPv6的特点  

目前广泛使用的IPv4是在20世纪70年代设计的，互联网经过几十年的飞速发展，到2011年2月，IPv4地址已经耗尽，为了解决“IP地址耗尽”问题，有以下三种措施：  

1）采用无类别编址CIDR，使IP地址的分配更加合理。2）采用网络地址转换（NAT）方法以节省全球IP地址。3）采用具有更大地址空间的新版本的IPv6。前两种方法只是延长了IPv4使用寿命，只有第三种方法能从根本上解决IP地址耗尽问题。  
>#### pro：IPv6的特点（2023）  

IPv6的主要特点如下：  

1）史人时地址工间。这定取里安的。IFV0付地址从IrV4时52位增人到128位，IrV0的地址空间是IPv4的 $2^{128-32}\!=\!2^{96}$ 倍，从长远来看，这些地址是绝对够用的。2）扩展的地址层次结构。IPv6因为地址空间很大，所以可以划分为更多的层次。3）灵活的首部格式。IPv6定义了许多可选的扩展首部，不仅可提供比IPv4更多的功能，而且能提高路由器的处理效率，这是因为路由器对扩展首部不进行处理。IPv4所规定的选项是固定不变的，其选项放在首部的可变部分。6）支持即插即用（即自动配置）。因此IPv6不需要使用DHCP。7）支持资源的预分配。IPv6支持实时音/视频等要求保证一定带宽和时延的应用。8）IPv6只有源主机才能分片，是端到端的，不允许类似IPv4传输路径中的路由分片。9）IPv6首部长度是固定的40B，而IPv4首部长度是可变的（必须是4B的整数倍）。10）增大了安全性。身份鉴别和保密功能是IPv6的扩展首部。  

虽然IPv6与IPv4不兼容，但总体而言它与所有其他的互联网协议兼容，包括TCP、UDP、ICMP、IGMP和DNS等，只是在少数地方做了必要的修改（大部分是为了处理长地址）。  

# 4.3.2IPv6数据报的基本首部  

IPv6数据报由两部分组成：基本首部和有效载荷（也称净负荷）。有效载荷由零个或多个扩展首部（扩展首部不属于IPv6数据报的首部）及其后面的数据部分构成，如图4.11所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f698b67646d9930c64da34e52dc45dad7d35022f8c9f2fdb596f320bf237c685.jpg)  
图4.11具有多个可选扩展首部的IPv6数据报的一般形式  

因为取消了首部中不必要的功能，IPv6基本首部的字段数减少到只有8个，但由于IPv6地址长度为128位，所以IPv6基本首部的长度反而增大到40B，如图4.12所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/03769dd7cc9b50a35c96a4fc7fbf8a9c5757c87a33f21ed45608a52f302efe1f.jpg)  
图4.12IPv6数据报的基本首部的格式  

>#### pro：IPv6基本首部字段的意义（2023）  

下面简单介绍IPv6基本首部中各字段的含义：  
1）版本。占4位，指明协议的版本，对于IPv6该字段的值是6。2）通信量类。占8位，用来区分不同的IPv6数据报的类别或优先级。  

3）流标号。占20位，IPv6提出流的抽象概念。流是指互联网上从特定源点到特定终点（单 播或多播）的一系列数据报（如实时音/视频传输），而在这个“流”所经过的路径上的路由器都保证指明的服务质量。所有属于同一个流的数据报都具有相同的流标号。  

4）有效载荷长度。占16位，指明IPv6数据报除基本首部以外的字节数（所有扩展首部都算在有效载荷之内）。这个字段的最大值是65535（单位为字节）。  

5）下一个首部。占8位，该字段相当于IPv4首部中的协议字段或可选字段。当IPv6没有扩展首部时，其作用与IPv4的协议字段一样，它指明IPv6数据报所运载的数据是何种协议数据单元；当IPv6带有扩展首部时，它就标识后面第一个扩展首部的类型。  

6）跳数限制。占8位，类似于IPv4首部的TTL字段。源点在每个数据报发出时即设定某个限制值（最大为255）。路由器每次转发时将其值减1，减为零时就将该数据报丢弃。  

7）源地址和目的地址。占128位，是数据报的发送端/接收端的IP地址。  

# 4.3.3IPv6地址  

IPv6数据报的目的地址有以下三种基本类型：  

1）单播。就是传统的点对点通信。  

2）多播。一点对多点的通信，数据报发送到一组计算机中的每一台。  

3）任播。这是IPv6增加的一种类型。任播的终点是一组计算机，但数据报只交付其中的一台计算机，通常是距离最近的一台计算机。  

IPv4地址通常使用点分十进制表示法。若IPv6也使用这种表示法，则地址书写起来将相当长。IPv6标准使用冒号十六进制记法，即把地址中的每4位用一个十六进制数表示，并用冒号分隔每16位，如4BF5:AA12:0216:FEBC:BA5F:039A:BE9A：2170。  

当16位域的开头有一些0时，可以采用一种缩写表示法，但在域中必须至少有一个数字。例如，可以把地址4BF5:0000:0000:0000:BA5F:039A:000A:2176缩写为4BF5:0:0:0:BA5F:39A:A:2176。  

当有相继的0值域时，还可以进一步缩写。这些域可用双冒号缩写（：）。当然，双冒号表示法在一个地址中仅能出现一次，因为0值域的个数没有编码，需要从指定的总的域的个数来推算。这样一来，前述地址可被更紧凑地书写成4BF5:BA5F:39A:A：2176。  

IPv6地址的分类如表4.3所示。  

表4.3IPv6地址的分类
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/471fef216dc17fd584cc9b372fa479feea53d81138258a20d51f969078e66308.jpg)  

对表4.3给出的五类地址简单解释如下：  

1）未指明地址：该地址不能用作目的地址，只能用于还未配置IPv6地址的主机作为源地址。  

2）环回地址：该地址的作用与IPv4的环回地址相同，但IPv6的环回地址仅此一个。  

3）多播地址：该地址的作用和IPv4的一样。这类地址占IPv6地址空间的1/256。  
4）本地链路单播地址：该地址的作用类似于 $\mathrm{IPv4}$ 的私有IP地址。  

5）全球单播地址：用得最多的地址。IPv6全球单播地址采用下图所示的三级结构：第一级为全球路由选择前缀，占48位，用于互联网中的路由选择，相当于IPv4分类地址中的网络号；第二级为子网标识符，占16位，用于各机构构建自己的子网：第三级为接口标识符，用于指明主机或路由器的单个网络接口，相当于IPv4分类地址中的主机号。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/2b339deff31fff0c110cdba987c1a5abd5ca2b0abcb54b14675383edc6b3882a.jpg)  

与IPv4不同，IPv6地址的接口标识符有64位之多，足以对各种接口的硬件地址直接进行编码。这样，IPv6就可直接从128位地址的最后64位中直接提取出相应的硬件地址，而不需要使用地址解析协议（ARP）进行地址解析。  

# 4.3.4 IPv 4 IPv 6  

从IPv4向IPv6过渡只能采用逐步演进的办法，同时还必须使新安装的IPv6系统能够向后兼容。IPv6系统必须能够接收和转发IPv4分组，并且能够为IPv4分组选择路由。  

>#### pro：IPv4向IPv6过渡的策略（2023）  

从IPv4向IPv6过渡可以采用下列两种策略：  

1）双协议栈，是指在一台设备上同时装有IPv4和IPv6两个协议栈，分别配置了一个IPv4地址和一个IPv6地址，因此这台设备既能和IPv4网络通信，又能和IPv6网络通信。双协议栈主机在与IPv6主机通信时采用IPv6地址，而在与IPv4主机通信时采用IPv4地址，双协议栈主机使用应用层的域名系统（DNS）获知目的主机采用的是哪种地址。若DNS返回的是IPv4地址，则双协议的源主机就使用IPv4地址。若DNS返回的是IPv6地址，则双协议栈的源主机就使用IPv6地址。  

2）隧道技术，是指在IPv6数据报要进入IPv4网络时，把整个IPv6数据报封装成IPv4数据报的数据部分，使原来的IPv6数据报就好像在IPv4网络的隧道中传输。当IPv4数据报离开IPv4网络时，再将其数据部分交给主机的IPv6协议。  


# 4.4路由算法与路由协议  

# 4.4.1路由算法  

路由选择协议的核心是路由算法，即需要何种算法来获得路由表中的各个项目。路由算法的目的很简单：给定一组路由器及连接路由器的链路，路由算法要找到一条从源路由器到目的路由 器的“最佳”路径。通常，“最佳”路径是指具有最低费用的路径。  

# 1.静态路由与动态路由  

路由器转发分组是通过路由表转发的，而路由表是通过各种算法得到的。从能否随网络的通信量或拓扑自适应地进行调整变化来划分，路由算法可以分为如下两大类。  

1）静态路由算法。指由网络管理员手工配置每一条路由。2）动态路由算法。根据网络流量负载和拓扑结构的变化来动态调整自身的路由表。  

静态路由算法的特点是简单和开销较小，但不能及时适应网络状态的变化，适用于简单的小型网络。动态路由算法能较好地适应网络状态的变化，但实现复杂，开销也大，适用于较复杂的大网络。常用的动态路由算法可分为两类：距离-向量路由算法和链路状态路由算法。  

# 2.距离-向量路由算法  

距离-向量算法的基础是Belliman-Ford算法，它用于计算单源最短路径。每个结点以自身为源点执行Bellman-Ford算法，所以全局上可以解决任意结点对之间的最短路径问题。  

下面讨论Bellman-Ford算法的基本思想。  

假设 $d_{x}(y)$ 表示从结点 $x$ 到结点 $y$ 的带权最短路径的费用，则有  

式中， $c(x,v)$ 是从 $x$ 到其邻居 $\nu$ 的费用。已知 $x$ 的所有邻居到 $y$ 的最短路径费用后，从 $x$ 到y的最短路径费用是对所有邻居 $v$ 的 $c(x,\nu)+d_{\nu}(y)$ 的最小值，如图4.13所示。所有最短路径算法都依赖于一个性质：“两点之间的最短路径也包含了路径上其他顶点间的最短路径。”  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/12611813d1879774849211636fc146bfc2d29d0e6ae99f100dc9742f52c0fa79.jpg)  
图4.13Bellman-Ford算法的基本思想  
对于距离-向量算法，每个结点 $x$ 维护下列路由信息：  

1）从 $x$ 到每个直接相连邻居 $\nu$ 的链路费用 $c(\boldsymbol{x},\boldsymbol{v})$ 。2）结点 $x$ 的距离向量，即 $x$ 到网络中其他结点的费用。这是一组距离，因此称为距离向量。3）它收到的每个邻居的距离向量，即 $x$ 的每个邻居到网络中其他结点的费用。  

在距离-向量算法中，每个结点定期地向它的每个邻居发送它的距离向量副本。当结点 $x$ 从它的任何一个邻居 $v$ 接收到一个新距离向量时，它首先保存 $v$ 的距离向量，Bellman-Ford公式 $d_{x}(y)=\operatorname*{min}\left\{c(x,v)+d_{v}(y)\right\}$ 更新自己的距离向量。若结点 $x$ 的距离向量因这个更新步骤而改变，则结点 $x$ 接下来继续向它的每个邻居发送其更新后的距离向量。  

下面以图4.14顶部三个结点的简单网络为例，说明距离-向量算法的实现。  

>#### pro：距离向量路由算法的具体实现（2021）  

图4.14(a)中的各列依次是三个结点的初始化距离向量，此时各结点之间尚未交换过任何路由信息，因此各结点的初始化距离向量就等于它到每个直接相连邻居v的费用。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/768629927fac929d4ab41b84621905d8960be70fc17d30ff64b196f1098835be.jpg)  
图4.14距离向量算法实现的举例  

初始化后，每个结点第一次向它的所有邻居发送其距离向量，在接收到该更新报文后，每个结点重新计算自已的距离向量。例如，结点 $x$ 计算的过程为： $\begin{array}{r}{d_{x}(x)=0\,;\,\,d_{x}(y)=\operatorname*{min}\left\{c(x,y)+d_{y}(y),\right.}\end{array}$  $c(x,z)+d_{z}(y)\}=\operatorname*{min}\{2+0,7+1\}=2$  d()=min{c(x,y)+d(z),  $c(x,z)+d_{z}(z)\}=\operatorname*{min}\{2+1,7+0\}=$   $\underline{{\boldsymbol{\mathfrak{s}}}}_{\circ}$ 注意到结点 $x$ 到结点 $z$ 的最低费用从7变成了3，结点 $z$ 到结点 $x$ 的最低费用也从7变成了3，如图4.14(b)所示。结点的距离向量变化后，再次向它们的邻居发送它们更新的距离向量，而没有变化的结点 $y$ 不用发送更新报文。接收到邻居的更新报文后，结点又重新计算它们的距离向量，此次没有结点更新，因此也无更新报文发送，算法进入静止状态，如图4.14(c)所示。  

显然，更新报文的大小与网络中的结点数目成正比，大型网络将导致很大的更新报文。最常见的距离-向量路由算法是RIP算法，它采用“跳数”作为距离的度量。  

# 3.链路状态路由算法  

链路状态是指本路由器都和哪些路由器相邻，以及相应链路的代价。链路状态算法要求每个结点都具有全网拓扑结构图（这个拓扑结构图在全网范围内是一致的），它们执行下列两项任务：第一，主动测试所有相邻结点的状态：第二，定期地将链路状态传播给所有其他结点。因此每个结点都知道全网共有多少个结点、哪些结点是相连的、其代价是多少等，于是每个结点都可使用Dijkstra最短路径算法计算出到达其他结点的最短路径。  

在链路状态算法中，结点每收到一个链路状态报文，便用其更新自己的网络状态“视野图”一旦链路状态发生变化，就使用Dijkstra算法重新计算到达所有其他结点的最短路径。  
因为一个结点的链路状态只涉及相邻结点的连通状态，而与整个互联网的规模并无直接关系，所以链路状态算法适用于大型的或路由信息变化聚敛的互联网环境。  

链路状态算法的主要优点是，每个结点都使用同样的链路状态数据独立地计算路径，而不依赖中间结点的计算；链路状态报文不加改变地传播，因此采用该算法易于查找敌障。当一个结点从所有其他结点接收到报文时，它就在本地立即计算出正确的路径，保证一步汇聚。最后，因为链路状态报文仅运载来自单个结点关于直接链路的信息，其大小与网络中的结点数目无关，所以链路状态算法比距离-向量算法有更好的规模可伸展性。  

两种路由算法的比较：在距离-向量算法中，每个结点仅与它的直接邻居交谈，向它的邻居发送自己的路由表，其大小取决于网络中的结点数目，代价较大。在链路状态算法中，每个结点通过广播的方式与所有其他结点交谈，但它只告诉它们与它直接相连的链路的费用。  

典型的链路状态路由算法是OSPF算法。  

# 4.4.2分层次的路由选择协议  

互联网采用的是自适应的、分布式路由选择协议。因为互联网的规模非常大，许多联网单位不愿让外界了解自己单位网络的布局细节，所以互联网采用分层次的路由选择协议。  

为此，可以把整个互联网划分为许多较小的自治系统（AutonomousSystem，AS）。自治系统是在单一技术管理下的一组路由器，这些路由器使用一种AS内部的路由选择协议和共同的度量。一个AS对其他AS表现出的是一个单一的和一致的路由选择策略。  

这样，互联网就把路由选择协议划分为两大类  

# 1.内部网关协议（Interior Gateway Protocol，IGP）  

内部网关协议即在一个自治系统内部使用的路由选择协议，它与在互联网中的其他自治系统选用什么路由选择协议无关。自前这类路由选择协议使用得最多，如RIP和OSPF。  

# 2.外部网关协议（External Gateway Protocol，EGP）  

若源主机和目的主机处在不同的自治系统中（两个自治系统可能使用不同的IGP），则当数据报传到一个自治系统的边界时，就需要使用一种协议将路由选择信息传递到另一个自治系统中。这样的协议就是外部网关协议。目前使用最多的外部网关协议是BGP-4。  

自治系统之间的路由选择也称域间路由选择，自治系统内部的路由选择也称域内路由选择。  

图4.15是两个自治系统互连的示意图。每个自治系统自己决定在本自治系统内部运行哪个内部网关协议（例如，可以是RIP或OSPF）。但每个自治系统都有一个或多个路由器（图中的路由器R1和R2）除运行本系统的内部网关协议外，还要运行外部网关协议（如BGP-4）。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/6112522be698219f313ddd9b098f0e24bb2125b01240cce7be446986a2d591b1.jpg)  
图4.15自治系统和内部网关协议、外部网关协议  

# 4.4.3路由信息协议（RIP）  

路由信息协议（Routing Information Protocol，RIP）I GP用的协议。RIP是一种分布式的基于距离向量的路由选择协议。  
1.RIP的规定  

1）网络中的每个路由器都要维护从它自身到其他每个目的网络的距离记录，即距离向量。2）RIP使用跳数（HopCount）（或称距离）来衡量到达目的网络的距离。规定从一路由器到直接连接的网络的距离定义为1；而每经过一个路由器，距离就加1。3）RIP认为好的路由就是它通过的路由器数目少，即距离短或跳数少。  

>#### pro：RIP中跳数为16的含义（2010）  

4）RIP允许一条路径最多只能包含15个路由器。因此距离等于16时表示网络不可达。可见RIP只适用于小型互联网。距离向量路由可能会出现环路的情况，规定路径上的最高跳数的目的是为了防止分组不断在环路上循环，减少网络拥塞的可能性。5）每个路由表项都有三个关键字段：<目的网络 $N$ ，距离 $d$ ，下一跳路由器地址 $\chi>$  

# 2.RIP的特点  

RIP的每个路由器都要不断与其他路由器交换信息，下面三个特点非常重要。  

1）和谁交换信息：仅和直接相邻的路由器交换信息。2）交换什么信息：交换的信息是本路由器所知道的全部信息，即自己的路由表。3）何时交换信息：按固定的时间间隔（如30秒）交换路由信息。当网络拓扑发生变化时，路由器也及时向相邻路由器通告拓扑变化后的路由信息。  

路由器刚开始工作时，只知道自己到直接相连的几个网络的距离为1。每个路由器仅和相邻路由器周期性地交换并更新路由信息。经过若干次交换和更新后，所有的路由器最终都会知道到达本自治系统内任何网络的最短距离和下一跳路由器的地址，称为收敛。  

>#### pro：封装RIP报文所采用的协议（2017）  

RIP是应用层协议，它使用UDP传送数据（端口520）。RIP选择的路径不一定是时间最短的，但一定是具有最少的路由跳数，因为它是根据最少跳数进行路径选择的。  

# 3.RIP的距离向量算法  

对每个相邻路由器发送来的RIP报文，执行如下步骤：  

1）对地址为 $X$ 的相邻路由器发来的RIP报文，先修改此报文中的所有项目：把“下一跳”字段中的地址都改为 $X,$ ，并把所有“距离”字段的值加1。  

2）对修改后的RIP报文中的每个项目，执行如下步骤：  

IF（若原来的路由表中没有目的网络 $N)$ 则把该项目添加到路由表中（表明这是新的目的网络）。ELSEIF（若原来的路由表中有目的网络 $N$ ，且下一跳路由器的地址是 $X)$ 用收到的项目替换原路由表中的项目（因为要以更新的消息为准）。ELSEIF（若原来的路由表中有目的网络 $N$ ，且下一跳路由器的地址不是 $X)$ 若收到的项目中的距离 $d$ 小于路由表中的距离，则进行更新。ELSE什么也不做。3）若180秒（RIP默认超时时间）还没有收到相邻路由器的更新路由表，则把此相邻路由器  

记为不可达的路由器，即把距离设置为16（距离为16表示不可达）。  

4）返回。下面举例说明RIP路由条目的更新过程。已知路由器R6和R4互为相邻路由器，表4.4(a)所示为R6的路由表，现在收到相邻路由器R4发来的路由更新信息，如表4.4(b)所示。  
表4.4(a）R6的路由表
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/889f89c59d634d95c1bd9984787004bbb1abfc4ccc76b076c5aebc5983ca6261.jpg)  

表4.4(b）R4发来的路由表
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/91cd1866cfc529d657f0a9580a36d851d3fc8364d3a2201b39819805333824a4.jpg)  

现在试更新R6的路由表。先把 $\mathrm{R_{4}}$ 发来的路由表［表4.4(b)】中各项的距离都加1，并把下一跳路由器都改为R4，得到表4.5(a)。将这个表的每行与R6的路由表[表4.4(a)］进行比较。  

第一行的Netl在表4.4(a)中没有，因此要把这一行添加到表4.4(a)中。第二行的Net2在表4.4(a)中有，且下一跳路由器也是R4，因此要更新（距离增大了）。  

第三行的Net3在表4.4(a)中有，但下一跳路由器不同。于是需要比较距离。新的路由信息的距离是2，小于原表中的4，因此要更新。这样，得出更新后的R6的路由表如表4.5(b)所示。  

表4.5(a)修改R4发来的路由表
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/a97c4d76eb3895ef462128c5897814b8e3366a96be378450b6fc83b80323f2fd.jpg)  

表4.5(b)R6更新后的路由表
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/91b094f046fb1e1478116d0079f503cecbaa272a878d4bac0f8118446d285adb.jpg)  

# 4.RIP的优缺点  

RIP的优点：  

1）实现简单、开销小、收敛过程较快 2）若一个路由器发现了更短的路由，则这种更新信息就传播得很快，在较短时间内便可被传至所有路由器，俗称“好消息传播得快”。  

RIP的缺点：  

1）RIP限制了网络的规模，它能使用的最大距离为15（16表示不可达）。2）路由器之间交换的是路由器中的完整路由表，因此网络规模越大，开销也越大。3）当网络出现故障时，路由器之间需反复多次交换信息才能完成收敛，要经过较长时间才能将故障消息传送到所有路由器（即慢收敛现象），俗称“坏消息传播得慢”。  

下面举例说明RIP“好消息传播得快，坏消息传播得慢”的特点。假设图4.16中的路由器都采用RIP交换路由信息，初始时R1到网络 $N$ 的距离为4，且R1和R2均已收敛。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/fcb2f30da895050fcf0b8687df1e357c43fd6cb3ad48015e8494ffb22c268878.jpg)  
图4.16RIP举例：链路开销改变  

在图4.16(a)中，某时刻R1的某个端口检测到“到 $N$ 更短的链路”（距离由4变为1），R1计算其到 $N$ 的最新距离 $=\operatorname*{min}\lbrace1,1+\mathrm{R}2$ 到 $N$ 的距离 $\}=\operatorname*{min}\{1,1+5\}=1$ ，并通知邻居；R2收到后，更新其到 $N$ 的距离为2，并通知邻居；R1收到后，R1到 $N$ 的最短距离未变，不再发送通知，算法进入静止状态。可见，R2到 $N$ 的距离减少的好消息通过RIP得到了迅速传播。  
>#### pro：RIP“坏消息传播得慢”的分析（2016）  

在图4.16（b)中，某时刻R1的某个端口检测到“ $^{\circ}N$ 不可达”（即距离变为16），R1计算其到 $N$ 的最新距离 $=\!\operatorname*{min}\{16,1+\mathrm{R}2$ 到 $N$ 的距离 $\}=\operatorname*{min}\{16,1+5\}=6$ 。从网络全局的视角可以看出，经过R2的这个新距离显然是错误的。R1算出到 $N$ 的最新距离后，通知邻居；R2收到后，更新其到 $N$ 的距离为7,通知邻居；R1收到后，计算其到 $N$ 的距离 $=\operatorname*{min}\{16,1+\mathrm{R}2$ 到 $N$ 的距离 $\ell=\operatorname*{min}\{16,$  $1+7\}=8$ ，继续通知邻居…...如此循环，直到R2最终算出它经由R1到达 $N$ 的距离为16为止。可见，RIP关于链路故障或距离增加的坏消息传播得很慢。  

# 4.4.4开放最短路径优先（OSPF）协议  

# 1.OSPF协议的基本特点  

开放最短路径优先（OSPF）协议是使用分布式链路状态路由算法的典型代表，也是内部网关协议（IGP）的一种。OSPF与RIP相比有以下4点主要区别：  

1）OSPF向本自治系统中所有路由器发送信息。这里使用的方法是洪泛法。而RIP仅仅向自己相邻的几个路由器发送信息。2）发送的信息是与本路由器相邻的所有路由器的链路状态，但这只是路由器所知道的部分信息。而在RIP中，发送的信息是本路由器所知道的全部信息，即整个路由表。3）只有当链路状态发生变化时，路由器才用洪泛法向所有路由器发送此信息，并且更新过程收敛得快，不会出现RIP“坏消息传得慢”的问题。而在RIP中，不管网络拓扑是否发生变化，路由器之间都要定期交换路由表的信息。  

>#### pro：封装OSPF报文所采用的协议（2017）  

4）OSPF是网络层协议，它不用UDP或TCP，而直接用IP数据报传送（其IP数据报首部的协议字段为89）。而RIP是应用层协议，它在传输层使用UDP。  

# 注意  

用UDP传送是指将该信息作为UDP报文的数据部分，而直接使用IP数据报传送是指将该信息直接作为IP数据报的数据部分。RIP报文是作为UDP数据报的数据部分。  

除以上区别外，OSPF还有以下特点：  

1）OSPF充许对每条路由设置成不同的代价，对于不同类型的业务可计算出不同的路由。2）若到同一个目的网络有多条相同代价的路径，则可将通信量分配给这几条路径。3）OSPF分组具有鉴别功能，从而保证仅在可信赖的路由器之间交换链路状态信息。4）OSPF支持可变长度的子网划分和无分类编址CIDR。5）每个链路状态都带上一个32位的序号，序号越大，状态就越新。  

# 2.OSPF的基本工作原理  

因为各路由器之间频繁地交换链路状态信息，所以所有路由器最终都能建立一个链路状态数据库，即全网的拓扑结构图。然后，每个路由器利用链路状态数据库中的数据，使用Dijkstra算法计算自己到达各自的网络的最优路径，构造出自己的路由表。此后，当链路状态发生变化时，每个路由器重新计算到达各目的网络的最优路径，构造出新的路由表。  

# 注意  

虽然使用Dijkstra算法能计算出完整的最优路径，但路由表中不会存储完整路径，而只存储“下一跳”（只有到了下一跳路由器，才能知道再下一跳应当怎样走）。  
为了使OSPF能够用于规模很大的网络，OSPF将一个自治系统再划分为若干更小的范围，称为区域。划分区域的好处是，将利用洪泛法交换链路状态信息的范围局限在每个区域而非整个自治系统，从而减少了整个网络上的通信量。  

# 3.OSPF的五种分组类型  

OSPF共有以下五种分组类型：  

1）问候分组，用来发现和维持邻站的可达性。  

2）数据库描述分组，向邻站给出自己的链路状态数据库中的所有链路状态项目的摘要信息。  

3）链路状态请求分组，尚对方请求发送某些链路状态项目的详细信息。  

4）链路状态更新分组，用洪泛法对全网更新链路状态，它是OSPF最核心的部分。  

5）链路状态确认分组，对链路更新分组的确认。  

在网络中通常传送的OSPF分组大多是问候分组。两个相邻路由器通常每隔10秒要交换一次问候分组，以便知道哪些站可达。若有40秒没有收到某个相邻路由器发来的问候分组，则认为该相邻路由器不可达，应立即修改链路状态数据库，并重新计算路由表。  

在路由器刚开始工作时，OSPF让每个路由器使用数据库描述分组和相邻路由器交换本数据库中已有的链路状态摘要信息。然后，路由器使用链路状态请求分组，向对方请求发送自己所缺少的某些链路状态项目的详细信息。经过一系列的这种分组交换，就建立了全网同步的链路数据库。图4.17给出了OSPF的基本操作，说明了两个路由器需要交换的各种类型的分组。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f0865e7a3e56305b7752f9c75c0c571d220f187b9e36b71961fb01a56f2fc570.jpg)  
图4.17OSPF的基本操作  

在网络运行的过程中，只要一个路由器的链路状态发生变化，该路由器就要使用链路状态更新分组，用洪泛法向全网更新链路状态。其他路由器在收到更新分组后要发送确认。  

为了确保链路状态数据库与全网的状态保持一致，OSPF还规定每隔一段时间（如30分钟）要刷新一次数据库中的链路状态。因为一个路由器的链路状态只涉及与相邻路由器的连通状态，与整个网络的规模并无直接关系，所以当互联网规模很大时，OSPF要比RIP好得多。  

# 4.4.5边界网关协议（BGP）  

>#### pro：BGP的作用（2013）  

边界网关协议（Border Gateway Protocol，BGP）AS信息的协议，是一种外部网关协议。边界网关协议BGP常用于互联网的网关之间。  

内部网关协议主要是设法使数据报在一个AS中尽可能有效地从源站传送到目的站。在一个AS内部也不需要考虑其他方面的策略。然而BGP使用的环境却不同，主要原因如下：  
1）互联网的规模太大，使得AS之间路由选择非常困难，每个主干网路由器表中的项目数都非常庞大。对于AS之间的路由选择，要寻找最佳路由是很不现实的。  

2）AS之间的路由选择必须考虑政治、安全或经济等有关因素。  

BGP只能是力求寻找一条能够到达目的网络且比较好的路由（不能兜圈子），而并非要寻找一条最佳路由。BGP采用的是路径向量路由选择协议，它与距离向量协议（如RIP）和链路状态协议（如OSPF）都有很大的区别。BGP是应用层协议，它是基于TCP的。  

BGP的工作原理如下：  

1）配置BGP时，每个AS的管理员要选择至少一个路由器，作为该AS的“BGP发言人”BGP发言人往往就是BGP边界路由器。  

>#### pro：封装BGP报文所采用的协议（2013、2017）  

2）一个BGP发言人与其他AS中的BGP发言人要交换路由信息，就要先建立TCP连接：然后在此连接上交换BGP报文以建立BGP会话，再利用BGP会话交换路由信息。使用TCP连接交换路由信息的两个BGP发言人，彼此成为对方的邻站或对等站。每个BGP发言人除了必须运行BGP外，还必须运行该AS所用的内部网关协议，如OSPF或RIP。图4.18所示为BGP发言人和自治系统AS的关系示意图。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/4ab8772ba2216b0083326b701c09c66e732cf291ac3af19cc38f7fdaebe5ed2b.jpg)  
图4.18BGP发言人和自治系统AS的关系示意图  

3）BGP所交换的网络可达性的信息，就是要到达某个网络所要经过的一系列自治系统。当BGPP发言人互相交换网络可达性的信息后，各BGP发言人就根据所用的策略，从收到的路由信息中找出到达各自治系统的较好路由。  

图4.19给出了一个BGP发言人交换路径向量的例子。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/8f8fe0ecd96d6202cbd624e068791f7ff2d406d6b61dd7bf65606f87db5e3929.jpg)  
图4.19主干网与自治系统间路径向量的交换  

BGP的特点如下：  

1）BGP交换路由信息的结点数量级是AS个数的数量级，这要比这些AS中的网络数少很多。  
2）寻找一条较好的路径，取决于找准正确的BGP发言人，而每个AS中BGP发言人（或边界路由器）的数目是很少的。这样就使得AS之间的路由选择不致过分复杂。3）BGP支持CIDR，因此BGP的路由表也就应当包括目的网络前缀、下一跳路由器，以及4）当BGP刚运行时，BGP的邻站交换整个BGP路由表。但以后只需要在发生变化时更新有变化的部分。这样做对节省网络带宽和减少路由器的处理开销方面都有好处。  

BGP-4共使用4种报文：  

1）打开（Open）报文。用来与相邻的另一个BGP发言人建立关系，使通信初始化。  

2）更新（Update）报文。用来通知某一路由的信息，以及列出要撤销的多条路由。  

3）保活（Keepalive）报文。用来周期性地证实邻站的连通性。  

4）通知（Notification）报文。用来发送检测到的差错。  

若一个BGP发言人想与另一个AS的BGP发言人建立邻站关系，则要向对方发送Open报文，若对方接受这种邻站关系，则用Keepalive报文响应。邻站关系一旦建立，就要继续维持这种关系。为此，这两个BGP发言人彼此要周期性地交换Keepalive报文（一般每隔30秒）。Keepalive报文只有19B，因此不会造成网络上太大的开销。Update报文是BGP的核心内容，BGP发言人可以用Update报文撤销它曾经通知过的路由，也可以宣布增加新的路由。  

RIP、OSPF与BGP的比较如表4.6所示。  

表4.6三种路由协议的比较
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/15cd3d3b0e07729275343dbe5d0888070cbc40ba2780a33c5736517ae359032a.jpg)  
 
# IP多播  

# 4.5.1 多播的概念  

多播是让源主机一次发送的单个分组可以抵达用一个组地址标识的若干目的主机，即一对多的通信。在互联网上进行的多播，称为IP多播。  

与单播相比，在一对多的通信中，多播可大大节约网络资源。假设视频服务器向90台主机传送同样的视频节目，单播与多播的比较如图4.20所示。多播时仅发送一份数据，并且只需发送一次，只有在传送路径出现分岔时才将分组复制后继续转发，因此大大减轻了发送者的负担和网络的负载。多播需要路由器的支持才能实现，能够运行多播协议的路由器称为多播路由器。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/19528b897648d1681e5067d8ed74aca814c66c4a765522f6600af4b81a300c9f.jpg)  
图4.20单播与多播的比较  

# 4.5.2IP多播地址  

多播数据报的源地址是源主机的IP地址，目的地址是IP多播地址。IP多播地址就是IPv4中的D类地址。D类地址的前四位是1110，因此D类地址范围是 $224.0.0.0{\sim}239.255.255.255.255.$ 。每个D类IP地址标志一个多播组，一台主机可以随时加入或离开一个多播组。  

多播数据报和一般的IP数据报的区别是，前者使用D类IP地址作为目的地址，并且首部中的协议字段值是2，表明使用IGMP协议。需要注意的是：  

1）多播数据报也是“尽最大努力交付”，不提供可靠交付。  

2）多播地址只能用于目的地址，而不能用于源地址。  

3）对多播数据报不产生ICMP差错报文。  

IP多播可以分为两种： $\textcircled{\scriptsize{1}}$ 只在本局域网上进行硬件多播； $\circledcirc$ 在互联网的范围内进行多播。目前大部分主机都是通过局域网接入互联网的。因此，在互联网上进行多播的最后阶段，还是要把多播数据报在局域网上用硬件多播交付给多播组的所有成员［见图4.20(b)]。  

多播机制仅应用于UDP，它能将报文同时发送给多个接收者。而TCP是一个面向连接的协议，它意味着分别运行在两台主机的进程之间存在一条连接，因此会一对一地发送。  

# 4.5.3在局域网上进行硬件多播  

因为局域网支持硬件多播，所以只要把IP多播地址映射成多播MAC地址，即可将IP多播数据报封装在局域网的MAC帧中，而MAC顿首部的目的MAC地址字段就设置为由IP多播地址映射成的多播MAC地址。这样，就很方便地利用硬件多播实现了局域网内的IP多播。  
IANA拥有的以太网多播地址的范围是从01-00-5E-00-00-00到01-00-5E-7F-FF-FF。在这些地址中，只有23位可用作多播。这只能和D类IP地址中的23位有一一对应关系。D类IP地址可供分配的有28位，可见在这28位中前5位无法映射到多播MAC地址，如图4.21所示。  

例如，IP多播地址224.128.64.32（即E0-80-40-20）和另一个IP多播地址224.0.64.32（即E0-00-40-20）转换成以太网的硬件多播地址都是01-00-5E-00-40-20。因为多播IP地址与以太网MAC地址的映射关系不是唯一的，所以收到多播数据报的主机，还要在IP层利用软件进行过滤，把不是本主机要接收的数据报丢弃。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/990325a354dd6d4421e60646b9cd97567ed23139bd25859486d30625de05571f.jpg)  
图4.21D类IP地址与以太网多播地址的映射关系  

# 4.5.4IGMP与多播路由协议  

路由器要获得多播组的成员信息，需要利用网际组管理协议（InternetGroupManagementProtocol，IGMP)。连接到局域网上的多播路由器还必须和互联网上的其他多播路由器协同工作，以便把多播数据报用最小代价传送给所有组成员，这就需要使用多播路由选择协议。  

IGMP是让连接到本地局域网上的多播路由器，知道本局域网上是否有主机参加或退出了某个多播组。IGMP并不是在互联网范围内对所有多播组成员进行管理的协议。IGMP不知道IP多播组包含的成员数，也不知道这些成员分布在哪些网络上。  

IGMP报文被封装在IP数据报中传送，但它也向IP提供服务。因此不把IGMP视为一个单独的协议，而视为整个网际协议IP的一个组成部分。IGMP的工作可分为两个阶段。  

第一阶段：当某台主机加入新的多播组时，该主机应向多播组的多播地址发送一个IGMIP报文，声明自己要成为该组的成员。本地的多播路由器收到IGIMP报文后，还要利用多播路由选择协议，把这种组成员关系转发给互联网上的其他多播路由器。  

第二阶段：组成员关系是动态的。本地多播路由器要周期性地探询本地局域网上的主机，以便知道这些主机是否仍继续是组的成员。只要对某个组有一台主机响应，多播路由器就认为这个组是活跃的。但一个组在经过几次探询后仍然没有一台主机响应，多播路由器就认为本网络上的主机都已离开了这个组，因此就不再把这个组的成员关系转发给其他的多播路由器。  

多播路由选择实际上就是要找出以源主机为根结点的多播转发树，其中每个分组在每条链路上只传送一次（即在多播转发树上的路由器不会收到重复的多播数据报）。不同的多播组对应于不同的多播转发树；同一个多播组，对不同的源点也会有不同的多播转发树。  
 

# 4.6 移动IP  

# 4.6.1 移动IP的概念  

移动IP技术是指移动站以固定的IP地址实现跨越不同网络的漫游功能，并保证基于IP的网络权限在漫游过程中不发生任何改变。移动IP的目标是把分组自动地投递给移动站。一个移动站是把其连接点从一个网络或子网改变到另一个网络或子网的主机。  

移动IP定义了三种功能实体：移动结点、本地代理（也称归属代理）和外地代理。1）移动结点。具有永久IP地址的移动主机。2）本地代理。通常就是连接在归属网络（原始连接到的网络）上的路由器。3）外地代理。通常就是连接在被访网络（移动到另一地点所接入的网络）上的路由器。  

值得注意的是，某用户将笔记本关机后从家里带到办公室重新上网，在办公室能很方便地通过DHCP自动获取新的IP地址。虽然笔记本移动了，更换了地点及所接入的网络，但这并不是移动IP。但是，若我们需要在移动中进行TCP传输，则在移动站漫游时，应一直保持这个TCP连接，否则移动站的TCP连接就会断断续续。可见，若要使移动站在移动中的TCP连接不中断，就必须使笔记本的IP地址在移动中保持不变。这就是移动IP要研究的问题。  

# 4.6.2移动IP通信过程  

用一个通俗的例子来描述移动IP的通信原理。例如，在以前科技不那么发达的年代，本科毕业时都将走向各自的工作岗位。因为事先并不知道自己未来的准确通讯地址，所以怎样继续和同学们保持联系呢？实际上也很简单。彼此留下各自的家庭地址（即永久地址）。毕业后若要和某同学联系，只要写信寄到该同学的永久地址，再请其家长把信件转交即可。  

在移动IP中，每个移动站都有一个原始地址，即永久地址（或归属地址），移动站原始连接的网络称为归属网络。永久地址和归属网络的关联是不变的。在图4.22中，移动站A的永久地址是131.8.6.7/16，而其归属网络是131.8.0.0/16。归属代理通常是连接到归属网络上的路由器，然而它实现的代理功能是在应用层完成的。当移动站移动到另一地点，所接入的外地网络也称被访网络。在图4.22中，移动站A被移动到被访网络15.0.0.0/8。被访网络中使用的代理称为外地代理，它通常是连接在被访网络上的路由器。外地代理有两个重要功能： $\textcircled{\scriptsize{1}}$ 要为移动站创建一个临时地址，称为转交地址。在图4.22中，移动站A的转交地址是15.5.6.7/8。转交地址的网络号显然和被访网络一致。 $\circledcirc$ 及时把移动站的转交地址告诉其归属代理。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/4174d26dc508d9296f99faad8d6f94645b3e04daa497b46f1ac2b81540095c98.jpg)  
图4.22移动IP的基本通信过程  
请注意两点：转交地址是供移动站、归属代理及外地代理使用的，各种应用程序都不会使用。外地代理要向连接在被访网络上的移动站发送IP分组时，直接使用移动站的MAC地址。  

在图4.22中，通信者B要和移动站A进行通信。B并不知道A在什么地方，但B使用A的永久地址作为发送的IP分组中的目的地址，移动IP的基本通信流程如下：  

1）移动站A在归属网络时，按传统的TCP/IP方式进行通信。  

2）移动站A漫游到被访网络时，向外地代理进行登记，以获得一个临时的转交地址。外地代理要向A的归属代理登记A的转交地址。3）归属代理知道移动站A的转交地址后，会构建一条通向转交地址的隧道，将截获的发送给A的IP分组进行再封装，并通过隧道发送给被访网络的外地代理。4）外地代理把收到的封装的IP分组进行拆封，恢复成原始的IP分组，然后发送给移动站A，这样A在被访网络就能收到这些发送给它的IP分组。5）移动站A在被访网络对外发送IP分组时，仍然使用自己的永久地址作为IP分组的源地址，此时显然无须通过A的归属代理来转发，而是直接通过被访网络的外部代理。  

6）移动站A移动到另一被访网络时，在新外地代理登记后，然后新外地代理将A的新转交地址告诉其归属代理。无论如何移动，A收到的IP分组都是由归属代理转发的。  

7）移动站A回到归属网络时，A向归属代理注销转交地址。  

为了支持移动性，在网络层中还应增加一些新功能： $\textcircled{\scriptsize{1}}$ 移动站到外地代理的登记协议； $\circledcirc$ 外地代理到归属代理的登记协议： $\textcircled{3}$ 归属代理数据报封装协议； $\textcircled{4}$ 外地代理拆封协议。  
  

# 4.7网络层设备  

# 4.7.1冲突域和广播域  

命题追踪各种中继设备对冲突域/广播域的划分（2010、2020）  

这里的“域”表示冲突或广播在其中发生并传播的区域  

1.冲突域  

冲突域是指连接到同一物理介质上的所有结点的集合，这些结点之间存在介质争用的现象。在OSI参考模型中，冲突域被视为第1层的概念，像集线器、中继器等简单无脑复制转发信号的第1层设备所连接的结点都属于同一个冲突域，也就是说它们不能划分冲突域。而第2层（网桥、交换机）、第3层（路由器）设备都可以划分冲突域。  

2.广播域  

广播域是指接收同样广播消息的结点集合。也就是说，在该集合中的任何一个结点发送一个广播帧，其他能收到这个顿的结点都被认为是该广播域的一部分。在OSI参考模型中，广播域被视为第2层的概念，像第1层（集线器等）、第2层（交换机等）设备所连接的结点都属于同一个广播域。而路由器，作为第3层设备，则可以划分广播域，即可以连接不同的广播域。  

通常所说的局域网（LAN）特指使用路由器分割的网络，也就是广播域。  
# 4.7.2路由器的组成和功能  

命题追踪路由器的功能（2010）  

路由器是一种具有多个输入/输出端口的专用计算机，其任务是连接不同的网络（连接异构网络）并完成分组转发。在多个逻辑网络（即多个广播域）互连时必须使用路由器。  

当源主机向自标主机发送数据报时，路由器先检查源主机与目标主机是否连接在同一个网络上。若源主机和自标主机在同一个网络上，则直接交付而无须通过路由器。若源主机和目标主机不在同一个网络上，则路由器按照转发表（由路由表得出）指出的路由将分组转发给下一个路由器，这称为间接交付。可见，在同一个网络中传递数据无须路由器的参与，而跨网络通信必须通过路由器进行转发。例如，路由器可以连接不同的LAN，连接不同的VLAN，连接不同的WAN，或者把LAN和WAN互连起来。路由器隔离了广播域。  

从结构上看，路由器由路由选择和分组转发两部分构成，如图4.23所示。而从模型的角度看，路由器是网络层设备，它实现了网络模型的下三层，即物理层、数据链路层和网络层。  

# 注意  

若一个存储转发设备实现了某个层次的功能，则它可以互连两个在该层次上使用不同协议的网段（网络）。若网桥实现了物理层和数据链路层，则网桥可以互连两个物理层和数据链路层不同的网段；但中继器实现了物理层后，却不能互连两个物理层不同的网段，这是因为中继器不是存储转发设备，它属于直通式设备。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/a6f3e8013ec6d6e4ad6b99d005103a7ca8fdd09388de0733bec78e66420e84ed.jpg)  
图4.23路由器体系结构  

路由选择部分也称控制部分，核心构件是路由选择处理机，其任务是根据所选定的路由选择协议构造出路由表，同时经常或定期地和相邻路由器交换路由信息而不断更新和维护路由表。  

分组转发部分由三部分组成：交换结构、一组输入端口和一组输出端口。  

交换结构也称交换组织，其作用是根据转发表对分组进行处理，将某个输入端口进入的分组从一个合适的输出端口转发出去。交换结构本身就是一个“在路由器中的网络”。  

路由器的端口中都有物理层、数据链路层和网络层的处理模块。输入端口在物理层接收比特流，在数据链路层提取出帧，剥去帧的首部和尾部后，分组就被送入网络层的处理模块。输出端口执行相反的操作。端口在网络层的处理模块中都设有一个缓冲队列，用来暂存等待处理或已处理完毕待发送的分组，还可用来进行必要的差错检测。若分组处理的速率赶不上分组进入队列的速率，就会使后面进入队列的分组因缓冲区满而只能被去弃。需要说明的是，路由器的端口一般都具有输入和输出的功能，图4.23中分别给出输入和输出端口是为了使读者更容易理解。  
# 4.7.3 路由表与分组转发  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c32894379baf2472f8b38363f02818ea0e57feb363b4efd3bc0fef6a8494738a.jpg)  

根据网络拓扑并利用路由聚合构造出路由表（2009、2013）  

路由表是根据路由选择算法得出的，主要用途是路由选择。从历年统考真题可以看出，标准的路由表有4个项目：目的网络IP地址、子网掩码、下一跳IP地址、接口。在图4.24所示的网络拓扑中，R1的路由表见表4.7，该路由表包含到互联网的默认路由。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/7fb84369cd25807505af80fe6999595f7d65c3f98e6f1977a51f4f5dd572de68.jpg)  
图4.24一个简单的网络拓扑  

>#### pro：路由表转发分组的分析（2014）  

表4.7R1的路由表
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/83d0ea3113ec3f53e1fd3612ba918f4a07fa3bee9ffe976731a024849b2d0c8e.jpg)  

转发表是从路由表得出的，其表项和路由表项有直接的对应关系。但转发表的格式和路由表的格式不同，其结构应使查找过程最优化（而路由表则需对网络拓扑变化的计算最优化）。转发表中含有一个分组将要发往的目的地址，以及分组的下一跳（即下一步接收者的目的地址，实际为MAC地址）。为了减少转发表的重复项目，可以使用一个默认路由代替所有具有相同“下一跳”的项目，并将默认路由设置得比其他项目的优先级低，如图4.25所示。路由表总是用软件来实现的；转发表可以用软件来实现，甚至也可以用特殊的硬件来实现。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/1454f74c2f1cf79b08cb4f8429965c256b8deb385876c24dc7e65a06f97f8c6a.jpg)  
图4.25未使用默认路由的转发表和使用了默认路由的转发表的对比  

注意转发和路由选择的区别：“转发”是路由器根据转发表把收到的IP数据报从合适的端口转发出去，它仅涉及一个路由器。而“路由选择”则涉及很多路由器，路由表是许多路由器协同工作的结果。这些路由器按照复杂的路由算法，根据从各相邻路由器得到的关于网络拓扑的变化情况，动态地改变所选择的路由，并由此构造出整个路由表。  

路由表不等于转发表，分组的实际转发是靠直接查找转发表，而不是查找路由表，  



# 4.8本章小结及疑难点  

1.“尽最大努力交付”有哪些含义？  

1）不保证源主机发送的IP数据报一定无差错地交付到目的主机。  

2）不保证源主机发送的IP数据报都在某一规定的时间内交付到目的主机。  

3）不保证源主机发送的IP数据报一定按发送时的顺序交付到目的主机。  

4）不保证源主机发送的IP数据报不会重复交付给目的主机。  

5）不敌意丢弃IP数据报。丢弃IP数据报的情况是：路由器检测出首部检验和有错误；或者因为网络中通信量过大，路由器或目的主机中的缓存已无空闲空间。  

但要注意，IP数据报的首部中有一个“首部检验和”字段。当它检验出IP数据报的首部出现了差错时，就丢弃该数据报。因此，凡交付给目的主机的IP数据报都是IP首部没有差错的或没有检测出差错的。也就是说，在传输过程中，出现差错的IP数据报都被丢弃了。  

现在互联网上绝大多数的通信量都属于“尽最大努力交付”。若数据必须可靠地交付给目的地，则使用IP的高层软件必须负责解决这一问题。  

2.假定在一个局域网中，计算机A广播一个ARP请求分组，希望找出计算机B的硬件地址。试问这时由哪个计算机发送ARP响应分组？将谁的硬件地址告诉计算机A？  

这要区分两种情况。第一，若计算机B和计算机A都连接在同一个局域网上，则计算机B发送ARP响应分组，给出计算机B的硬件地址。第二，若计算机B和计算机A不连接在同一个局域网上，则必须由一个连接计算机A所在局域网的路由器来响应，这时该路由器向计算机A发送ARP响应分组，给出该路由器的硬件地址。  
3.在数据报的首部中只有源IP地址和目的IP地址，而没有中间经过的路由器的IP地址，更没有指明下一跳路由器的IP地址，那么待转发的数据报怎样才能找到下一跳路由器呢？  

当路由器收到一个待转发的数据报时，由路由表得出下一跳路由器的IP地址后，不是把这个地址填入数据报，而是送交数据链路层的网络接口软件。网络接口软件负责把下一跳路由器的IP地转换成硬件地址（使用ARP），并将此硬件地址写入MAC帧的首部，然后根据此硬件地址找到下一跳路由器。可见，当发送一连事的数据报时，上述的查找路由表、用ARP得到硬件地址、把硬件地址写入MAC帧的首部等过程，将不断地重复进行，造成了一定的开销。  

那么，能不能在路由表中不使用IP地址而直接使用硬件地址呢？不行。我们要清楚，使用抽象的IP地址，本来就是为了隐蔽各种底层网络的复杂性而便于分析和研究问题，这样就不可避免地要付出一些代价，例如在选择路由时多了一些开销。反过来，若在路由表中直接使用硬件地址，则因为硬件地址是平面的，将导致路由表极为庞大，从而带来更多的麻烦。  

4.路由器实现了物理层、数据链路层、网络层，这句话的含义是什么？  

第1章中提到了网络中的两个通信结点利用协议栈进行通信的过程。发送方一层一层地把数据“包装”，接收方一层一层地把“包装”拆开，最后上交给用户。路由器实现了物理层，数据链路层和网络层的含义是指路由器有能力对这三层协议的控制信息进行识别、分析以及转换，直观的理解是路由器有能力对数据“包装”这三层协议或者“拆开”这三层协议。自然，路由器就有能力互连这三层协议不同的两个网络。  
# 第5章传输层  

# 【考纲内容】  

（一）传输层提供的服务传输层的功能：传输层寻址与端口：无连接服务和面向连接服务（二）UDPUDP数据报：UDP检验（三）TCPTCP段：TCP连接管理：TCP可靠传输：TCP流量控制与拥塞控制  

# 【复习提示】  

传输层是整个网络体系结构中的关键层次。要求掌握传输层在计算机网络中的功能、工作方式及原理等，掌握UDP及TCP（如首部格式、可靠传输、流量控制、拥塞控制、连接管理等）。其中，TCP报文分析、连接管理、流量控制与拥塞控制机制，出选择题、综合题的概率均较大，因此要将其工作原理透彻掌握，以便能在具体的题目中灵活运用。  

# 5.1传输层提供的服务  

# 5.1.1传输层的功能  

数据链路层提供链路上相邻结点之间的逻辑通信，网络层提供主机之间的逻辑通信。传输层位于网络层之上、应用层之下，它为运行在不同主机上的进程之间提供逻辑通信。传输层属于面向通信部分的最高层，同时也是用户功能中的最低层。显然，即使网络层协议不可靠（网络层协议使分组去失、混乱或重复），传输层同样能为应用程序提供可靠的服务。  

从图5.1可看出，网络的边缘部分的两台主机使用网络的核心部分的功能进行端到端的通信时，只有主机的协议栈才有传输层，而路由器在转发分组时都只用到下三层的功能（即在通信子网中没有传输层，传输层只存在于通信子网以外的主机中）。传输层的功能如下。  

# 1.应用进程之间的逻辑通信  

从网络层来说，通信的双方是两台主机，IP数据报的首部给出了这两台主机的IP地址。但“两台主机之间的通信”实际上是两台主机中的应用进程之间的通信。应用进程之间的通信又称端到端的逻辑通信。IP协议虽然能把分组送到自的主机，但这个分组还停留在主机的网络层，而没有交付给主机中的进程。从传输层来看，通信的真正端点不是主机而是主机中的进程  
# 2.复用和分用  

复用是指发送方不同的应用进程都可以使用同一个传输层协议传送数据。分用是指接收方的传输层在剥去报文的首部后能够把这些数据正确交付到目的应用进程。  

# 注意  

网络层也有复用和分用的功能，但网络层的复用是指发送方不同协议的数据都可被封装成IP数据报发送出去，分用是指接收方的网络层在剥去首部后把数据交付给相应的协议。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/63d78670549561819a300f6b9fc62e30df373cce7e510de756f34b967bc87bb0.jpg)  
图5.1传输层为相互通信的进程提供逻辑通信  

# 3.检错检测  

传输层要对收到的报文（首部和数据部分）进行差错检测。对于TCP协议，若接收方发现报文段出错，则要求发送方重发该报文段。对于UDP协议，若接收方发现数据报出错，则直接丢弃。在网络层，IP数据报首部中的检验和字段只检验首部是否出错，而不检查数据部分。  

# 4.提供面向连接和无连接的传输协议  

传输层向高层用户屏蔽了低层网络核心的细节（如网络拓扑、路由协议等），它使应用进程看见的是在两个传输层实体之间好像有一条端到端的逻辑通信信道，这条逻辑通信信道对上层的表现却因传输层协议不同而有很大的差别。当传输层采用面向连接的TCP协议时，尽管下面的网络是不可靠的（只提供尽最大努力的服务），但这种逻辑通信信道就相当于一条全双工的可靠信道。但当传输层采用无连接的UDP协议时，这种逻辑通信信道仍然是一条不可靠信道。  

而网络层无法同时实现两种协议（即在网络层要么只提供面向连接的服务，如虚电路；要么只提供无连接服务，如数据报，而不可能在网络层同时存在这两种方式）。  

# 5.1.2传输层的寻址与端口  

# 1.端口的作用  

端口能让应用层的各种进程将其数据通过端口向下交付给传输层，以及让传输层知道应当将其报文段中的数据向上通过端口交付给应用层相应的进程。端口在传输层的作用类似于IP地址在网络层的作用，只不过IP地址标识的是主机，而端口标识的是主机中的应用进程。  
数据链路层的服务访问点为顿的“类型”字段，网络层的服务访问点为IP数据报的“协议”字段，传输层的服务访问点为“端口号”字段，应用层的服务访问点为“用户界面”。  

在协议栈层间的抽象的协议端口是软件端口，它与路由器或交换机上的硬件端口是完全不同的概念。硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层的各种协议进程与传输实体进行层间交互的一种地址。传输层使用的是软件端口。  

# 2.端口号  

应用进程通过端口号进行标识，端口号长度为16比特，能够表示65536 $(2^{16}$ ）个不同的端口号。端口号只其有本地意义，即端口号只标识本计算机应用层中的各进程，在因特网中不同计算机的相同端口号是没有联系的。根据端口号范围可将端口分为两类：  

1）服务器端使用的端口号。它又分为两类，最重要的一类是熟知端口号，数值为 $\sim\!1023$ IANA（互联网地址指派机构）把这些端口号指派给了TCP/IP最重要的一些应用程序，让所有的用户都知道。另一类称为登记端口号，数值为 $1024\!\sim\!49151$ ，它是供没有熟知端口号的应用程序使用的，使用这类端口号必须在IANA登记，以防止重复。一些常用的熟知端口号如下：  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/e1544960964df4d9da3367ec224ca92c1bb3a1058ebde23539b5c5d0aa0c544a.jpg)  

2）客户端使用的端口号，数值为 $49152\!\sim\!65535$ 。因为这类端口号仅在客户进程运行时才动态地选择，所以又称短暂端口号。当服务器进程收到客户进程的报文时，就知道了客户进程所使用的端口号，因而可以把数据发送给客户进程。通信结束后，刚用过的客户端口号就不复存在，这个端口号就可以供其他客户进程使用。  

# 3.套接字  

在网络中通过IP地址来标识和区别不同的主机，通过端口号来标识和区分一台主机中的不同应用进程，端口号拼接到IP地址即构成套接字（Socket）。在网络中采用发送方和接收方的套接字来识别端点。套接字，实际上是一个通信端点，即  

它唯一地标识网络中的一台主机上的一个应用进程。  

在网络通信中，主机A发给主机B的报文包含目的端口号和源端口号，源端口号是“返回地址”的一部分，即当主机B需要发回一个报文给主机A时，主机B到主机A的报文中的目的端口号便是主机A到主机B的报文中的源端口号（完全的返回地址是主机A的IP地址和源端口号）  

# 5.1.3无连接服务与面向连接服务  

TCP/IP协议族在IP层之上使用了两个传输协议：一个是面向连接的传输控制协议（TCP），采用TCP时，传输层向上提供的是一条全双工的可靠逻辑信道；另一个是无连接的用户数据报协议（UDP），采用UDP时，传输层向上提供的是一条不可靠的逻辑信道。  

TCP提供面向连接的可靠服务，通信双方在传送数据之前必须先建立连接，然后基于此连接进行可靠数据传输，数据传输结束后要释放连接。TCP不提供广播或多播服务。TCP为了实现可靠数据传输，就必须增加许多措施，如确认、流量控制、计时器及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。因此TCP主要适用于可靠性更重要的场合，如文件传输协议（FTP）、超文本传输协议（HTTP）、远程登录（TELNET）等。  

UDP提供无连接的不可靠服务，通信双方在传送数据之前不需要建立连接，接收方的传输层在收到UDP用户数据报后，无须给发送方发回任何确认。UDP在IP层之上仅提供两个附加服务：多路复用和对数据的错误检查。IP层知道怎样把分组投递给一台主机，但不知道怎样把它们投递给主机上的具体应用。UDP在传送数据之前不需要先建立连接，远程主机的传输层收到UDP报文后，不需要给出任何确认。因为UDP比较简单，所以执行速度比较快、实时性好。使用UDP的应用主要包括小文件传送协议（TFTP）、DNS、SNIMP和实时传输协议（RTP）。  
表5.1所示为一些典型互联网应用所用的TCP/IP应用层协议和传输层协议。  

表5.1一些典型互联网应用所用的TCP/IP应用层协议和传输层协议
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/31e145544e04ef12547e4868bcdfac5ddf5c7a417aa2b6348a1ff3570218580d.jpg)  

# 注意  

I)IP数据报和UDP数据报的区别：IP数据报在网络层要经过路由器的存储转发；而UDP数据报在传输层的端到端的逻辑信道中传输，封装成IP数据报在网络层传输时，UDP数据报的信息对路由器是不可见的。  

2）TCP和网络层虚电路的区别：TCP报文段在传输层抽象的逻辑信道中传输，对路由器不可见；虚电路所经过的交换结点都必须保存虚电路状态信息。在网络层若采用虚电 路方式，则无法提供无连接服务；而传输层采用TCP不影响网络层提供无连接服务。  


# 5.2UDP 协议  

# 5.2.1UDP数据报  

1.UDP概述  

UDP仅在IP层的数据报服务之上增加了两个最基本的功能：复用和分用，以及差错检测。  
若应用开发者选择UDP而非TCP，则应用程序几乎直接与IP打交道。为什么应用开发者宁愿在UDP之上构建应用，也不选择TCP？既然TCP提供可靠的服务，而UDP不提供，则TCP总是首选吗？答案是否定的，因为有很多应用更适合用UDP，主要因为UDP具有如下优点：  

>#### pro：UDP协议的特点（2014）  

1）UDP无须建立连接。因此UDP不会引入建立连接的时延。试想若DNS运行在TCP而非UDP上，则DNS的速度会慢很多。HTTP使用TCP而非UDP，是因为对于基于文本数据的Web网页来说，可靠性是至关重要的。2）无连接状态。TCP需要在端系统中维护连接状态。此连接状态包括接收和发送缓存、拥塞控制参数和序号与确认号的参数。而UDP既不维护连接状态，也不跟踪这些参数。因此，当某些专用服务器使用UDP时，一般都能支持更多的活动客户机。3）UDP的首部开销小。TCP有20B的首部开销，而UDP仅有8B的开销。4）UDP没有拥塞控制，因此网络中的拥塞不会影响源主机的发送速率。某些实时应用要求源主机以稳定的速率发送数据，能容忍一些数据的丢失，但不允许有太大的时延。5）UDP支持一对一、一对多、多对一和多对多的交互通信。  

UDP常用于一次性传输较少数据的网络应用，如DNS、SNMP等，因为对于这些应用，若采用TCP，则将为连接创建、维护和拆除带来不小的开销。UDP也常用于多媒体应用（如IP电 话、实时视频会议、流媒体等），显然，可靠数据传输对这些应用来说并不是最重要的，但TCP的拥塞控制会导致数据出现较大的延迟，这是它们不可容忍的。  

UDP不保证可靠交付，但这并不意味着应用对数据的要求是不可靠的，所有维护可靠性的工作可由用户在应用层来完成。应用开发者可根据应用的需求来灵活设计自己的可靠性机制。  

UDP是面向报文的。发送方UDP对应用层交下来的报文，在添加首部后就向下交付给IP层，一次发送一个报文，既不合并，也不拆分，而是保留这些报文的边界；接收方UDP对IP层交上来UDP数据报，在去除首部后就原封不动地交付给上层应用进程，一次交付一个完整的报文。因此报文不可分割，是UDP数据报处理的最小单位。因此，应用程序必须选择合适大小的报文，若报文太长，UDP把它交给IP层后，可能会导致分片：若报文太短，UDP把它交给IP层后，会使IP数据报的首部的相对长度太大，两者都会降低IP层的效率。  

# 2.UDP的首部格式  

UDP数据报包含两部分：首部字段和用户数据字段。UDP首部有8B，由4个字段组成，每个字段的长度都是2B，如图5.2所示。各字段意义如下：  

>#### pro：UDP首部格式及各字段意义（2018）  

1）源端口。源端口号。在需要对方回信时选用，不需要时可用全0。2）目的端口。目的端口号。这在终点交付报文时必须使用到，  

>#### pro： UDP首部的长度（2021)  

3）长度。UDP数据报的长度（包括首部和数据），其最小值是8（仅有首部）。4）检验和。检测UDP数据报在传输中是否有错。有错就丢弃。该字段是可选的，当源主机不想计算检验和时，则直接令该字段为全0。当传输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过应的端口，上交最后的终点一一应用进程，如图5.3所示。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/da63d7c9b93503146918383294c5c15589fdbdc37358c5de93970ddb49063021.jpg)  
图5.2UDP数据报格式  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/a16cc2056a05a15b10c395b7339bc3ac5fd58814468389f9a0015024fd2be756.jpg)  
图5.3UDP基于端口的分用  

若接收方UDP发现收到的报文中的自的端口号不正确（即不存在对应于端口号的应用进程），则就丢弃该报文，并由ICMP发送“端口不可达”差错报文给发送方。  

# 5.2.2 UDP检验  

在计算检验和时，要在UDP数据报之前增加12B的伪首部，伪首部并不是UDP的真正首部。只是在计算检验和时，临时添加在UDP数据报的前面，得到一个临时的UDP数据报。检验和就是按照这个临时的UDP数据报来计算的。伪首部既不向下传送又不向上递交，而只是为了计算检验和。图5.4给出了UDP数据报的伪首部各字段的内容。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/05fa857d9ae050353446295e04e96bef0c74167c8553e5cf4439dd5c06e12f8d.jpg)  
图5.4UDP数据报的首部和伪首部  

UDP计算检验和的方法和计算IP数据报首部检验和的方法相似。不同的是：IP数据报的检验和只检验IP数据报的首部，但UDP的检验和要将首部和数据部分一起检验。  

UDP计算检验和的方法：发送方首先把全O放入检验和字段并添加伪首部，然后把UDP数据报视为许多16位的字串接起来。若UDP数据报的数据部分不是偶数个字节，则要在末尾填入一个全0字节（但此字节不发送）。然后按二进制反码计算出这些16位字的和，将此和的二进制反码写人检验和字段，并发送。接收方把收到的UDP数据报加上伪首部（若不为偶数个学节，则还需要补上全0字节）后，按二进制反码求这些16位字的和。当无差错时其结果应为全1，否则就表明有差错出现，接收方就应该去弃这个UDP数据报。  

图5.5给出了一个计算UDP检验和的例子。本例中，UDP数据报的长度是15B（不含伪首部），因此需要添加一个全0字节。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/9a474cc8b394cdcf814dda506d8775a8ef67f54081079a382c666e8607f4cb96.jpg)  
图5.5计算UDP检验和的例子  

# 注意  

1）检验时，若UDP数据报部分的长度不是偶数个字节，则需填入一个全0字节，如图5.5所示。但是此字节和伪首部一样，是不发送的。  

2）若UDP检验和检验出UDP数据报是错误的，则可以丢弃，也可以交付给上层，但是需要附上错误报告，即告诉上层这是错误的数据报  

3）通过伪首部，不仅可以检查源端口号、目的端口号和UDP用户数据报的数据部分，还可以检查IP数据报的源IP地址和目的地址。  

这种简单的差错检验方法的校错能力并不强，但它的好处是简单、处理速度快。  
  

# 5.3TCP协议  

# 5.3.1TCP协议的特点  

TCP是在不可靠的IP层之上实现的可靠的数据传输协议，它主要解决传输的可靠、有序、无丢失和不重复问题。TCP是TCP/IP体系中非常复杂的一个协议，主要特点如下：  

1）TCP是面向连接的传输层协议，TCP连接是一条逻辑连接。2）每一条TCP连接只能有两个端点，每一条TCP连接只能是一对一的。3）TCP提供可靠交付的服务，保证传送的数据无差错、不丢失、不重复且有序。4）TCP提供全双工通信，允许通信双方的应用进程在任何时候都能发送数据，为此TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双向通信的数据。发送缓存用来暂时存放以下数据： $\textcircled{\scriptsize{1}}$ 发送应用程序传送给发送方TCP准备发送的数据： $\circledcirc$ TCP已发送但尚未收到确认的数据。接收缓存用来暂时存放以下数据： $\textcircled{\scriptsize{1}}$ 按序到达但尚未被接收应用程序读取的数据： $\circledcirc$ 不按序到达的数据。5）TCP是面向字节流的，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但  

TCP把应用程序交下来的数据仅视为一连串的无结构的字节流。  

TCP和UDP在发送报文时所采用的方式完全不同。UDP报文的长度由发送应用进程决定，而TCP报文的长度则根据接收方给出的窗口值和当前网络拥塞程度来决定。若应用进程传送到TCP缓存的数据块太长，则TCP就把它划分得短一些再传送；若太短，则TCP也可等到积累足够多的字节后再构成报文段发送出去。关于TCP报文的长度问题，后面会详细讨论。  

# 5.3.2TCP报文段  

TCP传送的数据单元称为报文段。TCP报文段既可以用来运载数据，又可以用来建立连接、释放连接和应答。一个TCP报文段分为首部和数据两部分，整个TCP报文段作为IP数据报的数据部分封装在IP数据报中，如图5.6所示。其首部的前20B是固定的。TCP首部最短为20B，后面有 $4N$ 字节是根据需要而增加的选项，长度为4B的整数倍。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/4f25e5e7af600a926e06cfbeecdb4d247bc24f97f4e1b6d8267cb4459a094260.jpg)  
图5.6TCP报文段  

TCP的全部功能体现在其首部的各个字段中，各字段意义如下：  

>#### pro：TCP报文段首部中各字段的分析（2012）  

1）源端口和目的端口。各占2B。分别表示发送方和接收方使用的端口号。  

>#### pro：TCP首部中序号、确认号的含义（2009、2016）  

2）序号。占4B，范围为 $0{\sim}2^{32}\!-\!1$ ，共 $2^{32}$ 个序号。TCP连接中传送的字节流中的每个字节都要按顺序编号，序号字段值指的是本报文段所发送的数据的第一个字节的序号。例如，一报文段的序号字段值是301，而携带的数据共有100B，表明本报文段的数据的最后一个字节的序号是400，因此下一个报文段的数据序号应从401开始。  

3）确认号。占4B，是期望收到对方下一个报文段的第一个数据字节的序号。若确认号为 $N,$ 则表明到序号 $N\!-\!1$ 为止的所有数据都已正确收到。  

例如，B正确收到了A发送过来的一个报文段，其序号字段是501，而数据长度是200B（序号 $501{\sim}700)$ ，这表明B正确收到了A发送的到序号700为止的数据。因此B期望收到A的下一个数据序号是701，于是B在发送给A的确认报文段中把确认号置为701。  

>#### pro：TCP首部的最小长度（2021)  

4）数据偏移（即首部长度）。占4位，这里不是1IP数据报分片的那个数据偏移，而是表示首部长度（首部中还有长度不确定的选项字段），它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。“数据偏移”的单位是32位（以4B为计算单位）。因为4位二进制数能表示的最大值为15，所以TCP首部的最大长度为 $60\mathrm{B}$  

5）保留。占6位，保留为今后使用，但目前应置为0。  

6）紧急位URG。当 $\mathrm{{URG}}\!=\!1$ 时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送（相当于高优先级的数据）。紧急数据被插入到报文段数据的最前面，而  
在紧急数据后面的数据仍是普通数据，因此要与首部中的紧急指针字段配合使用。  

7）确认位ACK。仅当 $\mathrm{ACK}\!=\!1$ 时确认号字段才有效。当 $\mathrm{ACK}\!=\!0$ 时，确认号无效。TCP规定，在连接建立后所有传送的报文段都必须把ACK置1。  

8）推送位PSH（Push）。两个应用进程进行交互式通信时，都希望在键入一个命令后立即就能收到对方的响应，此时发送方TCP把PSH置1，接收方TCP收到 $\mathrm{PSH}\!=\!1$ 的报文段后，就尽快交付给接收应用进程，而不再等到整个缓存都填满了后再向上交付。  

9）复位位RST（Reset）。当 $\mathrm{RST}\!=\!1$ 时，表示TCP连接中出现严重差错（如主机崩溃等），必须释放连接，然后重新建立传输连接。此外，它还可用于拒绝一个非法的报文段。  

IU）位DIIN。= $\mathrm{{SYN}}\!=\!1$ 时衣小达定一十迁按请水或迁按按文报义。  

当 $\mathrm{{SYN}}\!=\!1$ ， $\scriptstyle\mathrm{ACK}\,=\,0$ 时，表明这是一个连接请求报文，若对方同意建立连接，则应在响应报文中使用 $\mathrm{{SYN}}\!=\!1$ ， $\mathrm{ACK}\!=\!1$ 。关于连接的建立和释放，下一节会详细讨论。  

11）终止位FIN（Finish）。用来释放一个连接。当 $\mathrm{FIN}\!=\!1$ 时，表明此报文段的发送方的数据已发送完毕，并要求释放传输连接。  

12）窗口。占2B，范围为 $0{\sim}2^{16}\mathrm{-}1$ 。窗口值告诉对方，从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（以字节为单位）。接收方的数据缓存空间是有限的，因此窗口值作为接收方让发送方设置其发送窗口的依据。例如，设确认号是701，窗口字段是1000。这表明，从701号算起，发送此报文段的一方还有接收1000字节数据（字节序号为 $701\!\sim\!1700$ ）的接收缓存空间。  

13）检验和。占2B。检验和字段检验的范围包括首部和数据两部分。在计算检验和时，和UDP一样，要在TCP报文段的前面加上12B的伪首部（只需将UDP伪首部的协议字段的17改成6，UDP长度字段改成TCP长度，其他的和UDP一样）。  

14）紧急指针。占2B。紧急指针仅在 $\mathrm{{URG}}\!=\!1$ 时才有意义，它指出本报文段中的紧急数据的字节数（紧急数据在报文段数据的最前面）。也就是说，使窗口为零也可以发送紧急数据。  

15）选项。长度可变，最长可达 $40\mathrm{B}$ 。当不使用选项时，TCP首部长度是20B。TCP最初只规定了一种选项，即最大报文段长度（Maximum Segment Size，MSS）。MSS是TCP报文段中的数据字段的最大长度（注意仅仅是数据字段）。  

16）填充。这是为了使整个首部长度是4B的整数倍。  

# 5.3.3TCP连接管理  

TCP是面向连接的协议，因此每个TCP连接都有三个阶段：连接建立、数据传送和连接释放。TCP连接的管理就是使运输连接的建立和释放都能正常进行。  

在TCP连接建立的过程中，要解决以下三个问题：  

1）要使每一方能够确知对方的存在。  

2）要允许双方协商一些参数（如最大窗口值、是否使用窗口扩大选项、时间戳选项等）。  

TCP把连接作为最基本的抽象，每条TCP连接有两个端点，TCP连接的端点不是主机，不是主机的IP地址，不是应用进程，也不是传输层的协议端口。TCP连接的端口即为套接字（Socket），每一条TCP连接唯一地被通信的两个端点（即两个套接字）所确定。还应注意：同一个IP地址可以有多个不同的TCP连接，而同一个端口号也可以出现在多个不同的TCP连接中。TCP连接的建立采用客户/服务器模式。主动发起连接建立的应用进程称为客户（Client），而被动等待连接建立的应用进程称为服务器（Server）。  
# 1.TCP连接的建立  

连接的建立经历以下3个步骤，通常称为“三次握手”，如图5.7所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/f3d6b28ee03e01ed9257ed21d0c6482a0056ae9c32f87658dd9c210a0ae313ca.jpg)  
图5.7用“三次握手”建立TCP连接  

连接建立前，服务器处于LISTEN（收听）状态，等待客户的连接请求。命题追踪TCP连接建立的报文段中各字段的分析（2011、2012、2016、2019）  

第一步：客户机的TCP首先向服务器的TCP发送连接请求报文段。这个报文段的首部中的同步位 $\mathrm{{SYN}}\!=\!1$ ，同时选择一个初始序号 ${\mathrm{secq}}\!=\!x$ TCP规定，SYN报文段不能携带数据，但要消耗掉一个序号。这时，客户机进入SYN-SENT（同步已发送）状态。  

第二步：服务器的TCP收到连接请求报文段后，如同意建立连接，则向客户机发回确认，并为该TCP连接分配缓存和变量。在确认报文段中，把SYN位和ACK位都置1，确认号是 $\operatorname{ack}\!=\!x\!+1$ 同时也为自己选择一个初始序号 ${\mathrm{setminus}}=y$ 。注意，确认报文段不能携带数据，但也要消耗掉一个序号。这时，服务器进入SYN-RCVD（同步收到）状态。  

第三步：当客户机收到确认报文段后，还要向服务器给出确认，并为该TCP连接分配缓存和变量。确认报文段的ACK位置1，确认号 $\mathsf{a c k}\!=\!y^{+}\,!$ ，序号 ${\mathrm{sep}}\!=\!x+1$ 。该报文段可以携带数据，若不携带数据则不消耗序号。这时，客户机进入ESTABLISHED（已建立连接）状态。  

当服务器收到来自客户机的确认后，也进入ESTABLISHED状态。  

成功进行以上三步后，就建立了TCP连接，接下来就可以传送应用层数据。TCP提供的是全双工通信，因此通信双方的应用进程在任何时候都能发送数据。  

# 2.TCP连接的释放  

天下没有不散的筵席，TCP同样如此。参与TCP连接的两个进程中的任何一个都能终止该连接。TCP连接释放的过程通常称为“四次挥手”，如图5.8所示。  

第一步：客户机打算关闭连接时，向其TCP发送连接释放报文段，并停止发送数据，主动关闭TCP连接，该报文段的终止位FIN置1，序号 ${\mathrm{setminus}}\!=\!u$ ，它等于前面已传送过的数据的最后一个字节的序号加1，FIN报文段即使不携带数据，也要消耗掉一个序号。这时，客户机进入FIN-WAIT-1（终止等待1）状态。TCP是全双工的，即可以想象为一条TCP连接上有两条数据通路，发送FIN的一端不能再发送数据，即关闭了其中一条数据通路，但对方还可以发送数据。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/55b5809743209b4220cf1a6af47b8f0bad83f3d69d445b181caa5341bfaaae47.jpg)  
图5.8用“四次挥手”释放TCP连接  

第二步：服务器收到连接释放报文段后即发出确认，确认号a $\mathrm{z}\!\stackrel{}{_{=}}\!u+1$ ，序号 ${\mathfrak{s e q}}\!=\!v$ ，等于它前面已传送过的数据的最后一个字节的序号加1。然后服务器进入CLOSE-WAIT（关闭等待）状态。此时，从客户机到服务器这个方向的连接就释放了，TCP连接处于半关闭状态。但服务器若发送数据，客户机仍要接收，即从服务器到客户机这个方向的连接并未关闭。客户机收到来自服务器的确认后，进入FIN-WAIT-2（终正等待2）状态，等待服务器发出的连接释放报文段。  

>#### pro：TCP连接释放过程中状态的变化（2021）  

第三步：若服务器已经没有要向客户机发送的数据，就通知TCP释放连接，此时，其发出 $\mathrm{FIN}\!=\!1$ 的连接释放报文段。设该报文段的序号为 $w$ （处于半关闭状态的服务器可能又发送了一些数据），还必须重复发送上次已发送的确认号 $\operatorname{ack}\!=\!u\!+1$ 。这时服务器进入LAST-ACK（最后确认）状态。  

>#### pro：TCP连接释放的过程及状态变化的时间分析（2016、2022）  

第四步：客户机收到连接释放报文段后，必须发出确认，之后进入TIME-WAIT（时间等待）状态。该报文段的确认位ACK置1，确认号 $\operatorname{ack}\!=\!w+1$ ，序号 $\scriptstyle{\mathrm{seq}}\,=\,u\,+\,1$ 。服务器收到该确认报文段后就进入CLOSED（连接关闭）状态。客户机进入TIME-WAIT状态后，还要经过时间等待计 2 MSL（Maximum Segment Lifetime，最长报文段寿命）后，才进入CLOSED状态。若服务器收到连接释放请求后不再发送数据，则从客户机发出FIN报文段时刻算起，客户机释放连接的最短时间为 $1\,\mathrm{RTT}+2\,\mathrm{MSL}$ ，服务器释放连接的最短时间为1.5RTT。  

除时间等待计时器外，TCP还设有一个保活计时器。设想TCP双方已建立连接，但后来客户主机突然出现故障。显然，服务器以后就不能再收到客户发来的数据。因此，应当有措施使服务器不要再白白等待下去，这个问题就可以使用保活计时器来解决。  
对上述TCP连接建立和释放的总结如下：  

1）建立连接。分为3步： $\textcircled{\scriptsize{1}}$   $)\,\mathrm{{SYMN}}\!=\!1$   ${\mathrm{secq}}\!=\!x$   $\begin{array}{r}{\mathrm{(\mathcal{Q})\;S Y N=1,\;\;A C K=1,\;\;s e q=}y,\;\;\mathrm{ack}=x+1\;\mathrm{s}}\end{array}$   $(\!)\operatorname{ACK}\,{=}\,1\,,\,\,\,\operatorname{neq}\,{=}\,x\,{+}\,1\,,\,\,\,\operatorname{ack}\,{=}\,y\,{+}\,1\,.$  

2）释放连接。分为4步  

$\begin{array}{r}{\mathrm{\bf(\mathbb{D})\;F I N}\!=\!1\,,\;\;\mathrm{seq}\!=\!u\!\circ}\end{array}$   $\operatorname{(2)ACK}=1\,,\;\;\operatorname{neq}=\nu\,,\;\;\operatorname{ack}=u+1\,.$   $(\!)\operatorname{FIN}\,{=}\,1\,,\,\,\,\operatorname{ACK}\,{=}\,1\,,\,\,\,\operatorname{sq}\,{=}\,w\,,\,\,\,\operatorname{ack}\,{=}\,u\,{+}\,1\,.$   $(\!4\!)\operatorname{ACK}\,{=}\,1\,,\,\,\,\operatorname{neq}\,{=}\,u\,{+}\,1\,,\,\,\,\operatorname{ack}\,{=}\,w\,{+}\,1\,.$  

选择题喜欢考查（关于连接建立和释放的题目，ACK、SYN、FIN都等于1），请牢记。  

# 5.3.4TCP可靠传输  

TCP在不可靠的IP层之上建立一种可靠数据传输服务。TCP提供的可靠数据传输服务保证接收方从缓存区读出的字节流与发送方发出的字节流完全一样。TCP使用了检验、序号、确认和重传等机制来达到这一目的。其中，TCP的检验机制与UDP一样，这里不再赘述。  

命题追踪TCP的确认机制，序号和确认号的含义（2011、2012、2013）  

1.序号  

TCP首部的序号字段用来保证数据能有序提交给应用层，TCP把数据视为一个无结构但有序的字节流，序号建立在传送的字节流之上，而不建立在报文段之上。  

TCP连接传送的数据流中的每个字节都编上一个序号。序号字段的值是指本报文段所发送的数据的第一个字节的序号。如图5.9所示，假设A和B之间建立了一条TCP连接，A的发送缓存区中共有10B，序号从0开始标号，第一个报文段包含第 $_{0\sim2}$ 个字节，则该TCP报文段的序号是0，第二个报文段的序号是3。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c26ac704f59eca3c51a2c5c371f1336b60b64260c34e4d2227d63e9f9712d1c8.jpg)  
图5.9A的发送缓存区中的数据划分成TCP段  

2.确认  

TCP首部的确认号是期望收到对方的下一个报文段的数据的第一个字节的序号。在图5.9中，若接收方B已收到第一个报文段的数据，此时B希望收到的下一个报文段的数据是从第3个字节开始的，则B发送给A的报文段中的确认号字段应为3。发送方缓存区会继续存储那些已发送但未收到确认的报文段，以便在需要时重传。  

TCP默认使用累积确认，即TCP只确认数据流中至第一个丢失字节为止的字节。例如，在图5.9中，接收方B收到了A发送的包含字节 $_{0\sim2}$ 及字节 $6\!\sim\!7$ 的报文段。由于某种原因，B还未收到字节3～5的报文段，此时B仍在等待字节3（和其后面的字节），因此B到A的下一个报文段将确认号字段置为3。  

# 3.重传  

有两种事件会导致TCP对报文段进行重传：超时和余ACK。  
（1）超时  

TCP每发送一个报文段，就对这个报文段设置一个超时计时器。计时器设置的重传时间到期但还未收到确认时，就要重传这一报文段。  

因为TCP的下层是互联网环境，IP数据报所选择的路由变化很大，所以传输层的往返时延的方差也很大。为了计算超时计时器的重传时间，TCP采用一种自适应算法，它记录一个报文段发出的时间，以及收到相应确认的时间，这两个时间之差称为报文段的往返时间（Round-TripTime，RTT）。TCP维护了RTT的一个加权平均往返时间RTTS，它会随新测量RTT样本值的变化而变化。显然，超时计时器设置的超时重传时间（RetransmissionTime-Out，RTO）应略大于RTTS，但也不能大太多，否则当报文段丢失时，TCP不能很快重传，导致数据传输时延大。  

（2）冗余ACK（冗余确认）  

超时触发重传存在的一个问题是超时周期往往太长。所幸的是，发送方通常可在超时事件发生之前通过注意所谓的冗余ACK来较好地检测丢包情况。冗余ACK就是再次确认某个报文段的ACK，而发送方先前已经收到过该报文段的确认。例如，发送方A发送了序号为1、2、3、4、5的TCP报文段，其中2号报文段在链路中丢失，它无法到达接收方B。因此3、4、5号报文段对于B来说就成了失序报文段。TCP规定每当比期望序号大的失序报文段到达时，就发送一个究余ACK，指明下一个期待字节的序号。在本例中，3、4、5号报文段到达B，但它们不是B所期望收到的下一个报文段，于是B就发送3个对1号报文段的余ACK，表示自己期望接收2号报文段。TCP规定当发送方收到对同一个报文段的3个究余ACK时，就可以认为跟在这个被确认报文段之后的报文段已经丢失。就前面的例子而言，当A收到对于1号报文段的3个究余ACK时，它可以认为2号报文段已经去失，这时发送方A可以立即对2号报文段执行重传，这种技术通常称为快速重传。当然，余ACK还被用在拥塞控制中，这将在后面的内容中讨论。  

# 5.3.5TCP流量控制  

流量控制的功能就是让发送方的发送速率不要太快，以便让接收方来得及接收，因此可以说流量控制是一个速度匹配服务（匹配发送方的发送速率与接收方的读取速率）。  

TCP利用滑动窗口机制来实现流量控制，滑动窗口的基本原理已在第3章中介绍过，这里要介绍的是TCP如何使用窗口机制来实现流量控制。TCP要求发送方维持一个接收窗口（rwnd），接收方根据当前接收缓存的大小，动态地调整接收窗口的大小，其大小反映了接收方的容量。接收方将其放在TCP报文段首部中的“窗口”字段，以通知发送方。发送方的发送窗口不能超过接收方给出的接收窗口值，以限制发送方向网络注入报文的速率。  

>#### pro：利用接收窗口实现流量控制的过程（2016、2021）  

图5.10说明了如何利用滑动窗口机制进行流量控制。假设数据只从A发往B，而B仅向A发送确认报文段，则B可通过设置确认报文段首部中的窗口字段来将rwnd通知给A。rwnd即接收方允许连续接收的能力，单位是字节。发送方A总是根据最新收到的rwnd值来限制自己发送窗口的大小，从而将未确认的数据量控制在rwnd大小之内，保证A不会使B的接收缓存溢出。设A向B发送数据，在连接建立时，B告诉A：“我的接收窗口rwnd $=400^{\circ}$ ”。接收方B进行了三次流量控制，这三个报文段都设置了 $\mathrm{ACK}\!=\!1$ ，只有在 $\mathrm{ACK}\!=\!1$ 时确认号字段才有意义。第一次把窗口减到rwnd $=300$ ，第二次又减到rwnd $=100$ ，最后减到rwnd $=\!0$ ，即不允许发送方再发送数据。这使得发送方暂停发送的状态将持续到B重新发出一个新的窗口值为止。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/2ea4a8c799f964a7e96572594c00ed4f1536d705a7e0ede4d1ac19178b9e9412.jpg)  
图5.10利用可变窗口进行流量控制举例  

TCP为每个连接设有一个持续计时器，只要发送方收到对方的零窗口通知，就启动持续计时器。若计时器超时，就发送一个零窗口探测报文段，而对方就在确认这个探测报文段时给出现在的窗口值。若窗口仍然为零，则发送方收到确认报文段后就重新设置持续计时器。  

传输层和数据链路层的流量控制的区别是：传输层实现的是端到端，即两个进程之间的流量控制；数据链路层实现的是两个中间的相邻结点之间的流量控制。此外，数据链路层的滑动窗口协议的窗口大小不能动态变化，传输层的窗口大小则可以动态变化。  

# 5.3.6TCP拥塞控制  

拥塞控制是指防止过多的数据注入网络，保证网络中的路由器或链路不致过载。出现拥塞时，端点并不了解拥塞发生的细节，对通信的端点来说，拥塞往往表现为通信时延的增加。  

拥塞控制与流量控制的区别：拥塞控制是让网络能够承受现有的网络负荷，是一个全局性的过程，涉及所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是指点对点的通信量的控制，是个端到端的问题（接收端控制发送端），它所要做的是抑制发送端发送数据的速率，以便使接收端来得及接收。当然，拥塞控制和流量控制也有相似的地方，即它们都通过控制发送方发送数据的速率来达到控制效果。  

例如，某个链路的传输速率为 $10\mathrm{{Gb}}/s$ ，某大型机向一台PC以1Gb/s的速率传送文件，显然网络的带宽是足够大的，因而不存在拥塞问题，但如此高的发送速率将导致PC可能来不及接收，因此必须进行流量控制。但若有100万台PC在此链路上以1Mb/s的速率传送文件，则现在的问题就变为网络的负载是否超过了现有网络所能承受的范围。  

TCP进行拥塞控制的算法有四种：慢开始、拥塞避免、快重传和快恢复。  

发送方在确定发送报文段的速率时，既要考虑接收方的接收能力，又要从全局考虑不要使网络发生拥塞。因此，除了上节介绍的接收窗口，TCP还要求发送方维持一个拥塞窗口（cwnd），其大小取决于网络的拥塞程度，并且动态地变化。发送方控制拥塞窗口的原则：只要网络未出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去，以提高网络的利用率。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络的分组数，以缓解网络出现的拥塞。  

发送窗口的上限值应取接收窗口rwnd和拥塞窗口cwnd中较小的一个，即  
# 发送窗口的上限值  $=$  min[rwnd, cwnd]  

接收窗口的大小可根据TCP报文首部的窗口字段通知发送方，而发送方如何维护拥塞窗口呢？这就是下面讲解的慢开始和拥塞避免算法。这里假设：数据为单方向传送，对方只传送确认报文；接收方总是有足够大的缓存空间，因而发送窗口的大小由网络的拥塞程度决定。  

为了便于理解，下面采用最大报文段长度MSS作为拥塞窗口大小的单位。  

# 1.慢开始和拥塞避免  

（1）慢开始算法  

慢开始算法的思路是当发送方刚开始发送数据时，因为并不清楚网络的负荷情况，若立即把大量数据注入网络，则有可能引发网络拥塞。具体方法是：先发送少量数据探测一下，若没有发生拥塞，则适当增大拥塞窗口，即由小到大逐渐增大拥塞窗口（即发送窗口）。  

>#### pro：慢开始算法的实现过程（2014、2015）  

例如，A向B发送数据，发送方先令cwnd $=1$ ，即一个MSS。A发送第一个报文段，A收到B对第一个报文段的确认后，把cwnd从1增大到2。于是A接着发送两个报文段，A收到B对这两个报文段的确认后，把cwnd从2增大到4，下次就可一次发送4个报文段。  

慢开始的“慢”并不是指拥塞窗口cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd $=1$ ，使得发送方一开始向网络注入的报文段少（目的是试探一下网络的拥塞情况），然后逐渐增大cwnd，这对防止网络出现拥塞是一个非常有力的措施。使用慢开始算法后，每经过一个传输轮次（即往返时延RTT），cwnd就会加倍，即cwnd的值随传输轮次指数增长。为了防止cwnd增长过大而引起网络拥塞，还需要设置一个慢开始门限ssthresh（网值）。这样，当慢开始一直把cwnd增大到一个规定的ssthresh时，然后改用拥塞避免算法。  

（2）拥塞避免算法  

>#### pro：慢开始和拥塞避免算法的实现过程/慢开始门限的作用（2017、2020、2023）  

拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，具体做法是：每经过一个往返时延RTT就 把发送方的拥塞窗口cwnd加1，而不是加倍，使拥塞窗口cwnd按线性规律缓慢增长（即加法增大），这比慢升始算法的拥塞窗口增长速率要缓慢得多。  

根据cwnd的大小执行不同的算法，可归纳如下：  

当cwnd<ssthresh时，使用慢开始算法。当cwnd $>$ ssthresh时，停止使用慢开始算法而改用拥塞避免算法。当cwnd $=$ ssthresh时，既可使用慢开始算法，又可使用拥塞避免算法（通常做法）。  

（3）网络拥塞的处理  

无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（未按时收到确认），就要首先把慢开始门限ssthresh设置为出现拥塞时的发送方的cwnd值的一半（但不能小于2），然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的是迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完。  

>#### pro：慢开始和拥塞避免阶段的平均传输速率分析（2016、2023）  

慢开始和拥塞避免算法的实现过程举例如图5.11所示。初始时，拥塞窗口置为1，即cwnd $=1$ ，慢开始门限置为16，即ssthresh $=16$  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/a1450fb7a0a2a7cbc01c8a1dcf0c026c45cb4c81db6c5a4ba5ff6ac97202f4bd.jpg)  
图5.11慢开始和拥塞避免算法的实现过程  

>#### pro：  

# 慢开始/拥塞避免阶段拥塞窗口的变化分析（2016、2023）  

慢开始阶段，发送方每收到一个对新报文段的确认ACK，就把拥塞窗口cwnd值加1，也即经过每个传输轮次（RTT），cwnd呈指数规律增长。当cwnd增长到慢开始门限ssthresh时（即当cwnd $=16$ 时），就改用拥塞避免算法，cwnd按线性规律增长。  

>#### pro：当网络超时时，慢开始和拥塞避免算法的实现过程（2009、2022）  

）当cwnd $=24$ 时，网络出现超时，调整ssthresh值为12（即为超时时cwnd值的一半），同时cwnd置为1，并执行慢开始算法，当cwnd $=12$ 时，改为执行拥塞避免算法。  

# 注意  

在慢开始阶段，若2cwnd $>$ ssthresh，RT T cw nd s s thresh,而不等于2cwnd。第16个轮次时cwnd $=8$ 、ssthresh $=12$ ，则第17个轮次时cwnd $=12$ ，而不等于16。  

在慢开始和拥塞避免算法中使用了“乘法减小”和“加法增大”方法。“乘法减小”是指不论是在慢开始阶段还是在拥塞避免阶段，只要出现超时（即很可能出现了网络拥塞），就把慢开始门限值ssthresh设置为当前拥塞窗口的一半（并执行慢开始算法）。当网络频繁出现拥塞时，ssthresh值就下降得很快，以大大减少注入网络的分组数。而“加法增大”是指执行拥塞避免算法后，在收到对所有报文段的确认后（即经过一个RTT），就把拥塞窗口cwnd增加一个MSS大小，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。  

拥塞避免并不能完全避免拥塞。利用以上措施要完全避免网络拥塞是不可能的。拥塞避免是指在拥塞避免阶段把拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。  

# 2.快重传和快恢复  

有时个别报文段会在网络中丢失，但实际上网络并未发生拥塞。若发送方迟迟收不到确认，就会产生超时，并误认为网络发生了拥塞，这就导致发送方错误地启动慢开始算法，从而降低传输效率。采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失。  

（1）快重传  

>#### pro：快重传算法的原理、重传的时机（2019）  

快重传算法是使发送方尽快（尽早）进行重传，而不等超时计时器超时再重传。这就要求接收方不要等待自已发送数据时才进行捐带确认，而要立即发送确认，即使收到了失序的报文段也要立即发出对已收到报文段的重复确认。发送方一旦连续收到3个冗余ACK（即重复确认），就立即重传相应的报文段，而不等该报文段的超时计时器超时再重传。  
（2）快恢复  

快恢复算法的原理如下：当发送方连续收到3个允余ACK（重复确认）时，执行“乘法减小”方法，把慢开始门限ssthresh调整为当前cwnd的一半。这是为了预防网络发生拥塞。但发送方现在认为网络很可能没有发生（严重）拥塞，否则就不会有几个报文段连续到达接收方，也不会连续收到重复确认。因此与慢开始算法的不同之处是，它把cwnd值也调整为当前cwnd的一半（即等于ssthresh值），然后开始执行拥塞避免算法（“加法增大"），使拥塞窗口缓慢地线性增大。  

因为跳过了拥塞窗口cwnd从1起始的慢开始过程，所以被称为快恢复。快恢复算法的实现过程如图5.12所示，作为对比，虚线为慢开始的处理过程。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/62dd33f004450128a3f441728d804d8b3a69264acb169f32cceb123861070b61.jpg)  
图5.12快恢复算法的实现过程  

实际上，这四种算法同时应用在TCP拥塞控制机制中，它们使用的总结：在TCP连接建立和网络出现超时时，采用慢开始和拥塞避免算法（ssthresh $\b=$ cwnd/2，cwnd $=1$ )；当发送方收到3个冗余ACK时，采用快重传和快恢复算法（ssthresh $=$ cwnd/2，cwnd $=$ ssthresh)。  

在流量控制中，发送方发送数据的量由接收方决定；而在拥塞控制中，则由发送方自己通过检测网络状况来决定。再次提醒读者：接收方的缓存空间总是有限的。因此，发送方发送窗口的大小由流量控制和拥塞控制共同决定。当题目中同时出现接收窗口（rwnd）和拥塞窗口（cwnd）时，发送方发送窗口的实际大小是由rwnd和cwnd中较小的那一个确定的。  

 

# 5.4本章小结及疑难点  

1.MSS设置得太大或太小会有什么影响？  

规定最大报文段长度MSS，并不是考虑接收方的缓存可能放不下TCP报文段中的数据。实际上，MSS与接收窗口没有关系。TCP报文段的数据部分，至少要加上4OB的首部（TCP首部至少20B和IP首部至少20B），才能组装成一个IP数据报。若选择较小的MSS值，网络的利用率就很低。设想在极端情况下，当TCP报文段只含有1B的数据时，在IP层传输的数据报的开销至少有40B（包括TCP首部和IP首部）。这样，网络的利用率就不会超过1/41。到了数据链路层还要加上一些开销，网络的利用率还会进一步降低。但反过来，若TCP报文段很长，则在IP层传输时有可能要分解成多个短数据报片。在终点还要把收到的各个短数据报片装配成原来的TCP报文段。当传输出错时，还要进行重传。这些也都会使开销增大。  

因此，MSS应尽可能大一些，只要在IP层传输时不要再分片就行。因为IP数据报所经历的路径是动态变化的，所以在一条路径上确定的不需要分片的MSS，若改走另一条路径，则可能需要进行分片。因此最佳的MSS是很难确定的。MSS的默认值为536B，因此在互联网上的所有主机都应能接受的报文段长度是 $536+20$ （TCP固定首部长度） $=556\mathrm{B}$  

2.TCP使用的是GBN还是选择重传？  

这是一个有必要弄清的问题。前面讲过，TCP使用累积确认，这看起来像是GBN的风格。但是，正确收到但失序的报文并不会丢弃，而是缓存起来，并且发送允余ACK指明期望收到的下一个报文段，这是TCP方式和GBN的显著区别。例如，A发送了 $N$ 个报文段，其中第 $k~(k<~N)$ 个报文段丢失，其余 $N{-}1$ 个报文段正确地按序到达接收方B。使用GBN时，A需要重传分组 $k$ ，以及所有后继分组 $k+1,k+2,\cdots,N$ 。相反，TCP却至多重传一个报文段，即报文段 $k$ 。另外，TCP中提供一个SACK（SelectiveACK）选项，即选择确认选项。使用选择确认选项时，TCP看起来就和SR非常相似。因此，TCP的差错恢复机制可视为GBN和SR协议的混合体。  
# 3.为什么超时事件发生时cwnd被置为1，而收到3个冗余ACK时cwnd减半？  

大家可以从如下角度考虑。超时事件发生和收到3个究余ACK，哪个意味看网络拥塞程度更严重？通过分析不难发现，在收到3个冗余ACK的情况下，网络虽然拥塞，但至少还有ACK报文段能被正确交付。而当超时发生时，说明网络可能已经拥塞得连ACK报文段都传输不了，发送方只能等待超时后重传数据。因此，超时事件发生时，网络拥塞更严重，发送方就应该最大限度地抑制数据发送量，所以cwnd置为1：收到3个冗余ACK时，网络拥塞不是很严重，发送方稍微抑制一下发送的数据量即可，所以cwnd减半。  

# 4.为什么不采用“两次握手”建立连接呢？  

这主要是为了防止两次握手情况下已失效的连接请求报文段突然又传送到服务器而产生错误。考虑下面这种情况。客户A向服务器B发出TCP连接请求，第一个连接请求报文在网络的某个结点长时间滞留，A超时后认为报文丢失，于是再重传一次连接请求，B收到后建立连接。数据传输完毕后双方断开连接。而此时，前一个滞留在网络中的连接请求到达服务器B，而B认为A又发来连接请求，此时若使用“三次握手”，则B向A返回确认报文段，因为是一个失效的请求，所以A不予理踩，建立连接失败。若采用的是“两次握手”，则这种情况下B认为传输连接已经建立，并一直等待A传输数据，而A此时并无连接请求，因此不予理踩，这样就造成了B的资源白白浪费。  

5.为什么TCP在建立连接时不能每次都选择相同的、固定的初始序号？  

1）假定主机A和B频繁地建立连接，传送一些TCP报文段后，再释放连接，然后又不断地建立新的连接、传送报文段和释放连接。2）假定每次建立连接时，主机A都选择相同的、固定的初始序号，如选择1。3）假定主机A发出的某些TCP报文段在网络中会滞留较长时间，以致主机A超时重传这些TCP报文段。4）假定有一些在网络中滞留时间较长的TCP报文段最后终于到达主机B，但这时传送该报文段的那个连接早已释放，而在到达主机B时的TCP连接是一条新的TCP连接。  

这样，工作在新的TCP连接的主机B就有可能会接收在旧的连接传送的、已无意义的、过时的TCP报文段（因为这个TCP报文段的序号有可能正好处在当前新连接所用的序号范围之中），结果产生错误。因此，必须使得迟到的TCP报文段的序号不处在新连接所用的序号范围之中。  

这样，TCP在建立新的连接时所选择的初始序号一定要和前面的一些连接所用过的序号不同。因此，不同的TCP连接不能使用相同的初始序号。  

6.假定在一个互联网中，所有链路的传输都不出现差错，所有结点也都不会发生故障。试问在这种情况下，TCP的“可靠交付”功能是否就是多余的？  

不是多余的。TCP的“可靠交付”功能在互联网中起着至关重要的作用。至少在以下的情况下，TCP的“可靠交付”功能是必不可少的。  
1）每个IP数据报独立地选择路由，因此在到达目的主机时有可能出现失序。2）由于路由选择的计算出现错误，导致IP数据报在互联网中转圈。最后数据报首部中的生存时间（TTL）的数值下降到零。这个数据报在中途就被丢失。3）某个路由器突然出现很大的通信量，以致路由器来不及处理到达的数据报。因此有的数据报被丢弃。以上列举的问题表明：必须依靠TCP的“可靠交付”功能才能保证在目的主机的目的进程中收到正确的报文。  
# 第6章应用层  

# 【考纲内容】  

（一）网络应用模型客户/服务器模型；P2P模型  

（二）域名系统（DNS）  

层次域名空间：域名服务器：域名解析过程  

（三）文件传输协议（FTP）FTP的工作原理：控制连接与数据连接  

（四）电子邮件（E-mail）电子邮件系统的组成结构；电子邮件格式与MIME；SMTP与POP3  

# 【复习提示】  

本章内容既可以以选择题的形式考查，又可以结合其他章节的内容出综合题。所以牢固掌握本章的几个典型应用层协议是关键。我们生活中的很多网络应用都是建立在这些协议的基础上的，因此在学习时要注意联系实际，提高学习的兴趣，才会获得更好的学习效果。  

# 6.1网络应用模型  

# 6.1.1客户/服务器模型  

命题追踪C/S模型和P2P模型的特点（2019）  

在客户/服务器（ClientServer，C/S）模型中，有一个总是打开的主机称为服务器，它服务于许多来自其他称为客户机的主机请求。其工作流程如下：  

1）服务器处于接收请求的状态。  

2）客户机发出服务请求，并等待接收结果。  

3）服务器收到请求后，分析请求，进行必要的处理，得到结果并发送给客户机。  

服务器上运行着专门用来提供某种服务的程序，可同时处理多个远程或本地客户的请求。客户程序必须知道服务器程序的地址。服务器启动后就一直不断地运行着，被动等待并接收来自各地客户的请求。因此，服务器程序不需要知道客户程序的地址。  

客户/服务器模型最主要的特征是：客户是服务请求方，服务器是服务提供方。如Web应用程序，其中总是打开的Web服务器服务于运行在客户机上的浏览器的请求。当Web服务器接收到来自客户机对某对象的请求时，它向该客户机发送所请求的对象以做出响应。使用客户/服务器模型的常见应用包括Web、文件传输协议（FTP）、远程登录和电子邮件等。  
客户/服务器模型的主要特点还有：  

1）网络中各计算机的地位不平等，服务器可通过对用户权限的限制来达到管理客户机的目的。整个网络的管理工作由少数服务器担当，因此网络的管理非常集中和方便。2）客户机相互之间不直接通信。例如，在Web应用中两个浏览器并不直接通信。3）可扩展性不佳。受服务器硬件和网络带宽的限制，服务器支持的客户机数有限。  

# 6.1.2P2P模型  

在C/S模型中（图6.1），服务器性能的好坏决定了整个系统的性能，当大量用户请求服务时，服务器就必然成为系统的瓶颈。P2P模型（见图6.2）的思想是整个网络中的传输内容不再被保存在中心服务器上，每个结点都同时具有下载、上传的功能，其权利和义务都是大体对等的。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/0968413e5bed6d57bfeff2b949e4c6ede48faed1adb20a5457f23dced3514fd4.jpg)  
图6.1C/S模型  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/056de45a9156710326d6d90dbab1f59c67aa4d467d7068d514a39ca0ff6589da.jpg)  
图6.2P2P模型  

在P2P模型中，各计算机没有固定的客户和服务器划分。相反，任意一对计算机一一称为对等方（Peer），直接相互通信。实际上，P2P模型从本质上来看仍然使用客户/服务器模型，每个结点既作为客户访问其他结点的资源，又作为服务器提供资源给其他结点访问。  

与C/S模型相比，P2P模型的优点主要体现如下：1）减轻了服务器的计算压力，消除了对某个服务器的完全依赖，可以将任务分配到各个结点上，因此大大提高了系统效率和资源利用率。2）多个客户机之间可以直接共享文档。3）可扩展性好，传统服务器有响应和带宽的限制，因此只能接受一定数量的请求。4）网络健壮性强，单个结点的失效不会影响其他部分的结点。  

P2P模型也有缺点。在获取服务的同时，还要给其他结点提供服务，因此会占用较多的内存，影响整机速度。例如，经常进行P2P下载还会对硬盘造成较大的损伤。据某互联网调研机构统计，当前P2P程序已占互联网 $50\%{\sim}90\%$ 的流量，使网络变得非常拥塞，因此各大ISP（互联网服务提供商，如电信、网通等）通常都对P2P应用持反对态度。  

 

# 6.2域名系统(DNS)  

>#### pro：DNS向下依次使用的协议（2018、2021）  

域名系统（DomainNameSystem，DNS）是因特网使用的命名系统，用来把便于人们记忆的具有特定含义的主机名（如www.cskaoyan.com）转换为便于机器处理的IP地址。相对于IP地址，人们更喜欢使用具有特定含义的字符串来标识因特网上的计算机。值得注意的是，DNS系统采用客户/服务器模型，其协议运行在UDP之上，使用53号端口。  

从概念上可将DNS分为三部分：层次域名空间、域名服务器和解析器。  

# 6.2.1层次域名空间  

因特网采用层次树状结构的命名方法。采用这种命名方法，任何一个连接到因特网的主机或路由器，都有一个唯一的层次结构名称，即域名（DomainName）。域（Domain）是名字空间中一个可被管理的划分。域可以划分为子域，而子域还可以继续划分为子域的子域，这样就形成了顶级域、二级域、三级域等。每个域名都由标号序列组成，而各标号之间用点（“.”）隔开。一个典型的例子如图6.3所示，它是王道论坛用于提供WWW服务的服务器的域名，它由三个标号组成，其中标号com是顶级域名，标号cskaoyan是二级域名，标号www是三级域名。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/335d7e57f36898e0a60c2df2cb3fd7fdafea1eee6aa0d4604bcebd67d4068da1.jpg)  
图6.3一个域名的例子  

关于域名中的标号有以下几点需要注意：1）标号中的英文不区分大小写。  
2）标号中除连字符（-）外不能使用其他的标点符号。3）每个标号不超过63个字符，多标号组成的完整域名最长不超过255个字符。4）级别最低的域名写在最左边，级别最高的顶级域名写在最右边。顶级域名（Top Level Domain，TLD）分为如下三大类  

1）国家（地区）顶级域名（nTLD）。国家和某些地区的域名，如“.cn”表示中国，“us”表示美国，“uk”表示英国。2）通用顶级域名（gTLD）。常见的有“.com”（公司）、“net”（网络服务机构）、“org”（非营利性组织）、“edu”（教育机构）、和“gov”（国家或政府部门）等。  

3）基础结构域名（arpa）。用于反向域名解析，即IP地址反向解析为域名。  

图6.4展示了域名空间的树状结构。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c7c571a79927f4b59ecf1e91a76adf8317ac05d76b12b5a344e3d21ebb103c82.jpg)  
图6.4域名空间的树状结构  

在域名系统中，各级域名由其上一级的域名管理机构管理，顶级域名由因特网名称与数字地址分配机构（ICANN）管理。国家顶级域名下注册的二级域名均由该国家自行确定，每个组织都可以将它的域再分成一定数目的子域，并将这些子域委托给其他组织去管理。例如，管理cn域的中国将edu.cn子域授权给中国教育和科研计算机网（CERNET）来管理。  

# 6.2.2域名服务器  

域名到TP地址的解析是由运行在域名服务器上的程序完成的，一个服务器所负责管辖的（或有权限的）范围称为区（小于或等于“域”），一个区中的所有结点必须是能够连通的，每个区设置相应的权限域名服务器，用来保存该区中的所有主机的域名到DP地址的映射。每个域名服务器不但能够进行一些域名到ITP地址的解析，而且还必须具有连向其他域名服务器的信息。当自己不能进行域名到IP地址的转换时，能够知道到什么地方去找其他域名服务器。  

DNS使用了大量的域名服务器，它们以层次方式组织。没有一台域名服务器具有因特网上所有主机的映射，相反，该映射分布在所有的域名服务器上。有4种类型的域名服务器。  

# 1.根域名服务器  

根域名服务器是最高层次的域名服务器，所有的根域名服务器都知道所有的顶级域名服务器的域名和IP地址。根域名服务器是最重要的域名服务器，不管是哪个本地域名服务器，要对因特网上任何一个域名进行解析，只要自己无法解析，就首先要求助于根域名服务器。因特网上有13个根域名服务器，尽管我们将这13个根域名服务器中的每一个都视为单个服务器，但每个“服务器”实际上是究余服务器的集群，以提供安全性和可靠性。需要注意的是，根域名服务器用来管辖顶级域（如.com），通常它并不直接把待查询的域名直接转换成IP地址，而是告诉本地域名服务器下一步应当找哪个顶级域名服务器进行查询。  
# 2.顶级域名服务器  

这些域名服务器负责管理在该顶级域名服务器注册的所有二级域名。收到DNS查询请求时，就给出相应的回答（可能是最后的结果，也可能是下一步应当查找的域名服务器的IP地址）。  

# 3.权限域名服务器（授权域名服务器）  

每台主机都必须在权限域名服务器处登记。为了更加可靠地工作，一台主机最好至少有两个权限域名服务器。实际上，许多域名服务器都同时充当本地域名服务器和权限域名服务器。权限域名服务器总能将其管辖的主机名转换为该主机的IP地址。  

# 4.本地域名服务器  

本地域名服务器对域名系统非常重要。每个因特网服务提供者（ISP），或一所大学，甚至一所大学中的各个系，都可以拥有一个本地域名服务器。当一台主机发出DNIS查询请求时，这个查询请求报文就发送给该主机的本地域名服务器。事实上，我们在Windows系统中配置“本地连接”时，就需要填写DNS地址，这个地址就是本地DNS（域名服务器）的地址。  

DNS的层次结构如图6.5所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/5629d8bb8fb5177ee3e9a1ab880774ec6a90aeab599acde76f7da73da3ff2f16.jpg)  
图6.5DNS的层次结构  

# 6.2.3域名解析过程  

命题追踪DNS协议的作用（2021)  

域名解析是指把域名转化为IP地址的过程。当客户端需要域名解析时，通过本机的DNS客户端构造一个DNS请求报文，以UDP数据报方式发往本地域名服务器。  

域名解析有两种方式：递归查询和选代查询。（1）主机向本地域名服务器的查询都采用递归查询  

递归查询是指若主机所询问的本地域名服务器不知道被查询域名的IP地址，则本地域名服务器就以DINS客户的身份，向根域名服务器继续发出查询请求报文（即替该主机继续查询），而不是让该主机自己进行下一步的查询。两种查询方式的这一步是相同的。  

（2）本地域名服务器向其他域名服务器采用递归查询或选代查询  
>#### pro：递归查询DNS的工作原理（2010）  

递归查询的过程如图6.6（a所示，本地域名服务器只需向根域名服务器查询一次，后面的几次查询都是递归地在其他几个域名服务器之间进行的［步骤 $\scriptstyle(\mathbf{\mathcal{B}}\sim\left(\mathbf{\mathcal{C}}\right)$ ]。在步骤 $\circleddash$ 中，本地域名服务器从根域名服务器得到了所需的ⅡP地址，最后在步骤 $^\mathrm{\textregistered}$ 中，本地域名服务器把查询结果告诉发起查询的主机。因为该方法给根域名服务器造成的负载过大，所以实际中几乎不使用。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/2663a99a9e96d72925ec8df3f3c96270b6c7942f0010e486c7694ed8830a3713.jpg)  
图6.6两种域名解析方式工作原理  

>#### pro：选代查询DNS的工作原理（2016、2020）  

本地域名服务器向根域名服务器的查询通常是采用送代查询。当根域名服务器收到本地域名服务器发出的选代查询请求报文时，要么给出所要查询的IⅡP地址，要么告诉本地域名服务器：“你下一步应当向哪个顶级域名服务器进行查询”。然后让本地域名服务器进行后续的查询（而不替本地域名服务器进行后续的查询），如图6.6(b)所示。同样，顶级域名服务器收到查询报文后，要么给出所要查询的IP地址，要么告诉本地域名服务器下一步应当向哪个权限域名服务器查询。最后，知道了所要解析的域名的IP地址后，把这个结果返回给发起查询的主机。  

下面举例说明域名解析的过程。假定某客户机想获知域名为y.abc.com主机的IP地址，域名解析的过程（最多需要使用8个UDP报文：4个查询报文和4个回答报文）如下：  

$\textcircled{\scriptsize{1}}$ 客户机向其本地域名服务器发出DNS请求报文（递归查询）。 $\circledcirc$ 本地域名服务器收到请求后，查询本地缓存，若没有该记录，则以DINS客户的身份向根域名服务器发出解析请求报文（迭代查询）。 $\textcircled{3}$ 根域名服务器收到请求后，判断该域名属于.com域，将对应的顶级域名服务器dns.com的IP地址返回给本地域名服务器。 $\textcircled{4}$ 本地域名服务器向顶级域名服务器dns.com发出解析请求报文（迭代查询）。 $\circledast$ 顶级域名服务器dns.com收到请求后，判断该域名属于abc.com域，因此将对应的权限域名服务器dns.abc.com的IP地址返回给本地域名服务器。 $^\mathrm{\textregistered}$ 本地域名服务器向权限域名服务器dns.abc.com发起解析请求报文（选代查询）。 $\circleddash$ 权限域名服务器dns.abc.com收到请求后，将查询结果返回给本地域名服务器。 $\circledast$ 本地域名服务器将查询结果保存到本地缓存，同时返回给客户机。  

为了提高DINS的查询效率，并减少因特网上的DNS查询报文数量，在域名服务器中广泛地使用了高速缓存，用来缓存最近查询过的域名的相关映射信息。这样，当另一个相同的域名查询到达该DINIS服务器时，该服务器就能直接提供所要求的IP地址。因为主机名和IP地址之间的映射不是永久的，所以DNS服务器将在一段时间后去弃高速缓存中的信息。在主机中同样也很需要高速缓存，许多主机在启动时从本地域名服务器下载域名和地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到域名时才使用域名服务器。  

# 6.3文件传输协议(FTP)  

# 6.3.1FTP的工作原理  

文件传输协议（FileTransferProtocol，FTP）是因特网上使用得最广泛的文件传输协议。FTP提供交互式的访问，充许客户指明文件的类型与格式，并充许文件具有存取权限。它屏蔽了各计算机系统的细节，因而适合于在异构网络中的任意计算机之间传送文件。  
FTP提供以下功能：  

$\textcircled{\scriptsize{1}}$ 提供不同种类主机系统（硬、软件体系等都可以不同）之间的文件传输能力。 $\circledcirc$ 以用户权限管理的方式提供用户对远程FTP服务器上的文件管理能力。 $\textcircled{3}$ 以匿名FTP的方式提供公用文件共享的能力。  

>#### pro：FTP在传输层所使用的协议（2009、2018）  

FTP采用客户/服务器的工作方式，使用TCP可靠的传输服务。一个FTP服务器进程可同时为多个客户进程提供服务。FTP的服务器进程由两大部分组成：一个主进程，负责接收新的请求：另外有若干从属进程，负责处理单个请求。其工作步骤如下：  

$\textcircled{\scriptsize{1}}$ 打开熟知端口21（控制端口），使客户进程能够连接上。  

$\circledcirc$ 等待客户进程发连接请求。 $\textcircled{3}$ 启动从属进程处理客户进程发来的请求。从属进程对客户进程的请求处理完毕后即终止。  

$\textcircled{4}$ 回到等待状态，继续接收其他客户进程的请求。主进程与从属进程是并发执行的。  

FTP服务器必须在整个会话期间保留用户的状态信息。特别是服务器必须把指定的用户账户与控制连接联系起来，服务器必须追踪用户在远程目录树上的当前位置。  

# 6.3.2控制连接与数据连接  

>#### pro：控制连接和数据连接的特点（2017、2023）  

FTP在工作时使用两个并行的TCP连接（见图6.7）：一个是控制连接（服务器端口号21），一个是数据连接（服务器端口号20）。使用两个不同的端口号可以使协议更容易实现。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/c1f0808dc3aeb3e8fa2e341b8a51d60ebf4df40ec50c263cab6b38816315d50f.jpg)  
图6.7控制连接和数据连接  

# 1.控制连接  

>#### pro：控制连接的作用（2009）  

服务器监听21号端口，等待客户连接，建立在这个端口上的连接称为控制连接，用来传输控制信息（如连接请求、传送请求等）。FTP客户发出的传送请求，通过控制连接发送给服务器端的控制进程，但控制连接并不用来传送文件。在传输文件时还可以使用控制连接（如客户在传输中途发一个中止传输的命令），因此控制连接在整个会话期间一直保持打开状态。  

# 2.数据连接  

服务器端的控制进程在接收到FTP客户发送来的文件传输请求后，就创建“数据传送进程”和“数据连接”。数据连接用来连接客户端和服务器端的数据传送进程，数据传送进程实际完成文件的传送，在传送完毕后关闭“数据传送连接”并结束运行。  

数据连接有两种传输模式：主动模式PORT和被动模式PASV。PORT模式的工作原理：客户端连接到服务器的21端口，登录成功后要读取数据时，客户端随机开放一个端口，并发送命令告知服务器，服务器收到PORT命令和端口号后，通过20端口和客户端开放的端口连接，发送数据。PASV模式的不同点是，客户端要读取数据时，发送PASV命令到服务器，服务器在本地随机开放一个端口，并告知客户端，客户端再连接到服务器开放的端口进行数据传输。可见，是用PORT模式还是PASV模式，选择权在客户端。简单概括为，主动模式传送数据是“服务器”连接到“客户端”的端口；被动模式传送数据是“客户端”连接到“服务器”的端口。  
# 注意  

很多教材并未介绍这两种模式，如无特别说明可默认为采用主动模式。  

因为FTP使用了一个分离的控制连接，所以也称FTP的控制信息是带外（Out-ofband）传送的。使用FTP时，要修改服务器上的文件，就需要先将此文件传送到本地主机，然后将修改后的文件副本传送到原服务器，来回传送耗费很多时间。网络文件系统（NFS）采用另一种思路，它允许进程打开一个远程文件，并能在该文件的某个特定位置开始读写数据。这样，NFS可使用户只复制一个大文件中的一个很小的片段，而不需要复制整个大文件。  

 
# 6.4电子邮件  

# 6.4.1电子邮件系统的组成结构  

自从有了因特网，电子邮件就在因特网上流行起来。电子邮件是一种异步通信方式，通信时不需要双方同时在场。电子邮件把邮件发送到收件人使用的邮件服务器，并放在其中的收件人邮箱中，收件人可以随时上网到自已使用的邮件服务器进行读取。  

一个电子邮件系统应具有图6.8所示的三个最主要的组成构件，即用户代理（UserAgent）、邮件服务器和电子邮件使用的协议，如SMTP、POP3（或IMAP）等。  
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/dfcc3f07d050e1a4bd109677dfc892e5090689da8a858b59b160fa23ab313e71.jpg)  
图6.8电子邮件系统最主要的组成构件  

用户代理（UA）：用户与电子邮件系统的接口。用户代理向用户提供一个很友好的接口来发送和接收邮件，用户代理至少应当具有撰写、显示和邮件处理的功能。通常情况下，用户代理就是一个运行在PC上的程序（电子邮件客户端软件），常见的有Outlook和Foxmail等。  

邮件服务器：它的功能是发送和接收邮件，同时还要向发件人报告邮件传送的情况（已交付、被拒绝、丢失等）。邮件服务器以客户/服务器模式工作，但它必须能够同时充当客户和服务器。例如，当邮件服务器A向邮件服务器B发送邮件时，A就作为SMTP客户，而B是SMTP服务器；反之，当B向A发送邮件时，B就是SMTP客户，而A就是SMTP服务器。  

>#### pro：邮件发送协议和读取协议的应用（2012）  

邮件发送协议和读取协议：邮件发送协议用于用户代理向邮件服务器发送邮件或在邮件服务器之间发送邮件，如SMTP；邮件读取协议用于用户代理从邮件服务器读取邮件，如POP3。注意，SMTP用的是“推”（Push）的通信方式，即用户代理向邮件服务器发送邮件及在邮件服务器之间发送邮件时，SMTP客户将邮件“推”送到SMTP服务器。而POP3用的是“拉”（PulI）的通信方式，即用户读取邮件时，用户代理向邮件服务器发出请求，“拉”取用户邮箱中的邮件。  

电子邮件的发送、接收过程可简化为如图6.9所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/6ca073f4d9e5db6d02912d03369337bbc2dd68d517d1196365f94c02d9453f0b.jpg)  
图6.9电子邮件的发送、接收过程  

下面简单介绍电子邮件的收发过程。  

$\textcircled{\scriptsize{1}}$ 发件人调用用户代理来撰写和编辑要发送的邮件。  

$\circledcirc$ 邮件撰写完后，发件人点击“发送邮件”按钮，把发送邮件的工作全都交给用户代理来完成，就什么都不用管了。用户代理用SMTP把邮件传送给发送端邮件服务器。  

$\textcircled{3}$ 发送端邮件服务器将邮件放入邮件缓存队列中，等待发送。  

$\textcircled{4}$ 发送端邮件服务器的SMTP客户与接收端邮件服务器的SMTP服务器建立TCP连接，然后就把邮件缓存队列中的邮件依次发送出去。注意，邮件是直接传送给接收端邮件服务器的，而不会在互联网的某个中间邮件服务器落地。  

$\circledast$ 运行在接收端邮件服务器中的SMTP服务器进程收到邮件后，将邮件放入收件人的用户邮箱，等待收件人在方便时进行读取。  
$\textcircled{6}$ 收件人打算收信时，调用用户代理，使用POP3（或IMAP）协议将自己的邮件从接收端邮件服务器的用户邮箱中取回（如果邮箱中有来信的话）。  

# 6.4.2电子邮件格式与MIME  

# 1.电子邮件格式  

一个电子邮件分为信封和内容两大部分，邮件内容又分为首部和主体两部分。RFC822规定了邮件的首部格式，而邮件的主体部分则让用户自由撰写。用户写好首部后，邮件系统自动地将信封所需的信息提取出来并写在信封上，用户不需要亲自填写信封上的信息。  

邮件内容的首部包含一些首部行，每个首部行由一个关键字后跟冒号再后跟值组成。有些关键字是必需的，有些则是可选的。最重要的关键字是To和Subject。  

To是必填的关键字，后面填入一个或多个收件人的电子邮件地址。电子邮件地址的格式为：收件人邮箱名 $^{\textit{\textregistered}}$ 邮箱所在主机的域名，如abc@cskaoyan.com，abc cska oy an.com这个邮件服务器上必须是唯一的。这也就保证了该邮件地址在整个因特网上是唯一的。  

Subjiect是可选关键字，是邮件的主题，反映了邮件的主要内容。  

当然，还有一个必填的关键字是From，但它通常由邮件系统自动填入。首部与主体之间用一个空行进行分割。典型的邮件内容如下：  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/ad6c7d88b4818d5ccfd48b3f5f46a9fdfe4b14571fa005e2fce9eb9bd53a5b58.jpg)  

# 2.多用途因特网邮件扩展（MIME）  

命题追踪SMTP直接传输的内容（2018）  

因为SMTP只能传送7位ASCII码文本邮件，许多其他非英语国家的文字（如中文、俄文，甚至带重音符号的法文或德文）就无法传送，且无法传送可执行文件及其他二进制对象，所以提（Multipurpose Internet Mail Extensions，MIME）。  

MIME并未改动SMTP或取代它。当发送端发送的邮件中包含有非ASCII码数据时，不能直接使用SMTP进行传送，而要通过MIME进行转换，将非ASCII码数据转换为ASCII码数据。之后，就可以使用SMTP进行传送。接收端也要使用MIME对接收到的ASCII码数据进行逆转换，以便可以得到包含有非ASCII码数据的邮件。MIME与SMTP的关系如图6.10所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/b50f6aad5d70911c62bdd8542a01a0e00833e19a2ac698dac6e472b48a6ca867.jpg)  
图6.10SMTP与MIME的关系  
MIME主要包括以下三部分内容：  

$\textcircled{\scriptsize{1}}$ 5个新的邮件首部字段，包括MIME版本、内容描述、内容标识、传送编码和内容类型。  

$\circledcirc$ 定义了许多邮件内容的格式，对多媒体电子邮件的表示方法进行了标准化。  

$\textcircled{3}$ 定义了传送编码，可对任何内容格式进行转换，而不会被邮件系统改变。  

# 6.4.3 SMTP和POP3  

>#### pro：  

1.SMTP  

>#### pro：  

SMTP和POP3在传输层所使用的服务（2015、2018）  

SMTP的用途及特点（2013、2014）  

简单邮件传输协议（Simple Mail Transfer Protocol，SMTP）件传输的协议，它控制两个相互通信的SMTP进程交换信息。因为SMTP采用客户/服务器模式工作，所以负责发送邮件的SMTP进程就是SMTP客户，而负责接收邮件的SMTP进程就是SMTP服务器。SMTP用的是TCP连接，端口号为25。SMTP通信有以下三个阶段。  

（1）连接建立  

发件人的邮件发送到发送方邮件服务器的邮件缓存中后，SMTP客户就每隔一定时间对邮件缓存扫描一次。如发现有邮件，就与接收方邮件服务器的SMTP服务器建立TCP连接，SMTP服务器使用的熟知端口号为25。连接建立后，接收方SMTP服务器发出220Serviceready（服务就绪）。然后SMTP客户向SMTP服务器发送HELO命令，附上发送方的主机名。  

SMTP不使用中间的邮件服务器。TCP连接总是在发送方和接收方这两个邮件服务器之间直接建立，而不管它们相隔多远，不管在传送过程中要经过多少个路由器。当接收方邮件服务器因故障暂时不能建立连接时，发送方的邮件服务器只能等待一段时间后再次尝试连接。  

（2）邮件传送  

连接建立后，就可开始传送邮件。邮件的传送从MAIL命令开始，MAIL命令后面有发件人的地址。如MAILFROM:<fh@hit.edu.cn>。若SMTP服务器已准备好接收邮件，则回答250OK。下面跟着一个或多个RCPT命令，格式为RCPTTO：<收件人地址>。每发送一个RCPT命令，都应有相应的信息从SMTP服务器返回，如250OK或 $550\,\mathrm{No}$ such user here（无此用户）。  

RCPT命令的作用是，先弄清接收方系统是否已做好接收邮件的准备，然后才发送邮件，以便不至于发送了很长的邮件后才知道地址错误，进而避免浪费通信资源。  

获得OK的回答后，客户端就使用DATA命令，表示要开始传送邮件的内容。正常情况下，SMTP 354 Start mail input;endwith<CRLF>.<CRLF>。<CRLF>表示回车换行。此时SMTP客户就可开始传送邮件内容，并用<CRLF>.<CRLF>表示邮件内容的结束。  

（3）连接释放  

邮件发送完毕后，SMTP客户应发送QUIT命令。SMTP服务器返回的信息是221（服务关闭），表示SMITP同意释放TCP连接。邮件传送的全部过程就此结束。  

2.P0P3和IMAP  

邮局协议（PostOficeProtocol，POP）是一个非常简单但功能有限的邮件读取协议，现在使用的版本是POP3。POP也采用客户/服务器模式，在传输层使用TCP，端口号为110。  

接收方的用户代理必须运行POP客户程序，而接收方的邮件服务器中则运行POP服务器程序。POP有两种工作方式：“下载并保留”和“下载并删除”。在“下载并保留”方式下，用户从邮件服务器上读取邮件后，邮件依然会保存在邮件服务器上，用户可再次从服务器上读取该邮件：  
而使用“下载并删除”方式时，邮件一旦被读取，就被从邮件服务器上删除。  

另一个邮件读取协议是因特网报文存取协议（IMAP），它比POP复杂得多，IMAP为用户提供了创建文件夹、在不同文件夹之间移动邮件及在远程文件夹中查询邮件等联机命令，为此IMAP服务器维护了会话用户的状态信息。IMAP的另一特性是允许用户代理只获取报文的某些部分，例如可以只读取一个报文的首部，或多部分MIM正报文的一部分。这非常适用于低带宽的情况，用户可能并不想取回邮箱中的所有邮件，尤其是包含很多音频或视频的大邮件。  

此外，随着万维网的流行，目前出现了很多基于万维网的电子邮件，如Hotmail、Gmail等。这种电子邮件的特点是，用户浏览器与Hlotmail或Gmail的邮件服务器之间的邮件发送或接收使用的是HTTP，而仅在不同邮件服务器之间传送邮件时才使用SMTP。  
  

二、综合应用题  

01.【解答】  

有时对方的邮件服务器不工作，邮件就发送不出去。对方的邮件服务器出故障也会使邮件去失。有时网络非常拥塞，路由器丢弃大量的IP数据报，导致通信中断。  

02.【解答】  

因为SMTP存在一些缺点和不足，所以通过MIME并非改变或取代SMTP。MIME继续使用RFC822格式，但增加了邮件主体的结构，并定义了传送非ASCII码的编码规则。也就是说，MIME邮件可在已有的电子邮件和协议下传送。  
03.【解答】  

1）本题中并未明确告诉这个报文段是从用户代理发往服务器还是从服务器发往用户代理。分析TCP首部格式可知，源端口为49382（0xc0e6），目的端口为25（0x0019），因此该应用层协议为SMTP。  

2）因为使用的是SMTP，且服务器端口25作为目的端口，所以源端口49382为用户代理所使用的端口。  

3）因为SMTP的协议字段都是用ASCII码表示的，所以发件人的关键字是FROM，从截图AS ClI FROM:cska oy an 2012  $\textit{\textcenttextcenttextcent}$  163.com  

# 6.5 万维网 (www)  

# 6.5.1WWW的概念与组成结构  

万维网（WorldWideWeb，WWW）是一个分布式、联机式的信息存储空间，在这个空间中：一样有用的事物称为一样“资源”，并由一个全域“统一资源定位符”（URL）标识。这些资源通过超文本传输协议（HTTP）传送给使用者，而后者通过单击链接来获取资源。  

万维网使用链接的方法能非常方便地从因特网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。超文本标记语言使得万维网页面的设计者很方便地用一个超链接从本页面的某处链接到因特网上的任何一个页面，并能在自己的计算机屏幕上显示这些页面。  

>#### pro：HTTP在传输层所使用的协议（2018）  

万维网的内核部分是由三个标准构成的：  

1）统一资源定位符（URL）。负责标识万维网上的各种文档，并使每个文档在整个万维网的范围内具有唯一的标识符URL。2）超文本传输协议（HTTP）。一个应用层协议，它使用TCP连接进行可靠的传输，HTTP是万维网客户程序和服务器程序之间交互所必须严格遵守的协议。3）超文本标记语言（HTML）。一种文档结构的标记语言，它使用一些约定的标记对页面上的各种信息（包括文字、声音、图像、视频等）、格式进行描述。URL是对可以从因特网上得到的资源的位置和访问方法的一种简洁表示。URL相当于一个  

文件名在网络范围的扩展。URL的一般形式是：  

<协议>指用什么协议来获取万维网文档，常见的协议有htp、ftp等；<主机>是存放资源的主机在因特网中的域名或IP地址；<端口>和<路径 $\scriptscriptstyle\dot{>}$ 有时可省略。在URL中不区分大小写。  

万维网以客户/服务器模式工作。浏览器是在用户主机上的万维网客户程序，而万维网文档所驻留的主机则运行服务器程序，这台主机称为万维网服务器。客户程序向服务器程序发出请求服务器程序向客户程序送回客户所要的万维网文档。工作流程如下：  

1）Web用户使用浏览器（指定URL）与Web服务器建立连接，并发送浏览请求。  

2）Web服务器把URL转换为文件路径，并返回信息给Web浏览器。  

3）通信完成，关闭连接。  

万维网是无数个网络站点和网页的集合，它们在一起构成了因特网最主要的部分（因特网也包括电子邮件、Usenet和新闻组）。  
# 6.5.2超文本传输协议（HTTP）  

HTTP定义了浏览器（万维网客户进程）怎样向万维网服务器请求方维网文档，以及服务器怎样把文档传送给浏览器。从层次的角度看，HTTP是面向事务（Transaction-oriented）的应用层协议，它规定了在浏览器和服务器之间的请求和响应的格式与规则，是方维网上能够可靠地交换文件（包括文本、声音、图像等各种多媒体文件）的重要基础。  

# 1.HTTP的操作过程  

从协议执行过程来说，浏览器要访问WWW服务器时，首先要完成对WWW服务器的域名解析。一旦获得了服务器的IP地址，浏览器就通过TCP向服务器发送连接建立请求。  

万维网的大致工作过程如图6.11所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/363a6b1080e3e78e9e80684b408b2662a0e895391584428207a067d33fa28931.jpg)  
图6.11万维网的工作过程  

每个方维网站点都有一个服务器进程，它不断地监听TCP的端口80（默认），当监听到连接请求后便与浏览器建立TCP连接。然后，浏览器就向服务器发送请求获取某个Web页面的HTTP请求。服务器收到请求后，将构建所请求W6页的必需信息，并通过HTTP响应返回给浏览器。浏览器再将信息进行解释，然后将Web页显示给用户。最后，TCP连接释放。  

>#### pro：访问Web时可能用到的协议（2014、2021）  

用户单击鼠标后所发生的事件按顺序如下（以访问清华大学的网站为例）：  

1）URL（http://www.tsinghua.edu.cn/chn/index.htm）。2）DNS www.tsinghua.edu.cn的IP地址。3）域名系统DNS解析出清华大学服务器的IP地址。4）浏览器与该服务器建立TCP连接（默认端口号为80）。5）HTTP：GET/chn/index.htm 6）服务器通过HTTP响应把文件index.htm发送给浏览器。  

7）释放TCP连接。  

8）浏览器解释文件index.htm，并将Web页显示给用户。  

上述过程是一个简化过程，实际过程涉及TCP/IP体系结构中应用层的DHCP、DNS和HTTP，传输层的UDP和TCP，网际层的IP和ARP，数据链路层的CSMA/CD或PPP（若涉及ISP接入或广域网传输）。本节主要介绍HTTP。  
2.HTTP的特点  

HTTP使用TCP作为传输层协议，保证了数据的可靠传输。HTTP不必考虑数据在传输过程中被丢弃后又怎样被重传。但是，HTTP本身是无连接的（务必注意）。也就是说，虽然HTTP使用了TCP连接，但通信的双方在交换HTTP报文之前不需要先建立HTTP连接。  

HTTP是无状态的。也就是说，同一个客户第二次访问同一个服务器上的页面时，服务器的响应与第一次被访问时的相同，因为服务器并不记得曾经服务过的这个客户。  

HTTP的无状态特性简化了服务器的设计，使之更易支持大量并发的请求。在实际应用中，通常使用Cookie加数据库的方式来跟踪用户的活动（如记录用户最近浏览的商品等）。Cookie的工作原理：当用户初次浏览某个使用Cookie的网站时，该网站服务器就为用户产生一个唯一的Cookie识别码，如“12345”，并以此为索引在后端数据库中创建一个项目，用来记录用户访问该网站的各种信息。接着在给用户的响应报文中添加一个Set-cookie的首部行“Setcookie:12345”，用户收到响应后，就在它管理的特定Cookie文件中添加该服务器的主机名和Cookie识别码。当用户再次浏览这个网站时，会取出这个网站的识别码，并在请求报文中添加一个Cookie首部行“Cookie:12345”。服务器根据Cookie识别码就能从数据库中查询到该用户的活动记录，进而执行一些个性化的工作，如根据用户的历史浏览记录向其推荐新商品等。  

HTTP既可以使用非持续连接（HTTP/1.O），也可以使用持续连接（HTTP/1.1支持）。  

>#### pro：HTTP页面请求时间的分析（2020）  

对于非持续连接，每个网页元素对象（如JPEG图形、Flash等）的传输都需要单独建立一个TCP连接，如图6.12所示（第三次握手的报文段中梢带了客户对万维网文档的请求）。请求一个万维网文档所需的时间是该文档的传输时间（与文档大小成正比）加上两倍往返时间RTT（一个RTT用于TCP连接，另一个RTT用于请求和接收文档）。每请求一个对象都导致 $2{\times}\mathrm{RTT}$ 的开销，此外每次建立新的TCP连接都要分配缓存和变量，使万维网服务器的负担很重。  

所谓持续连接，是指万维网服务器在发送响应后仍然保持这条连接，使同一个客户和该服务器可以继续在这条TCP连接上传送后续的HTTP请求报文和响应报文，如图6.13所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/08b82f7f1d88b1f3b0c9eb1da958e256c83631e22d81d9985f204e369daec97d.jpg)  
图6.12请求一个万维网文档所需的时间  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/d8a1e5c5841bd5690047250af1122856a1bed175683d0f7181aa958511f8ee4e.jpg)  
图6.13使用持续连接（非流水线）  
>#### pro：HTTP/1.1页面请求时间的分析（2011、2022）  

HTTP/1.1默认使用持续连接。持续连接又分为非流水线和流水线两种工作方式。对于非流水线方式，客户在收到前一个响应后才能发出下一个请求，服务器在发送完一个对象后，其TCP连接就处于空闲状态，浪费了服务器资源。对于流水线方式，客户可以连续发出对各个对象的请求，服务器就可连续响应这些请求。若所有的请求和响应都是连续发送的，则引用所有对象共计经历1个RTT延迟，而不是像非流水线方式那样，每个对象都必须有1个RTT延迟。这种方式减少了TCP连接中的空闲时间，提高了效率。当然，在流水线方式中，服务器在每个RTT连续发送的数据量还受到TCP发送窗口的限制。  

# 3.HTTP的报文结构  

>#### pro：  

# HTTP请求报文中各种方法的意义（2015）  

HTTP是面向文本的（Text-Oriented），因此报文中的每个字段都是一些ASCⅡI码串，并且每个字段的长度都是不确定的。有两类HTTP报文：  

请求报文：从客户向服务器发送的请求报文，如图6.14(a)所示。响应报文：从服务器到客户的回答，如图6.14(b)所示。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/dc22417e8a5262e7d4371c0540322afc2b85b46a41a3f4dc747d385dd38e9c24.jpg)  
图6.14HTTP的报文结构  

从图6.14可以看出，两种报文都由三个部分组成，两者格式的区别就是开始行不同。  

开始行：在请求报文中的开始行称为请求行，而在响应报文中的开始行称为状态行。开始行的三个字段之间都以空格分隔，最后的“CR”和“LF”分别代表“回车”和“换行”。  

首部行：用来说明浏览器、服务器或报文主体的一些信息。首部可以有几行，但也可以不使用。在每个首部行中都有首部字段名和它的值，每一行的结束都要有“回车”和“换行”。整个首部行结束时，还有一空行将首部行和后面的实体主体分开。  

实体主体：在请求报文中一般不用这个字段，而在响应报文中也可能没有这个字段。  

请求报文的“请求行”有三个内容：方法、请求资源的URL及HTTP的版本。其中，“方法”是对所请求对象进行的操作，这些方法实际上也就是一些命令。表6.1列出了常用的几种方法。  

表6.1HTTP请求报文中常用的几个方法
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/92d53ee3242092e4b08f0650c3127b1480828e42ece80aeb9314973ae11db4ab.jpg)  
下面是一个典型的HTTP请求报文：  

GET/bbs/index.htmHTTP/1.1指明方法“GET”、相对URL、HTTP版本}Host:www.cskaoyan.com 指明服务器的域名 Connection: Keep-Alive要求服务器在发送完被请求的文档后保持这条连接User-Agent:Mozilla/5.0{表明用户代理是浏览器Mozilla/5.0}Accept-Language: cn{表示用户希望优先得到中文版本的文档}  

第1行是请求行，它使用了相对URL，因为下面的首部行给出了服务器的域名。第3行告诉服务器使用持续连接，表示浏览器要求服务器在发送完被请求的文档后保持这条TCP连接，若要求使用非持续连接，则对应首部行应为“Connection:close”。  

HTTP响应报文的第1行是状态行，它包含三个内容：HTTP的版本、状态码、解释状态码的短语。下面是HTTP响应报文中常见的三种状态行：  

HTTP/1.1 202 Accepted{接受请求}HTTP/1.1 400Bad Request {错误的请求} HTTP/1.1404 Not Found{找不到页面}  

# 4.HTTP请求报文举例  

图6.15所示为Wireshark捕获的一个HTTP请求报文。  

![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/515e751b14db49afc2fe22d36d3a943c3fb0480756f37eda47cc30973bd9d976.jpg)  
图6.15用Wireshark捕获的一个HTTP请求报文  

根据帧的结构定义，在图6.15的以太网数据帧中，第 $1\!\sim\!6$ 个字节为目的MAC地址（默认网关地址），即00-0f-e2-3f-27-3f；第 $7\!\sim\!12$ 个字节为本机MAC地址，即00-27-13-67-73-8d；第 $13\!\sim\!14$ 个字节 $08\!\sim\!00$ 为类型字段，表示上层使用的是IP数据报协议。第 $15{\sim}34$ 个字节（共20B）为IP数据报的首部，其中第 $27\!\sim\!30$ 个字节为源IP地址，即db-df-d2-70，转换成十进制为219.223.210.112：第 $31\!\sim\!34$ 个字节为目的IP地址，即71-69-4e-0a，转换成十进制为113.105.78.10。第 $35\!\sim\!54$ 个字节（共20B）为TCP报文段的首部。  

从第55个字节开始才是TCP数据部分（阴影部分），即从应用层传递下来的数据（本例中即请求报文），GET对应请求行的方法，/face/20.gif对应请求行的URL， $\mathrm{HTTP}/1.1$ 对应请求行的版本，左边数字是对应字符的ASCII码，如 $\mathrm{'G'}\,{=}\,0\mathrm{x}47$ 、 ${}^{\prime}\mathrm{E^{\prime}}\!=\!0\mathrm{x}45$ 、 $\mathrm{{'T'}}\!=\!0\mathrm{{x}}54$ 等。图6.15的请求报文中首部行字段内容的含义，建议读者自行了解，也可以自己动手抓包分析。  
常见应用层协议小结如表6.2所示。  

表6.2常见应用层协议小结
![](https://cdn-mineru.openxlab.org.cn/model-mineru/prod/6a17e3acc5e24d05afd103b899739bb177a17668a96e0a1d020cb0a76d5289c1.jpg)  


# 6.6本章小结及疑难点  

1.如何理解客户进程端口号与服务器进程端口号？  

通常我们所说的熟知端口号是指应用层协议在服务器端的默认端口号，而客户端进程的端口号是由客户端进程任意指定的（临时的）。  

当客户进程向服务器进程发出建立连接请求时，要寻找连接服务器进程的熟知端口号，同时还要告诉服务器进程自己的临时端口号。接着，服务器进程就用自己的熟知端口号与客户进程所提供的端口号建立连接。  

2.因特网和万维网的区别是什么？  

因特网（Intemet）是指在ARPA网基础上发展而来的世界上最大的全球性互连网络，它采用TCP/IP协议族作为通信规则。  

万维网（WWW）是无数个网络站点和网页的集合，它们一起构成了因特网最主要的部分（因特网也包括电子邮件、Usenet和新闻组）。  
